package eventbus

import (
	"context"
	"encoding/json"
	"fmt"
	"runtime"
	"sync/atomic"
	"testing"
	"time"
)

// JetStreamPerformanceMetrics JetStreamæ€§èƒ½æŒ‡æ ‡
type JetStreamPerformanceMetrics struct {
	System            string
	StorageMode       string // "memory", "file"
	Pressure          string
	Messages          int
	Sent              int64
	Received          int64
	Errors            int64
	SuccessRate       float64
	SendRate          float64
	Throughput        float64
	FirstLatency      time.Duration
	AverageLatency    time.Duration
	P95Latency        time.Duration
	P99Latency        time.Duration
	InitialMemoryMB   float64
	PeakMemoryMB      float64
	MemoryDeltaMB     float64
	InitialGoroutines int
	PeakGoroutines    int
	GoroutineDelta    int
	Duration          time.Duration
	BytesSent         int64
	BytesReceived     int64
}

// TestRealJetStreamPerformance çœŸæ­£çš„JetStreamæ€§èƒ½æµ‹è¯•
func TestRealJetStreamPerformance(t *testing.T) {
	t.Logf("ğŸš€ REAL NATS JETSTREAM PERFORMANCE TEST")
	t.Logf("ğŸ’¾ Testing Memory vs Disk persistence with proper EventBus configuration")

	// æµ‹è¯•åœºæ™¯
	scenarios := []struct {
		name     string
		messages int
		timeout  time.Duration
	}{
		{"Light", 300, 60 * time.Second},
		{"Medium", 800, 90 * time.Second},
		{"Heavy", 1500, 120 * time.Second},
		{"Extreme", 2500, 150 * time.Second},
	}

	allResults := make(map[string][]*JetStreamPerformanceMetrics)
	allResults["JetStream-Memory"] = make([]*JetStreamPerformanceMetrics, 0)
	allResults["JetStream-Disk"] = make([]*JetStreamPerformanceMetrics, 0)
	allResults["Kafka-Disk"] = make([]*JetStreamPerformanceMetrics, 0)

	for _, scenario := range scenarios {
		t.Logf("\nğŸ¯ ===== %s Load JetStream Test (%d messages) =====", scenario.name, scenario.messages)

		// 1. JetStream MemoryæŒä¹…åŒ–
		t.Logf("ğŸŸ¡ NATS JetStream Memory Persistence...")
		memoryResult := testJetStreamMemoryPersistence(t, scenario.name, scenario.messages, scenario.timeout)
		allResults["JetStream-Memory"] = append(allResults["JetStream-Memory"], memoryResult)

		// æ¸…ç†é—´éš”
		time.Sleep(5 * time.Second)
		runtime.GC()

		// 2. JetStream DiskæŒä¹…åŒ–
		t.Logf("ğŸŸ  NATS JetStream Disk Persistence...")
		diskResult := testJetStreamDiskPersistence(t, scenario.name, scenario.messages, scenario.timeout)
		allResults["JetStream-Disk"] = append(allResults["JetStream-Disk"], diskResult)

		// æ¸…ç†é—´éš”
		time.Sleep(5 * time.Second)
		runtime.GC()

		// 3. Kafkaå¯¹æ¯”
		t.Logf("ğŸ”´ Kafka Disk Persistence...")
		kafkaResult := testKafkaForComparison(t, scenario.name, scenario.messages, scenario.timeout)
		allResults["Kafka-Disk"] = append(allResults["Kafka-Disk"], kafkaResult)

		// åˆ†æå›åˆç»“æœ
		analyzeJetStreamRound(t, scenario.name, memoryResult, diskResult, kafkaResult)

		// æ¸…ç†é—´éš”
		time.Sleep(8 * time.Second)
		runtime.GC()
	}

	// ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
	generateJetStreamFinalReport(t, allResults)
}

// testJetStreamMemoryPersistence æµ‹è¯•JetStreamå†…å­˜æŒä¹…åŒ–
func testJetStreamMemoryPersistence(t *testing.T, pressure string, messageCount int, timeout time.Duration) *JetStreamPerformanceMetrics {
	config := &NATSConfig{
		URLs:                []string{"nats://localhost:4223"},
		ClientID:            fmt.Sprintf("jetstream-memory-%s-%d", pressure, time.Now().Unix()),
		MaxReconnects:       5,
		ReconnectWait:       2 * time.Second,
		ConnectionTimeout:   10 * time.Second,
		HealthCheckInterval: 30 * time.Second,
		JetStream: JetStreamConfig{
			Enabled:        true,
			PublishTimeout: 10 * time.Second,
			AckWait:        15 * time.Second,
			MaxDeliver:     3,
			Stream: StreamConfig{
				Name:      fmt.Sprintf("MEMORY_PERF_%s_%d", pressure, time.Now().Unix()),
				Subjects:  []string{fmt.Sprintf("memory.perf.%s.>", pressure)},
				Retention: "limits",
				Storage:   "memory", // å†…å­˜æŒä¹…åŒ–
				Replicas:  1,
				MaxAge:    30 * time.Minute,
				MaxBytes:  512 * 1024 * 1024, // 512MB
				MaxMsgs:   100000,
				Discard:   "old",
			},
			Consumer: NATSConsumerConfig{
				DurableName:   fmt.Sprintf("memory_perf_%s_%d", pressure, time.Now().Unix()),
				DeliverPolicy: "all",
				AckPolicy:     "explicit",
				ReplayPolicy:  "instant",
				MaxAckPending: 500,
				MaxWaiting:    200,
				MaxDeliver:    3,
			},
		},
	}

	testTopic := fmt.Sprintf("memory.perf.%s.test", pressure)
	return runJetStreamPerformanceTest(t, config, "JetStream", "memory", pressure, messageCount, timeout, testTopic)
}

// testJetStreamDiskPersistence æµ‹è¯•JetStreamç£ç›˜æŒä¹…åŒ–
func testJetStreamDiskPersistence(t *testing.T, pressure string, messageCount int, timeout time.Duration) *JetStreamPerformanceMetrics {
	config := &NATSConfig{
		URLs:                []string{"nats://localhost:4223"},
		ClientID:            fmt.Sprintf("jetstream-disk-%s-%d", pressure, time.Now().Unix()),
		MaxReconnects:       5,
		ReconnectWait:       2 * time.Second,
		ConnectionTimeout:   10 * time.Second,
		HealthCheckInterval: 30 * time.Second,
		JetStream: JetStreamConfig{
			Enabled:        true,
			PublishTimeout: 10 * time.Second,
			AckWait:        15 * time.Second,
			MaxDeliver:     3,
			Stream: StreamConfig{
				Name:      fmt.Sprintf("DISK_PERF_%s_%d", pressure, time.Now().Unix()),
				Subjects:  []string{fmt.Sprintf("disk.perf.%s.>", pressure)},
				Retention: "limits",
				Storage:   "file", // ç£ç›˜æŒä¹…åŒ–
				Replicas:  1,
				MaxAge:    30 * time.Minute,
				MaxBytes:  512 * 1024 * 1024, // 512MB
				MaxMsgs:   100000,
				Discard:   "old",
			},
			Consumer: NATSConsumerConfig{
				DurableName:   fmt.Sprintf("disk_perf_%s_%d", pressure, time.Now().Unix()),
				DeliverPolicy: "all",
				AckPolicy:     "explicit",
				ReplayPolicy:  "instant",
				MaxAckPending: 500,
				MaxWaiting:    200,
				MaxDeliver:    3,
			},
		},
	}

	testTopic := fmt.Sprintf("disk.perf.%s.test", pressure)
	return runJetStreamPerformanceTest(t, config, "JetStream", "file", pressure, messageCount, timeout, testTopic)
}

// testKafkaForComparison æµ‹è¯•Kafkaä½œä¸ºå¯¹æ¯”
func testKafkaForComparison(t *testing.T, pressure string, messageCount int, timeout time.Duration) *JetStreamPerformanceMetrics {
	config := &KafkaConfig{
		Brokers:  []string{"localhost:29094"},
		ClientID: fmt.Sprintf("jetstream-compare-kafka-%s", pressure),
		Producer: ProducerConfig{
			MaxMessageBytes: 1024 * 1024,
			RequiredAcks:    1, // ç¡®ä¿æŒä¹…åŒ–
			Timeout:         10 * time.Second,
		},
		Consumer: ConsumerConfig{
			GroupID:            fmt.Sprintf("jetstream-compare-kafka-%s-group", pressure),
			AutoOffsetReset:    "earliest",
			SessionTimeout:     10 * time.Second,
			HeartbeatInterval:  3 * time.Second,
			MaxProcessingTime:  8 * time.Second,
			FetchMaxWait:       200 * time.Millisecond,
			MaxPollRecords:     2000,
			EnableAutoCommit:   true,
			AutoCommitInterval: 1000 * time.Millisecond,
		},
	}

	eventBus, err := NewKafkaEventBus(config)
	if err != nil {
		t.Fatalf("Kafka failed: %v", err)
	}
	defer eventBus.Close()

	// è®¾ç½®é¢„è®¢é˜…
	kafkaBus := eventBus.(*kafkaEventBus)
	testTopic := fmt.Sprintf("jetstream.compare.kafka.%s.test", pressure)
	kafkaBus.allPossibleTopics = []string{testTopic}

	return runKafkaPerformanceTest(t, eventBus, "Kafka", "file", pressure, messageCount, timeout, testTopic)
}

// runJetStreamPerformanceTest è¿è¡ŒJetStreamæ€§èƒ½æµ‹è¯•
func runJetStreamPerformanceTest(t *testing.T, config *NATSConfig, system, storageMode, pressure string, messageCount int, timeout time.Duration, topic string) *JetStreamPerformanceMetrics {
	// åˆå§‹åŒ–æŒ‡æ ‡
	metrics := &JetStreamPerformanceMetrics{
		System:      system,
		StorageMode: storageMode,
		Pressure:    pressure,
		Messages:    messageCount,
	}

	// è®°å½•åˆå§‹èµ„æºçŠ¶æ€
	metrics.InitialGoroutines = runtime.NumGoroutine()
	var m runtime.MemStats
	runtime.ReadMemStats(&m)
	metrics.InitialMemoryMB = float64(m.Alloc) / 1024 / 1024

	// åˆ›å»ºEventBus
	eventBus, err := NewNATSEventBus(config)
	if err != nil {
		t.Logf("âŒ %s %s failed: %v", system, storageMode, err)
		metrics.Errors = int64(messageCount)
		return metrics
	}
	defer eventBus.Close()

	ctx, cancel := context.WithTimeout(context.Background(), timeout)
	defer cancel()

	startTime := time.Now()
	var receivedCount int64
	var errors int64
	var firstMessageTime time.Time
	latencies := make([]time.Duration, 0, messageCount)
	var totalBytes int64

	// æ¶ˆæ¯å¤„ç†å™¨
	handler := func(ctx context.Context, message []byte) error {
		receiveTime := time.Now()
		count := atomic.AddInt64(&receivedCount, 1)
		atomic.AddInt64(&totalBytes, int64(len(message)))

		if count == 1 {
			firstMessageTime = receiveTime
		}

		// è§£ææ¶ˆæ¯è·å–å‘é€æ—¶é—´
		var msg map[string]interface{}
		if err := json.Unmarshal(message, &msg); err == nil {
			if sendTimeNano, ok := msg["sendTime"].(float64); ok {
				sendTime := time.Unix(0, int64(sendTimeNano))
				latency := receiveTime.Sub(sendTime)
				latencies = append(latencies, latency)
			}
		}

		return nil
	}

	// è®¢é˜…
	err = eventBus.Subscribe(ctx, topic, handler)
	if err != nil {
		t.Logf("âŒ %s %s subscribe failed: %v", system, storageMode, err)
		metrics.Errors = int64(messageCount)
		return metrics
	}

	// é¢„çƒ­
	t.Logf("ğŸ”¥ %s (%s) warming up for 5 seconds...", system, storageMode)
	time.Sleep(5 * time.Second)

	t.Logf("âš¡ %s (%s) sending %d messages...", system, storageMode, messageCount)

	// å‘é€æ¶ˆæ¯å¹¶è®°å½•æ€§èƒ½
	sendStart := time.Now()
	var sentBytes int64

	for i := 0; i < messageCount; i++ {
		sendTime := time.Now()
		message := map[string]interface{}{
			"id":        fmt.Sprintf("%s-%s-%s-%d", system, storageMode, pressure, i),
			"content":   fmt.Sprintf("%s %s %s performance test message %d", system, storageMode, pressure, i),
			"sendTime":  sendTime.UnixNano(),
			"index":     i,
			"system":    system,
			"storage":   storageMode,
			"pressure":  pressure,
			"timestamp": sendTime.Format(time.RFC3339Nano),
		}

		messageBytes, _ := json.Marshal(message)
		atomic.AddInt64(&sentBytes, int64(len(messageBytes)))

		err := eventBus.Publish(ctx, topic, messageBytes)
		if err != nil {
			atomic.AddInt64(&errors, 1)
		} else {
			atomic.AddInt64(&metrics.Sent, 1)
		}
	}

	sendDuration := time.Since(sendStart)
	metrics.SendRate = float64(messageCount) / sendDuration.Seconds()
	metrics.BytesSent = sentBytes

	t.Logf("ğŸ“¤ %s (%s) sent %d messages in %.2fs (%.1f msg/s)",
		system, storageMode, messageCount, sendDuration.Seconds(), metrics.SendRate)

	// ç­‰å¾…å¤„ç†å®Œæˆ
	waitTime := 20 * time.Second
	t.Logf("â³ %s (%s) waiting %.0fs for processing...", system, storageMode, waitTime.Seconds())
	time.Sleep(waitTime)

	// è®°å½•ç»“æŸæ—¶é—´å’Œæœ€ç»ˆçŠ¶æ€
	endTime := time.Now()
	metrics.Duration = endTime.Sub(startTime)
	metrics.Received = atomic.LoadInt64(&receivedCount)
	metrics.Errors = atomic.LoadInt64(&errors)
	metrics.BytesReceived = atomic.LoadInt64(&totalBytes)

	// è®¡ç®—æˆåŠŸç‡å’Œååé‡
	metrics.SuccessRate = float64(metrics.Received) / float64(messageCount) * 100
	metrics.Throughput = float64(metrics.Received) / metrics.Duration.Seconds()

	// è®¡ç®—å»¶è¿ŸæŒ‡æ ‡
	if !firstMessageTime.IsZero() {
		metrics.FirstLatency = firstMessageTime.Sub(sendStart)
	}

	if len(latencies) > 0 {
		// è®¡ç®—å¹³å‡å»¶è¿Ÿ
		var totalLatency time.Duration
		for _, lat := range latencies {
			totalLatency += lat
		}
		metrics.AverageLatency = totalLatency / time.Duration(len(latencies))

		// è®¡ç®—P95å’ŒP99å»¶è¿Ÿ
		if len(latencies) >= 20 {
			// ç®€å•æ’åºå–ç™¾åˆ†ä½
			sortedLatencies := make([]time.Duration, len(latencies))
			copy(sortedLatencies, latencies)
			// ç®€åŒ–ç‰ˆæ’åº
			for i := 0; i < len(sortedLatencies); i++ {
				for j := i + 1; j < len(sortedLatencies); j++ {
					if sortedLatencies[i] > sortedLatencies[j] {
						sortedLatencies[i], sortedLatencies[j] = sortedLatencies[j], sortedLatencies[i]
					}
				}
			}

			p95Index := int(float64(len(sortedLatencies)) * 0.95)
			p99Index := int(float64(len(sortedLatencies)) * 0.99)
			if p95Index < len(sortedLatencies) {
				metrics.P95Latency = sortedLatencies[p95Index]
			}
			if p99Index < len(sortedLatencies) {
				metrics.P99Latency = sortedLatencies[p99Index]
			}
		}
	}

	// è®°å½•å³°å€¼èµ„æºä½¿ç”¨
	metrics.PeakGoroutines = runtime.NumGoroutine()
	metrics.GoroutineDelta = metrics.PeakGoroutines - metrics.InitialGoroutines

	runtime.ReadMemStats(&m)
	metrics.PeakMemoryMB = float64(m.Alloc) / 1024 / 1024
	metrics.MemoryDeltaMB = metrics.PeakMemoryMB - metrics.InitialMemoryMB

	t.Logf("ğŸ“Š %s (%s) Results: %d/%d (%.1f%%), %.1f msg/s throughput, %v first latency",
		system, storageMode, metrics.Received, messageCount, metrics.SuccessRate,
		metrics.Throughput, metrics.FirstLatency)

	return metrics
}

// runKafkaPerformanceTest è¿è¡ŒKafkaæ€§èƒ½æµ‹è¯•
func runKafkaPerformanceTest(t *testing.T, eventBus EventBus, system, storageMode, pressure string, messageCount int, timeout time.Duration, topic string) *JetStreamPerformanceMetrics {
	// åˆå§‹åŒ–æŒ‡æ ‡
	metrics := &JetStreamPerformanceMetrics{
		System:      system,
		StorageMode: storageMode,
		Pressure:    pressure,
		Messages:    messageCount,
	}

	// è®°å½•åˆå§‹èµ„æºçŠ¶æ€
	metrics.InitialGoroutines = runtime.NumGoroutine()
	var m runtime.MemStats
	runtime.ReadMemStats(&m)
	metrics.InitialMemoryMB = float64(m.Alloc) / 1024 / 1024

	ctx, cancel := context.WithTimeout(context.Background(), timeout)
	defer cancel()

	startTime := time.Now()
	var receivedCount int64
	var errors int64
	var firstMessageTime time.Time
	latencies := make([]time.Duration, 0, messageCount)
	var totalBytes int64

	// æ¶ˆæ¯å¤„ç†å™¨
	handler := func(ctx context.Context, message []byte) error {
		receiveTime := time.Now()
		count := atomic.AddInt64(&receivedCount, 1)
		atomic.AddInt64(&totalBytes, int64(len(message)))

		if count == 1 {
			firstMessageTime = receiveTime
		}

		// è§£ææ¶ˆæ¯è·å–å‘é€æ—¶é—´
		var msg map[string]interface{}
		if err := json.Unmarshal(message, &msg); err == nil {
			if sendTimeNano, ok := msg["sendTime"].(float64); ok {
				sendTime := time.Unix(0, int64(sendTimeNano))
				latency := receiveTime.Sub(sendTime)
				latencies = append(latencies, latency)
			}
		}

		return nil
	}

	// è®¢é˜…
	err := eventBus.Subscribe(ctx, topic, handler)
	if err != nil {
		t.Logf("âŒ %s %s subscribe failed: %v", system, storageMode, err)
		metrics.Errors = int64(messageCount)
		return metrics
	}

	// é¢„çƒ­
	t.Logf("ğŸ”¥ %s (%s) warming up for 5 seconds...", system, storageMode)
	time.Sleep(5 * time.Second)

	t.Logf("âš¡ %s (%s) sending %d messages...", system, storageMode, messageCount)

	// å‘é€æ¶ˆæ¯å¹¶è®°å½•æ€§èƒ½
	sendStart := time.Now()
	var sentBytes int64

	for i := 0; i < messageCount; i++ {
		sendTime := time.Now()
		message := map[string]interface{}{
			"id":        fmt.Sprintf("%s-%s-%s-%d", system, storageMode, pressure, i),
			"content":   fmt.Sprintf("%s %s %s performance test message %d", system, storageMode, pressure, i),
			"sendTime":  sendTime.UnixNano(),
			"index":     i,
			"system":    system,
			"storage":   storageMode,
			"pressure":  pressure,
			"timestamp": sendTime.Format(time.RFC3339Nano),
		}

		messageBytes, _ := json.Marshal(message)
		atomic.AddInt64(&sentBytes, int64(len(messageBytes)))

		err := eventBus.Publish(ctx, topic, messageBytes)
		if err != nil {
			atomic.AddInt64(&errors, 1)
		} else {
			atomic.AddInt64(&metrics.Sent, 1)
		}
	}

	sendDuration := time.Since(sendStart)
	metrics.SendRate = float64(messageCount) / sendDuration.Seconds()
	metrics.BytesSent = sentBytes

	t.Logf("ğŸ“¤ %s (%s) sent %d messages in %.2fs (%.1f msg/s)",
		system, storageMode, messageCount, sendDuration.Seconds(), metrics.SendRate)

	// ç­‰å¾…å¤„ç†å®Œæˆ
	waitTime := 20 * time.Second
	t.Logf("â³ %s (%s) waiting %.0fs for processing...", system, storageMode, waitTime.Seconds())
	time.Sleep(waitTime)

	// è®°å½•ç»“æŸæ—¶é—´å’Œæœ€ç»ˆçŠ¶æ€
	endTime := time.Now()
	metrics.Duration = endTime.Sub(startTime)
	metrics.Received = atomic.LoadInt64(&receivedCount)
	metrics.Errors = atomic.LoadInt64(&errors)
	metrics.BytesReceived = atomic.LoadInt64(&totalBytes)

	// è®¡ç®—æˆåŠŸç‡å’Œååé‡
	metrics.SuccessRate = float64(metrics.Received) / float64(messageCount) * 100
	metrics.Throughput = float64(metrics.Received) / metrics.Duration.Seconds()

	// è®¡ç®—å»¶è¿ŸæŒ‡æ ‡
	if !firstMessageTime.IsZero() {
		metrics.FirstLatency = firstMessageTime.Sub(sendStart)
	}

	if len(latencies) > 0 {
		// è®¡ç®—å¹³å‡å»¶è¿Ÿ
		var totalLatency time.Duration
		for _, lat := range latencies {
			totalLatency += lat
		}
		metrics.AverageLatency = totalLatency / time.Duration(len(latencies))

		// è®¡ç®—P95å’ŒP99å»¶è¿Ÿ
		if len(latencies) >= 20 {
			// ç®€å•æ’åºå–ç™¾åˆ†ä½
			sortedLatencies := make([]time.Duration, len(latencies))
			copy(sortedLatencies, latencies)
			// ç®€åŒ–ç‰ˆæ’åº
			for i := 0; i < len(sortedLatencies); i++ {
				for j := i + 1; j < len(sortedLatencies); j++ {
					if sortedLatencies[i] > sortedLatencies[j] {
						sortedLatencies[i], sortedLatencies[j] = sortedLatencies[j], sortedLatencies[i]
					}
				}
			}

			p95Index := int(float64(len(sortedLatencies)) * 0.95)
			p99Index := int(float64(len(sortedLatencies)) * 0.99)
			if p95Index < len(sortedLatencies) {
				metrics.P95Latency = sortedLatencies[p95Index]
			}
			if p99Index < len(sortedLatencies) {
				metrics.P99Latency = sortedLatencies[p99Index]
			}
		}
	}

	// è®°å½•å³°å€¼èµ„æºä½¿ç”¨
	metrics.PeakGoroutines = runtime.NumGoroutine()
	metrics.GoroutineDelta = metrics.PeakGoroutines - metrics.InitialGoroutines

	runtime.ReadMemStats(&m)
	metrics.PeakMemoryMB = float64(m.Alloc) / 1024 / 1024
	metrics.MemoryDeltaMB = metrics.PeakMemoryMB - metrics.InitialMemoryMB

	t.Logf("ğŸ“Š %s (%s) Results: %d/%d (%.1f%%), %.1f msg/s throughput, %v first latency",
		system, storageMode, metrics.Received, messageCount, metrics.SuccessRate,
		metrics.Throughput, metrics.FirstLatency)

	return metrics
}

// analyzeJetStreamRound åˆ†æå•è½®JetStreamæµ‹è¯•ç»“æœ
func analyzeJetStreamRound(t *testing.T, pressure string, memoryResult, diskResult, kafkaResult *JetStreamPerformanceMetrics) {
	t.Logf("\nğŸ“ˆ %s Load JetStream Analysis:", pressure)

	// è¯¦ç»†ç»“æœå±•ç¤º
	t.Logf("ğŸŸ¡ JetStream Memory:")
	t.Logf("   ğŸ“Š Success: %.1f%% (%d/%d)", memoryResult.SuccessRate, memoryResult.Received, memoryResult.Messages)
	t.Logf("   ğŸš€ Send Rate: %.1f msg/s", memoryResult.SendRate)
	t.Logf("   ğŸ“ˆ Throughput: %.1f msg/s", memoryResult.Throughput)
	t.Logf("   â±ï¸  First Latency: %v", memoryResult.FirstLatency)
	t.Logf("   ğŸ“Š Avg Latency: %v", memoryResult.AverageLatency)
	t.Logf("   ğŸ”§ Goroutines: %d (+%d)", memoryResult.PeakGoroutines, memoryResult.GoroutineDelta)
	t.Logf("   ğŸ’¾ Memory: %.2f MB (+%.2f MB)", memoryResult.PeakMemoryMB, memoryResult.MemoryDeltaMB)

	t.Logf("ğŸŸ  JetStream Disk:")
	t.Logf("   ğŸ“Š Success: %.1f%% (%d/%d)", diskResult.SuccessRate, diskResult.Received, diskResult.Messages)
	t.Logf("   ğŸš€ Send Rate: %.1f msg/s", diskResult.SendRate)
	t.Logf("   ğŸ“ˆ Throughput: %.1f msg/s", diskResult.Throughput)
	t.Logf("   â±ï¸  First Latency: %v", diskResult.FirstLatency)
	t.Logf("   ğŸ“Š Avg Latency: %v", diskResult.AverageLatency)
	t.Logf("   ğŸ”§ Goroutines: %d (+%d)", diskResult.PeakGoroutines, diskResult.GoroutineDelta)
	t.Logf("   ğŸ’¾ Memory: %.2f MB (+%.2f MB)", diskResult.PeakMemoryMB, diskResult.MemoryDeltaMB)

	t.Logf("ğŸ”´ Kafka Disk:")
	t.Logf("   ğŸ“Š Success: %.1f%% (%d/%d)", kafkaResult.SuccessRate, kafkaResult.Received, kafkaResult.Messages)
	t.Logf("   ğŸš€ Send Rate: %.1f msg/s", kafkaResult.SendRate)
	t.Logf("   ğŸ“ˆ Throughput: %.1f msg/s", kafkaResult.Throughput)
	t.Logf("   â±ï¸  First Latency: %v", kafkaResult.FirstLatency)
	t.Logf("   ğŸ“Š Avg Latency: %v", kafkaResult.AverageLatency)
	t.Logf("   ğŸ”§ Goroutines: %d (+%d)", kafkaResult.PeakGoroutines, kafkaResult.GoroutineDelta)
	t.Logf("   ğŸ’¾ Memory: %.2f MB (+%.2f MB)", kafkaResult.PeakMemoryMB, kafkaResult.MemoryDeltaMB)

	// ç›´æ¥å¯¹æ¯”åˆ†æ
	t.Logf("\nâš”ï¸ Direct Comparison:")

	// å¯é æ€§å¯¹æ¯”
	if memoryResult.SuccessRate >= kafkaResult.SuccessRate && diskResult.SuccessRate >= kafkaResult.SuccessRate {
		t.Logf("   âœ… JetStream wins in reliability: Memory %.1f%%, Disk %.1f%% vs Kafka %.1f%%",
			memoryResult.SuccessRate, diskResult.SuccessRate, kafkaResult.SuccessRate)
	} else if kafkaResult.SuccessRate > memoryResult.SuccessRate && kafkaResult.SuccessRate > diskResult.SuccessRate {
		t.Logf("   âœ… Kafka wins in reliability: %.1f%% vs JetStream Memory %.1f%%, Disk %.1f%%",
			kafkaResult.SuccessRate, memoryResult.SuccessRate, diskResult.SuccessRate)
	}

	// ååé‡å¯¹æ¯”
	if memoryResult.Throughput > kafkaResult.Throughput {
		ratio := memoryResult.Throughput / kafkaResult.Throughput
		t.Logf("   âœ… JetStream Memory wins in throughput: %.1fx faster (%.1f vs %.1f msg/s)",
			ratio, memoryResult.Throughput, kafkaResult.Throughput)
	}

	if diskResult.Throughput > kafkaResult.Throughput {
		ratio := diskResult.Throughput / kafkaResult.Throughput
		t.Logf("   âœ… JetStream Disk wins in throughput: %.1fx faster (%.1f vs %.1f msg/s)",
			ratio, diskResult.Throughput, kafkaResult.Throughput)
	}

	// å»¶è¿Ÿå¯¹æ¯”
	if memoryResult.FirstLatency > 0 && kafkaResult.FirstLatency > 0 {
		if memoryResult.FirstLatency < kafkaResult.FirstLatency {
			ratio := float64(kafkaResult.FirstLatency.Nanoseconds()) / float64(memoryResult.FirstLatency.Nanoseconds())
			t.Logf("   âœ… JetStream Memory wins in latency: %.1fx faster (%v vs %v)",
				ratio, memoryResult.FirstLatency, kafkaResult.FirstLatency)
		}
	}

	if diskResult.FirstLatency > 0 && kafkaResult.FirstLatency > 0 {
		if diskResult.FirstLatency < kafkaResult.FirstLatency {
			ratio := float64(kafkaResult.FirstLatency.Nanoseconds()) / float64(diskResult.FirstLatency.Nanoseconds())
			t.Logf("   âœ… JetStream Disk wins in latency: %.1fx faster (%v vs %v)",
				ratio, diskResult.FirstLatency, kafkaResult.FirstLatency)
		}
	}

	// æŒä¹…åŒ–æ¨¡å¼å¯¹æ¯”
	if memoryResult.Throughput > 0 && diskResult.Throughput > 0 {
		impact := (memoryResult.Throughput - diskResult.Throughput) / memoryResult.Throughput * 100
		t.Logf("   ğŸ“Š JetStream Disk persistence impact: %.1f%% throughput reduction vs Memory", impact)
	}

	// èµ„æºæ•ˆç‡å¯¹æ¯”
	if kafkaResult.MemoryDeltaMB > 0 && diskResult.MemoryDeltaMB > 0 {
		if kafkaResult.MemoryDeltaMB < diskResult.MemoryDeltaMB {
			ratio := diskResult.MemoryDeltaMB / kafkaResult.MemoryDeltaMB
			t.Logf("   âœ… Kafka wins in memory efficiency: %.1fx less memory (%.2f vs %.2f MB)",
				ratio, kafkaResult.MemoryDeltaMB, diskResult.MemoryDeltaMB)
		}
	}
}

// generateJetStreamFinalReport ç”ŸæˆJetStreamæœ€ç»ˆæŠ¥å‘Š
func generateJetStreamFinalReport(t *testing.T, allResults map[string][]*JetStreamPerformanceMetrics) {
	t.Logf("\nğŸ† ===== EVENTBUS + NATS JETSTREAM FINAL PERFORMANCE REPORT =====")

	// æ€§èƒ½è¡¨æ ¼
	t.Logf("\nğŸ“Š Detailed Performance Metrics Table:")
	t.Logf("Load       | System           | Storage | Messages | Success    | Send Rate    | Throughput | First Latency | Avg Latency")
	t.Logf("-----------+------------------+---------+----------+------------+--------------+------------+---------------+-------------")

	scenarios := []string{"Light", "Medium", "Heavy", "Extreme"}
	systems := []string{"JetStream-Memory", "JetStream-Disk", "Kafka-Disk"}

	for i, scenario := range scenarios {
		for _, system := range systems {
			if i < len(allResults[system]) {
				result := allResults[system][i]
				t.Logf("%-10s | %-16s | %-7s | %8d | %9.1f%% | %11.1f/s | %9.1f/s | %12v | %10v",
					scenario, result.System, result.StorageMode, result.Messages,
					result.SuccessRate, result.SendRate, result.Throughput,
					result.FirstLatency, result.AverageLatency)
			}
		}
		if i < len(scenarios)-1 {
			t.Logf("           +                  +         +          +            +              +            +               +")
		}
	}

	// èµ„æºä½¿ç”¨åˆ†æ
	t.Logf("\nğŸ’¾ Resource Usage Analysis:")
	t.Logf("Load       | System           | Storage | Goroutines   | Memory(MB)   | Network Sent | Network Recv")
	t.Logf("-----------+------------------+---------+--------------+--------------+--------------+--------------")

	for i, scenario := range scenarios {
		for _, system := range systems {
			if i < len(allResults[system]) {
				result := allResults[system][i]
				t.Logf("%-10s | %-16s | %-7s | %8d(+%d) | %8.2f(+%.2f) | %11.2f MB | %11.2f MB",
					scenario, result.System, result.StorageMode,
					result.PeakGoroutines, result.GoroutineDelta,
					result.PeakMemoryMB, result.MemoryDeltaMB,
					float64(result.BytesSent)/1024/1024, float64(result.BytesReceived)/1024/1024)
			}
		}
		if i < len(scenarios)-1 {
			t.Logf("           +                  +         +              +              +              +")
		}
	}

	// è®¡ç®—å¹³å‡æ€§èƒ½
	avgMetrics := make(map[string]*JetStreamPerformanceMetrics)
	for system, results := range allResults {
		if len(results) == 0 {
			continue
		}

		avg := &JetStreamPerformanceMetrics{
			System:      results[0].System,
			StorageMode: results[0].StorageMode,
		}

		var totalSuccess, totalThroughput, totalSendRate float64
		var totalFirstLatency, totalAvgLatency time.Duration
		var totalMemory, totalGoroutines float64
		validResults := 0

		for _, result := range results {
			if result.SuccessRate > 0 {
				totalSuccess += result.SuccessRate
				totalThroughput += result.Throughput
				totalSendRate += result.SendRate
				totalFirstLatency += result.FirstLatency
				totalAvgLatency += result.AverageLatency
				totalMemory += result.MemoryDeltaMB
				totalGoroutines += float64(result.GoroutineDelta)
				validResults++
			}
		}

		if validResults > 0 {
			avg.SuccessRate = totalSuccess / float64(validResults)
			avg.Throughput = totalThroughput / float64(validResults)
			avg.SendRate = totalSendRate / float64(validResults)
			avg.FirstLatency = totalFirstLatency / time.Duration(validResults)
			avg.AverageLatency = totalAvgLatency / time.Duration(validResults)
			avg.MemoryDeltaMB = totalMemory / float64(validResults)
			avg.GoroutineDelta = int(totalGoroutines / float64(validResults))
			avgMetrics[system] = avg
		}
	}

	// æ€§èƒ½å¯¹æ¯”åˆ†æ
	t.Logf("\nğŸ” EventBus Performance Analysis:")

	jetStreamMemory := avgMetrics["JetStream-Memory"]
	jetStreamDisk := avgMetrics["JetStream-Disk"]
	kafka := avgMetrics["Kafka-Disk"]

	if jetStreamMemory != nil && kafka != nil {
		t.Logf("ğŸ“Š JetStream Memory vs Kafka:")
		if jetStreamMemory.SuccessRate > 0 && kafka.SuccessRate > 0 {
			reliabilityRatio := jetStreamMemory.SuccessRate / kafka.SuccessRate
			throughputRatio := jetStreamMemory.Throughput / kafka.Throughput
			latencyRatio := float64(kafka.FirstLatency.Nanoseconds()) / float64(jetStreamMemory.FirstLatency.Nanoseconds())

			t.Logf("   ğŸ›¡ï¸  Reliability: %.2fx (%.1f%% vs %.1f%%)", reliabilityRatio, jetStreamMemory.SuccessRate, kafka.SuccessRate)
			t.Logf("   ğŸš€ Throughput: %.2fx (%.1f vs %.1f msg/s)", throughputRatio, jetStreamMemory.Throughput, kafka.Throughput)
			t.Logf("   â±ï¸  Latency: %.2fx faster (%v vs %v)", latencyRatio, jetStreamMemory.FirstLatency, kafka.FirstLatency)
			t.Logf("   ğŸ’¾ Memory: %.2fx more (%.2f vs %.2f MB)", jetStreamMemory.MemoryDeltaMB/kafka.MemoryDeltaMB, jetStreamMemory.MemoryDeltaMB, kafka.MemoryDeltaMB)
		}
	}

	if jetStreamDisk != nil && kafka != nil {
		t.Logf("ğŸ“Š JetStream Disk vs Kafka:")
		if jetStreamDisk.SuccessRate > 0 && kafka.SuccessRate > 0 {
			reliabilityRatio := jetStreamDisk.SuccessRate / kafka.SuccessRate
			throughputRatio := jetStreamDisk.Throughput / kafka.Throughput
			latencyRatio := float64(kafka.FirstLatency.Nanoseconds()) / float64(jetStreamDisk.FirstLatency.Nanoseconds())

			t.Logf("   ğŸ›¡ï¸  Reliability: %.2fx (%.1f%% vs %.1f%%)", reliabilityRatio, jetStreamDisk.SuccessRate, kafka.SuccessRate)
			t.Logf("   ğŸš€ Throughput: %.2fx (%.1f vs %.1f msg/s)", throughputRatio, jetStreamDisk.Throughput, kafka.Throughput)
			t.Logf("   â±ï¸  Latency: %.2fx faster (%v vs %v)", latencyRatio, jetStreamDisk.FirstLatency, kafka.FirstLatency)
			t.Logf("   ğŸ’¾ Memory: %.2fx more (%.2f vs %.2f MB)", jetStreamDisk.MemoryDeltaMB/kafka.MemoryDeltaMB, jetStreamDisk.MemoryDeltaMB, kafka.MemoryDeltaMB)
		}
	}

	if jetStreamMemory != nil && jetStreamDisk != nil {
		t.Logf("ğŸ“Š JetStream Memory vs Disk:")
		if jetStreamMemory.SuccessRate > 0 && jetStreamDisk.SuccessRate > 0 {
			persistenceImpact := (jetStreamMemory.Throughput - jetStreamDisk.Throughput) / jetStreamMemory.Throughput * 100
			latencyImpact := (jetStreamDisk.FirstLatency.Nanoseconds() - jetStreamMemory.FirstLatency.Nanoseconds()) / jetStreamMemory.FirstLatency.Nanoseconds() * 100

			t.Logf("   ğŸ“Š Disk persistence impact: %.1f%% throughput reduction", persistenceImpact)
			t.Logf("   â±ï¸  Disk persistence impact: %.1f%% latency increase", float64(latencyImpact))
		}
	}

	// æœ€ç»ˆç»“è®º
	t.Logf("\nğŸ† FINAL EVENTBUS PERFORMANCE VERDICT:")

	// ç¡®å®šè·èƒœè€…
	var winner string
	var winnerScore float64

	if jetStreamMemory != nil && jetStreamMemory.SuccessRate > 0 {
		score := jetStreamMemory.SuccessRate*0.3 + jetStreamMemory.Throughput*0.5 + (1000.0/float64(jetStreamMemory.FirstLatency.Milliseconds()))*0.2
		if score > winnerScore {
			winnerScore = score
			winner = "ğŸŸ¡ EventBus + NATS JetStream Memory"
		}
	}

	if jetStreamDisk != nil && jetStreamDisk.SuccessRate > 0 {
		score := jetStreamDisk.SuccessRate*0.3 + jetStreamDisk.Throughput*0.5 + (1000.0/float64(jetStreamDisk.FirstLatency.Milliseconds()))*0.2
		if score > winnerScore {
			winnerScore = score
			winner = "ğŸŸ  EventBus + NATS JetStream Disk"
		}
	}

	if kafka != nil && kafka.SuccessRate > 0 {
		score := kafka.SuccessRate*0.3 + kafka.Throughput*0.5 + (1000.0/float64(kafka.FirstLatency.Milliseconds()))*0.2
		if score > winnerScore {
			winnerScore = score
			winner = "ğŸ”´ EventBus + Kafka"
		}
	}

	if winner != "" {
		t.Logf("ğŸ¥‡ WINNER: %s", winner)
		t.Logf("ğŸ“Š Performance Score: %.2f", winnerScore)
	}

	// ä½¿ç”¨åœºæ™¯å»ºè®®
	t.Logf("\nğŸ’¡ EventBus Implementation Recommendations:")

	if jetStreamMemory != nil && jetStreamMemory.SuccessRate > 80 {
		t.Logf("ğŸŸ¡ Choose EventBus + NATS JetStream Memory when:")
		t.Logf("   âœ… You need maximum performance (%.1f msg/s avg throughput)", jetStreamMemory.Throughput)
		t.Logf("   âœ… You require ultra-low latency (%v avg latency)", jetStreamMemory.FirstLatency)
		t.Logf("   âœ… You can accept memory-only persistence")
		t.Logf("   âœ… You're building real-time applications")
		t.Logf("   âœ… You have sufficient memory resources")
	}

	if jetStreamDisk != nil && jetStreamDisk.SuccessRate > 80 {
		t.Logf("ğŸŸ  Choose EventBus + NATS JetStream Disk when:")
		t.Logf("   âœ… You need high performance with persistence (%.1f msg/s avg throughput)", jetStreamDisk.Throughput)
		t.Logf("   âœ… You require low latency (%v avg latency)", jetStreamDisk.FirstLatency)
		t.Logf("   âœ… You need durable message storage")
		t.Logf("   âœ… You want modern cloud-native architecture")
		t.Logf("   âœ… You prefer simpler deployment than Kafka")
	}

	if kafka != nil && kafka.SuccessRate > 70 {
		t.Logf("ğŸ”´ Choose EventBus + Kafka when:")
		t.Logf("   âœ… You need enterprise-grade reliability (%.1f%% avg success rate)", kafka.SuccessRate)
		t.Logf("   âœ… You require mature ecosystem and tooling")
		t.Logf("   âœ… You have complex data processing pipelines")
		t.Logf("   âœ… You need guaranteed message persistence")
		t.Logf("   âœ… You're building data-intensive applications")
		t.Logf("   âœ… You have existing Kafka expertise")
	}

	// æ€§èƒ½åŸºå‡†
	t.Logf("\nğŸ“‹ EventBus Performance Benchmarks for Your Environment:")

	if jetStreamMemory != nil {
		t.Logf("ğŸŸ¡ EventBus + JetStream Memory Expected Performance:")
		t.Logf("   ğŸ“Š Throughput: %.1f msg/s", jetStreamMemory.Throughput)
		t.Logf("   â±ï¸  Latency: %v", jetStreamMemory.FirstLatency)
		t.Logf("   ğŸ’¾ Memory: %.2f MB per test", jetStreamMemory.MemoryDeltaMB)
		t.Logf("   ğŸ›¡ï¸  Reliability: %.1f%% success rate", jetStreamMemory.SuccessRate)
	}

	if jetStreamDisk != nil {
		t.Logf("ğŸŸ  EventBus + JetStream Disk Expected Performance:")
		t.Logf("   ğŸ“Š Throughput: %.1f msg/s", jetStreamDisk.Throughput)
		t.Logf("   â±ï¸  Latency: %v", jetStreamDisk.FirstLatency)
		t.Logf("   ğŸ’¾ Memory: %.2f MB per test", jetStreamDisk.MemoryDeltaMB)
		t.Logf("   ğŸ›¡ï¸  Reliability: %.1f%% success rate", jetStreamDisk.SuccessRate)
	}

	if kafka != nil {
		t.Logf("ğŸ”´ EventBus + Kafka Expected Performance:")
		t.Logf("   ğŸ“Š Throughput: %.1f msg/s", kafka.Throughput)
		t.Logf("   â±ï¸  Latency: %v", kafka.FirstLatency)
		t.Logf("   ğŸ’¾ Memory: %.2f MB per test", kafka.MemoryDeltaMB)
		t.Logf("   ğŸ›¡ï¸  Reliability: %.1f%% success rate", kafka.SuccessRate)
	}

	t.Logf("\nğŸ¯ EVENTBUS + NATS JETSTREAM PERFORMANCE TEST COMPLETED!")
	t.Logf("ğŸ“Š Total tests run: 4 scenarios Ã— 3 systems = 12 tests")
	t.Logf("ğŸ”¬ Metrics collected: Performance, Reliability, Resource Usage, Persistence Impact")
	t.Logf("ğŸ’¾ Persistence modes tested: Memory, Disk")
}
