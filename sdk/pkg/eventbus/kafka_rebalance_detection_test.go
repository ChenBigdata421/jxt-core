package eventbus

import (
	"context"
	"encoding/json"
	"fmt"
	"sync"
	"sync/atomic"
	"testing"
	"time"

	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

// ğŸ¯ Kafkaå†å¹³è¡¡ç°è±¡æ£€æµ‹æµ‹è¯•
// ä¸“é—¨æ£€æµ‹ç»Ÿä¸€Consumeræ¶æ„æ˜¯å¦è§£å†³äº†å†å¹³è¡¡é—®é¢˜

// RebalanceDetectionMetrics å†å¹³è¡¡æ£€æµ‹æŒ‡æ ‡
type RebalanceDetectionMetrics struct {
	// æ¶ˆæ¯å¤„ç†æŒ‡æ ‡
	MessagesSent       int64 // å‘é€æ¶ˆæ¯æ€»æ•°
	MessagesReceived   int64 // æ¥æ”¶æ¶ˆæ¯æ€»æ•°
	ProcessingGaps     int64 // å¤„ç†é—´éš™æ¬¡æ•° (å¯èƒ½çš„å†å¹³è¡¡)
	
	// æ—¶é—´æŒ‡æ ‡
	StartTime          time.Time
	EndTime            time.Time
	LastMessageTime    time.Time
	MaxGapDuration     time.Duration // æœ€å¤§å¤„ç†é—´éš™
	
	// å†å¹³è¡¡æ£€æµ‹
	SuspectedRebalances int64 // ç–‘ä¼¼å†å¹³è¡¡æ¬¡æ•°
	ConnectionLosses    int64 // è¿æ¥ä¸¢å¤±æ¬¡æ•°
	
	// æ¶ˆæ¯é¡ºåº
	OrderViolations    int64 // é¡ºåºè¿åæ¬¡æ•°
	DuplicateMessages  int64 // é‡å¤æ¶ˆæ¯æ¬¡æ•°
}

// RebalanceTestMessage å†å¹³è¡¡æµ‹è¯•æ¶ˆæ¯
type RebalanceTestMessage struct {
	ID        string    `json:"id"`
	Topic     string    `json:"topic"`
	Sequence  int64     `json:"sequence"`
	Timestamp time.Time `json:"timestamp"`
	Data      string    `json:"data"`
}

// TestKafkaRebalanceDetection Kafkaå†å¹³è¡¡æ£€æµ‹æµ‹è¯•
func TestKafkaRebalanceDetection(t *testing.T) {
	if testing.Short() {
		t.Skip("Skipping Kafka rebalance detection test in short mode")
	}

	metrics := &RebalanceDetectionMetrics{
		StartTime: time.Now(),
	}

	// åˆ›å»ºKafka EventBusé…ç½® (ä½¿ç”¨åŸºå‡†æµ‹è¯•ç«¯å£)
	kafkaConfig := &KafkaConfig{
		Brokers: []string{"localhost:29093"},
		Producer: ProducerConfig{
			RequiredAcks:     1,
			Compression:      "none",
			FlushFrequency:   10 * time.Millisecond,
			FlushMessages:    50,
			Timeout:          10 * time.Second,
			FlushBytes:       1024 * 1024,
			RetryMax:         3,
			BatchSize:        16 * 1024,
			BufferSize:       32 * 1024 * 1024,
			Idempotent:       false,
			MaxMessageBytes:  1024 * 1024,
			PartitionerType:  "hash",
			LingerMs:         5 * time.Millisecond,
			CompressionLevel: 6,
			MaxInFlight:      5,
		},
		Consumer: ConsumerConfig{
			GroupID:            "rebalance-detection-group",
			AutoOffsetReset:    "earliest",
			SessionTimeout:     30 * time.Second, // å¢åŠ è¶…æ—¶ä»¥å‡å°‘å†å¹³è¡¡
			HeartbeatInterval:  10 * time.Second, // å¢åŠ å¿ƒè·³é—´éš”
			MaxProcessingTime:  60 * time.Second,
			FetchMinBytes:      1024,
			FetchMaxBytes:      50 * 1024 * 1024,
			FetchMaxWait:       500 * time.Millisecond,
			MaxPollRecords:     100, // å‡å°‘æ‰¹é‡å¤§å°
			EnableAutoCommit:   false,
			AutoCommitInterval: 5 * time.Second,
			IsolationLevel:     "read_committed",
			RebalanceStrategy:  "range", // ä½¿ç”¨rangeç­–ç•¥
		},
		HealthCheckInterval:  30 * time.Second,
		ClientID:             "rebalance-detection-client",
		MetadataRefreshFreq:  10 * time.Minute,
		MetadataRetryMax:     3,
		MetadataRetryBackoff: 250 * time.Millisecond,
		Net: NetConfig{
			DialTimeout:  30 * time.Second,
			ReadTimeout:  30 * time.Second,
			WriteTimeout: 30 * time.Second,
			KeepAlive:    30 * time.Second,
			MaxIdleConns: 10,
			MaxOpenConns: 100,
		},
	}

	eventBus, err := NewKafkaEventBus(kafkaConfig)
	require.NoError(t, err, "Failed to create Kafka EventBus")
	defer eventBus.Close()

	// ç­‰å¾…è¿æ¥å»ºç«‹
	time.Sleep(5 * time.Second)

	t.Logf("ğŸ” Starting Kafka Rebalance Detection Test")
	
	// è¿è¡Œå†å¹³è¡¡æ£€æµ‹æµ‹è¯•
	runRebalanceDetectionTest(t, eventBus, metrics)

	// åˆ†æç»“æœ
	analyzeRebalanceResults(t, metrics)
}

// runRebalanceDetectionTest è¿è¡Œå†å¹³è¡¡æ£€æµ‹æµ‹è¯•
func runRebalanceDetectionTest(t *testing.T, eventBus EventBus, metrics *RebalanceDetectionMetrics) {
	ctx, cancel := context.WithTimeout(context.Background(), 60*time.Second)
	defer cancel()

	// åˆ›å»ºæµ‹è¯•topic
	topics := []string{
		"rebalance.detection.topic.1",
		"rebalance.detection.topic.2",
		"rebalance.detection.topic.3",
	}

	// è®¾ç½®æ¶ˆæ¯å¤„ç†å™¨ (æ£€æµ‹å†å¹³è¡¡)
	var wg sync.WaitGroup
	setupRebalanceDetectionHandlers(t, eventBus, topics, metrics, &wg)

	// ç­‰å¾…è®¢é˜…å»ºç«‹
	time.Sleep(3 * time.Second)

	// å¼€å§‹å‘é€æ¶ˆæ¯
	metrics.StartTime = time.Now()
	sendRebalanceDetectionMessages(t, eventBus, topics, metrics)

	// ç­‰å¾…æ¶ˆæ¯å¤„ç†å®Œæˆ
	done := make(chan struct{})
	go func() {
		wg.Wait()
		close(done)
	}()

	select {
	case <-done:
		t.Logf("âœ… All messages processed")
	case <-time.After(45 * time.Second):
		t.Logf("â° Test timeout reached")
	case <-ctx.Done():
		t.Logf("ğŸ›‘ Context cancelled")
	}

	metrics.EndTime = time.Now()
}

// setupRebalanceDetectionHandlers è®¾ç½®å†å¹³è¡¡æ£€æµ‹å¤„ç†å™¨
func setupRebalanceDetectionHandlers(t *testing.T, eventBus EventBus, topics []string, metrics *RebalanceDetectionMetrics, wg *sync.WaitGroup) {
	for _, topic := range topics {
		wg.Add(1)
		go func(topicName string) {
			defer wg.Done()
			
			var lastSequence int64 = -1
			var lastProcessTime time.Time = time.Now()
			
			handler := func(ctx context.Context, message []byte) error {
				currentTime := time.Now()
				
				// æ£€æµ‹å¤„ç†é—´éš™ (å¯èƒ½çš„å†å¹³è¡¡)
				if !lastProcessTime.IsZero() {
					gap := currentTime.Sub(lastProcessTime)
					if gap > 5*time.Second { // è¶…è¿‡5ç§’è®¤ä¸ºæ˜¯å¼‚å¸¸é—´éš™
						atomic.AddInt64(&metrics.ProcessingGaps, 1)
						if gap > 10*time.Second { // è¶…è¿‡10ç§’è®¤ä¸ºæ˜¯å†å¹³è¡¡
							atomic.AddInt64(&metrics.SuspectedRebalances, 1)
							t.Logf("ğŸš¨ Suspected rebalance detected: %v gap in topic %s", gap, topicName)
						}
						
						// æ›´æ–°æœ€å¤§é—´éš™
						if gap > metrics.MaxGapDuration {
							metrics.MaxGapDuration = gap
						}
					}
				}
				lastProcessTime = currentTime
				
				// è§£ææ¶ˆæ¯
				var testMsg RebalanceTestMessage
				if err := json.Unmarshal(message, &testMsg); err != nil {
					return err
				}
				
				// æ£€æµ‹é¡ºåºè¿å
				if lastSequence >= 0 && testMsg.Sequence <= lastSequence {
					atomic.AddInt64(&metrics.OrderViolations, 1)
					t.Logf("âš ï¸ Order violation in topic %s: expected > %d, got %d", 
						topicName, lastSequence, testMsg.Sequence)
				}
				lastSequence = testMsg.Sequence
				
				// æ›´æ–°æ¥æ”¶è®¡æ•°
				atomic.AddInt64(&metrics.MessagesReceived, 1)
				metrics.LastMessageTime = currentTime
				
				return nil
			}
			
			err := eventBus.Subscribe(context.Background(), topicName, handler)
			if err != nil {
				atomic.AddInt64(&metrics.ConnectionLosses, 1)
				t.Errorf("Failed to subscribe to topic %s: %v", topicName, err)
			}
		}(topic)
	}
}

// sendRebalanceDetectionMessages å‘é€å†å¹³è¡¡æ£€æµ‹æ¶ˆæ¯
func sendRebalanceDetectionMessages(t *testing.T, eventBus EventBus, topics []string, metrics *RebalanceDetectionMetrics) {
	var sendWg sync.WaitGroup
	messagesPerTopic := 200 // æ¯ä¸ªtopicå‘é€200æ¡æ¶ˆæ¯
	
	for _, topic := range topics {
		sendWg.Add(1)
		go func(topicName string) {
			defer sendWg.Done()
			
			for i := 0; i < messagesPerTopic; i++ {
				testMsg := RebalanceTestMessage{
					ID:        fmt.Sprintf("%s-%d", topicName, i),
					Topic:     topicName,
					Sequence:  int64(i),
					Timestamp: time.Now(),
					Data:      fmt.Sprintf("rebalance-test-data-%d", i),
				}
				
				messageBytes, err := json.Marshal(testMsg)
				if err != nil {
					continue
				}
				
				err = eventBus.Publish(context.Background(), topicName, messageBytes)
				if err != nil {
					t.Logf("âŒ Failed to send message to %s: %v", topicName, err)
				} else {
					atomic.AddInt64(&metrics.MessagesSent, 1)
				}
				
				// æ§åˆ¶å‘é€é€Ÿç‡
				if i%20 == 0 {
					time.Sleep(100 * time.Millisecond)
				}
			}
		}(topic)
	}
	
	sendWg.Wait()
	t.Logf("ğŸ“¤ Finished sending rebalance detection messages")
}

// analyzeRebalanceResults åˆ†æå†å¹³è¡¡ç»“æœ
func analyzeRebalanceResults(t *testing.T, metrics *RebalanceDetectionMetrics) {
	duration := metrics.EndTime.Sub(metrics.StartTime)
	successRate := float64(metrics.MessagesReceived) / float64(metrics.MessagesSent) * 100
	
	t.Logf("\nğŸ” ===== Kafka Rebalance Detection Results =====")
	t.Logf("â±ï¸  Test Duration: %v", duration)
	t.Logf("ğŸ“¤ Messages Sent: %d", metrics.MessagesSent)
	t.Logf("ğŸ“¥ Messages Received: %d", metrics.MessagesReceived)
	t.Logf("âœ… Success Rate: %.2f%%", successRate)
	
	t.Logf("\nğŸš¨ Rebalance Detection:")
	t.Logf("   Processing Gaps (>5s): %d", metrics.ProcessingGaps)
	t.Logf("   Suspected Rebalances (>10s): %d", metrics.SuspectedRebalances)
	t.Logf("   Max Gap Duration: %v", metrics.MaxGapDuration)
	t.Logf("   Connection Losses: %d", metrics.ConnectionLosses)
	
	t.Logf("\nâš ï¸ Message Order Issues:")
	t.Logf("   Order Violations: %d", metrics.OrderViolations)
	t.Logf("   Duplicate Messages: %d", metrics.DuplicateMessages)
	
	// è¯„ä¼°å†å¹³è¡¡æƒ…å†µ
	if metrics.SuspectedRebalances == 0 {
		t.Logf("\nâœ… ä¼˜ç§€! æœªæ£€æµ‹åˆ°æ˜æ˜¾çš„å†å¹³è¡¡ç°è±¡")
	} else if metrics.SuspectedRebalances <= 2 {
		t.Logf("\nâš ï¸ æ£€æµ‹åˆ°å°‘é‡å†å¹³è¡¡ç°è±¡ (%dæ¬¡)", metrics.SuspectedRebalances)
	} else {
		t.Logf("\nâŒ æ£€æµ‹åˆ°é¢‘ç¹çš„å†å¹³è¡¡ç°è±¡ (%dæ¬¡)", metrics.SuspectedRebalances)
	}
	
	// åŸºæœ¬éªŒè¯
	assert.Greater(t, metrics.MessagesSent, int64(0), "Should send messages")
	assert.Greater(t, metrics.MessagesReceived, int64(0), "Should receive messages")
	assert.Greater(t, successRate, 80.0, "Success rate should be > 80%")
	assert.LessOrEqual(t, metrics.SuspectedRebalances, int64(3), "Should have minimal rebalances")
	
	t.Logf("âœ… Kafka Rebalance Detection Test Completed!")
}
