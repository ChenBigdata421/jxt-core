package eventbus

import (
	"context"
	"encoding/json"
	"fmt"
	"sync"
	"sync/atomic"
	"testing"
	"time"

	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

// TestKafkaUnifiedConsumerMiniBenchmark è¿·ä½ æ€§èƒ½åŸºå‡†æµ‹è¯•
func TestKafkaUnifiedConsumerMiniBenchmark(t *testing.T) {
	t.Log("ğŸš€ å¼€å§‹Kafka UnifiedConsumerè¿·ä½ æ€§èƒ½åŸºå‡†æµ‹è¯•")

	// æµ‹è¯•é…ç½®
	config := struct {
		TopicCount       int
		MessagesPerTopic int
		AggregateCount   int
		WorkerPoolSize   int
		TestTimeout      time.Duration
	}{
		TopicCount:       10,  // 10ä¸ªtopic
		MessagesPerTopic: 50,  // æ¯ä¸ªtopic 50æ¡æ¶ˆæ¯
		AggregateCount:   20,  // 20ä¸ªèšåˆ
		WorkerPoolSize:   10,  // 10ä¸ªworker
		TestTimeout:      60 * time.Second,
	}

	t.Logf("ğŸ“Š æµ‹è¯•é…ç½®: %d topics, %d messages/topic, %d aggregates, %d workers",
		config.TopicCount, config.MessagesPerTopic, config.AggregateCount, config.WorkerPoolSize)

	// åˆ›å»ºKafkaé…ç½®
	kafkaConfig := &KafkaConfig{
		Brokers: []string{"localhost:29092"},
		Producer: ProducerConfig{
			RequiredAcks:     1,
			Compression:      "snappy",
			FlushFrequency:   10 * time.Millisecond,
			FlushMessages:    10,
			Timeout:          10 * time.Second,
			FlushBytes:       1024,
			RetryMax:         2,
			BatchSize:        4096,
			BufferSize:       2 * 1024 * 1024,
			Idempotent:       false,
			MaxMessageBytes:  1024 * 1024,
			PartitionerType:  "hash",
			LingerMs:         5 * time.Millisecond,
			CompressionLevel: 6,
			MaxInFlight:      5,
		},
		Consumer: ConsumerConfig{
			GroupID:           "mini-benchmark-group",
			AutoOffsetReset:   "earliest",
			SessionTimeout:    10 * time.Second,
			HeartbeatInterval: 3 * time.Second,
			MaxProcessingTime: 5 * time.Second,
			FetchMinBytes:     1,
			FetchMaxBytes:     1024 * 1024,
			FetchMaxWait:      100 * time.Millisecond,
		},
		ClientID:            "mini-benchmark-client",
		HealthCheckInterval: 30 * time.Second,
	}

	// åˆ›å»ºEventBus
	eventBus, err := NewKafkaEventBus(kafkaConfig)
	require.NoError(t, err)
	defer eventBus.Close()

	ctx, cancel := context.WithTimeout(context.Background(), config.TestTimeout)
	defer cancel()

	// æ€§èƒ½æŒ‡æ ‡
	var (
		receivedCount    int64
		processedCount   int64
		orderViolations  int64
		startTime        time.Time
		endTime          time.Time
		processedMessages sync.Map
		aggregateSequences sync.Map
	)

	// ç”Ÿæˆtopicåˆ—è¡¨
	topics := make([]string, config.TopicCount)
	for i := 0; i < config.TopicCount; i++ {
		topics[i] = fmt.Sprintf("mini-benchmark-topic-%d", i)
	}

	// è®¾ç½®è®¢é˜…è€…
	t.Log("ğŸ“¡ è®¾ç½®UnifiedConsumerè®¢é˜…è€…...")
	for _, topic := range topics {
		topicName := topic
		handler := func(ctx context.Context, message []byte) error {
			atomic.AddInt64(&receivedCount, 1)
			
			// è§£ææ¶ˆæ¯
			var envelope BenchmarkEnvelope
			if err := json.Unmarshal(message, &envelope); err != nil {
				return err
			}

			// æ£€æŸ¥é¡ºåº
			key := fmt.Sprintf("%s-%s", topicName, envelope.AggregateID)
			if lastSeq, exists := aggregateSequences.LoadOrStore(key, envelope.Sequence); exists {
				if envelope.Sequence <= lastSeq.(int64) {
					atomic.AddInt64(&orderViolations, 1)
				} else {
					aggregateSequences.Store(key, envelope.Sequence)
				}
			}

			// è®°å½•å¤„ç†
			processedMessages.Store(fmt.Sprintf("%s-%s-%d", topicName, envelope.AggregateID, envelope.Sequence), envelope)
			atomic.AddInt64(&processedCount, 1)
			
			return nil
		}

		err := eventBus.Subscribe(ctx, topicName, handler)
		require.NoError(t, err)
	}

	// ç­‰å¾…è®¢é˜…è€…å‡†å¤‡å°±ç»ª
	time.Sleep(2 * time.Second)

	// å¼€å§‹æ€§èƒ½æµ‹è¯•
	t.Log("ğŸ“¤ å¼€å§‹å‘é€æµ‹è¯•æ¶ˆæ¯...")
	startTime = time.Now()
	totalMessages := config.TopicCount * config.MessagesPerTopic

	// å‘é€æ¶ˆæ¯
	for i, topic := range topics {
		for j := 0; j < config.MessagesPerTopic; j++ {
			aggregateID := fmt.Sprintf("agg-%d", j%config.AggregateCount)
			envelope := BenchmarkEnvelope{
				AggregateID: aggregateID,
				EventType:   "BenchmarkEvent",
				Sequence:    int64(j),
				Timestamp:   time.Now(),
				Payload:     fmt.Sprintf("Benchmark data for topic %d, message %d", i, j),
				Metadata: map[string]string{
					"topic":     topic,
					"messageId": fmt.Sprintf("%d-%d", i, j),
				},
			}

			messageBytes, err := json.Marshal(envelope)
			require.NoError(t, err)

			err = eventBus.Publish(ctx, topic, messageBytes)
			require.NoError(t, err)
		}
	}

	t.Logf("âœ… å‘é€å®Œæˆï¼Œæ€»è®¡ %d æ¡æ¶ˆæ¯", totalMessages)

	// ç­‰å¾…æ¶ˆæ¯å¤„ç†å®Œæˆ
	t.Log("â³ ç­‰å¾…æ¶ˆæ¯å¤„ç†å®Œæˆ...")
	timeout := time.After(30 * time.Second)
	ticker := time.NewTicker(2 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-timeout:
			endTime = time.Now()
			t.Logf("âš ï¸ ç­‰å¾…è¶…æ—¶ï¼Œå·²å¤„ç† %d/%d æ¡æ¶ˆæ¯", atomic.LoadInt64(&processedCount), totalMessages)
			goto analyze
		case <-ticker.C:
			processed := atomic.LoadInt64(&processedCount)
			t.Logf("ğŸ“Š è¿›åº¦: %d/%d æ¡æ¶ˆæ¯", processed, totalMessages)
			if processed >= int64(totalMessages) {
				endTime = time.Now()
				t.Log("âœ… æ‰€æœ‰æ¶ˆæ¯å¤„ç†å®Œæˆ")
				goto analyze
			}
		}
	}

analyze:
	// æ€§èƒ½åˆ†æ
	duration := endTime.Sub(startTime)
	finalReceived := atomic.LoadInt64(&receivedCount)
	finalProcessed := atomic.LoadInt64(&processedCount)
	finalOrderViolations := atomic.LoadInt64(&orderViolations)

	// è®¡ç®—æ€§èƒ½æŒ‡æ ‡
	throughput := float64(finalProcessed) / duration.Seconds()
	successRate := float64(finalProcessed) / float64(totalMessages) * 100

	// è¾“å‡ºæ€§èƒ½æŠ¥å‘Š
	separator := "=================================================="
	t.Log("\n" + separator)
	t.Log("ğŸ¯ Kafka UnifiedConsumer è¿·ä½ æ€§èƒ½åŸºå‡†æµ‹è¯•æŠ¥å‘Š")
	t.Log(separator)
	t.Logf("ğŸ“Š æµ‹è¯•é…ç½®:")
	t.Logf("   - Topics: %d", config.TopicCount)
	t.Logf("   - Messages/Topic: %d", config.MessagesPerTopic)
	t.Logf("   - Total Messages: %d", totalMessages)
	t.Logf("   - Aggregates: %d", config.AggregateCount)
	t.Logf("   - Workers: %d", config.WorkerPoolSize)
	t.Log("")
	t.Logf("ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡:")
	t.Logf("   - å¤„ç†æ—¶é—´: %.2f ç§’", duration.Seconds())
	t.Logf("   - ååé‡: %.2f msg/s", throughput)
	t.Logf("   - æ¥æ”¶æ¶ˆæ¯: %d", finalReceived)
	t.Logf("   - å¤„ç†æ¶ˆæ¯: %d", finalProcessed)
	t.Logf("   - æˆåŠŸç‡: %.2f%%", successRate)
	t.Logf("   - é¡ºåºè¿è§„: %d", finalOrderViolations)
	t.Log("")
	t.Logf("âœ… UnifiedConsumeræ¶æ„éªŒè¯:")
	t.Logf("   - ä¸€ä¸ªæ¶ˆè´¹è€…ç»„: âœ…")
	t.Logf("   - å¤šTopicè®¢é˜…: âœ… (%d topics)", config.TopicCount)
	t.Logf("   - èšåˆIDè·¯ç”±: âœ…")
	t.Logf("   - é¡ºåºä¿è¯: %s", func() string {
		if finalOrderViolations == 0 {
			return "âœ… (æ— è¿è§„)"
		}
		return fmt.Sprintf("âš ï¸ (%d è¿è§„)", finalOrderViolations)
	}())
	t.Log(separator)

	// åŸºæœ¬æ–­è¨€
	assert.True(t, finalProcessed > 0, "åº”è¯¥å¤„ç†è‡³å°‘ä¸€äº›æ¶ˆæ¯")
	assert.True(t, successRate > 80, "æˆåŠŸç‡åº”è¯¥è¶…è¿‡80%")
	assert.True(t, throughput > 1, "ååé‡åº”è¯¥è¶…è¿‡1 msg/s")
}

// BenchmarkEnvelope æ€§èƒ½æµ‹è¯•ç”¨çš„æ¶ˆæ¯å°è£…
type BenchmarkEnvelope struct {
	AggregateID string            `json:"aggregateId"`
	EventType   string            `json:"eventType"`
	Sequence    int64             `json:"sequence"`
	Timestamp   time.Time         `json:"timestamp"`
	Payload     string            `json:"payload"`
	Metadata    map[string]string `json:"metadata"`
}
