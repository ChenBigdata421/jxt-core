# jxt-core EventBus è¿ç§»åˆ° Hollywood Actor Pool æ–¹æ¡ˆ

## ğŸ¯ **æ ¸å¿ƒè®¾è®¡ç†å¿µ**

### å…³é”®çº¦æŸ
- âœ… **åƒä¸‡çº§èšåˆID**: ä¸èƒ½ä¸ºæ¯ä¸ªèšåˆIDåˆ›å»ºç‹¬ç«‹Actor
- âœ… **å›ºå®š Actor Pool**: ç±»ä¼¼ Keyed Worker Pool,ä½¿ç”¨å›ºå®šæ•°é‡çš„Actor
- âœ… **å•æœºéƒ¨ç½²**: æ¯ä¸ªå¾®æœåŠ¡ç‹¬ç«‹çš„Actor Pool,æ— éœ€åˆ†å¸ƒå¼
- âœ… **ä¿æŒé¡ºåº**: åŒä¸€èšåˆIDçš„æ¶ˆæ¯è·¯ç”±åˆ°åŒä¸€Actor,ä¿è¯é¡ºåº

### æ¶æ„å¯¹æ¯”

```
Keyed Worker Pool (å½“å‰):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  256ä¸ª Worker (å›ºå®š goroutine + channel)            â”‚
â”‚  Hash(aggregateID) % 256 â†’ Worker[i]                â”‚
â”‚  é—®é¢˜: å¤´éƒ¨é˜»å¡,æ•…éšœéš”ç¦»å·®                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Hollywood Actor Pool (ç›®æ ‡):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  256ä¸ª Actor (Hollywood ç®¡ç† + Supervisor)          â”‚
â”‚  Hash(aggregateID) % 256 â†’ Actor[i]                 â”‚
â”‚  ä¼˜åŠ¿: Supervisor æœºåˆ¶,äº‹ä»¶æµç›‘æ§,æ¶ˆæ¯ä¿è¯          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—ï¸ **æ ¸å¿ƒæ¶æ„è®¾è®¡**

### 1. Actor Pool æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Kafka/NATS Consumer                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ExtractAggregateID(message)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Hash(aggregateID) % poolSize â†’ actorIndex           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PoolActor[0]   PoolActor[1]   ...   PoolActor[255]        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚Inbox     â”‚   â”‚Inbox     â”‚         â”‚Inbox     â”‚         â”‚
â”‚  â”‚[1000]    â”‚   â”‚[1000]    â”‚   ...   â”‚[1000]    â”‚         â”‚
â”‚  â”‚          â”‚   â”‚          â”‚         â”‚          â”‚         â”‚
â”‚  â”‚Supervisorâ”‚   â”‚Supervisorâ”‚         â”‚Supervisorâ”‚         â”‚
â”‚  â”‚è‡ªåŠ¨é‡å¯  â”‚   â”‚è‡ªåŠ¨é‡å¯  â”‚         â”‚è‡ªåŠ¨é‡å¯  â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ç‰¹ç‚¹:
âœ… å›ºå®šæ•°é‡ Actor (256/512/1024,å¯é…ç½®)
âœ… ä¸€è‡´æ€§å“ˆå¸Œè·¯ç”± (åŒä¸€èšåˆID â†’ åŒä¸€Actor)
âœ… Hollywood Supervisor æœºåˆ¶ (è‡ªåŠ¨é‡å¯)
âœ… äº‹ä»¶æµç›‘æ§ (DeadLetter, ActorRestarted)
âœ… æ¶ˆæ¯ä¿è¯é€è¾¾ (Buffer æœºåˆ¶)
âœ… å•æœºéƒ¨ç½²,æ— åˆ†å¸ƒå¼å¤æ‚åº¦
```

---

## ğŸ’» **æ ¸å¿ƒå®ç°**

### 1. hollywood_actor_pool.go

```go
package eventbus

import (
    "context"
    "fmt"
    "hash/fnv"
    "sync"
    "sync/atomic"
    
    "github.com/anthdm/hollywood/actor"
)

// HollywoodActorPoolConfig Actor Pool é…ç½®
type HollywoodActorPoolConfig struct {
    // Pool é…ç½®
    PoolSize    int `yaml:"poolSize" json:"poolSize"`       // Actor æ•°é‡ (256/512/1024)
    InboxSize   int `yaml:"inboxSize" json:"inboxSize"`     // æ¯ä¸ª Actor çš„ Inbox å¤§å°
    MaxRestarts int `yaml:"maxRestarts" json:"maxRestarts"` // æœ€å¤§é‡å¯æ¬¡æ•°
    
    // ç›‘æ§é…ç½®
    EnableEventStream bool `yaml:"enableEventStream" json:"enableEventStream"`
}

// DefaultHollywoodActorPoolConfig é»˜è®¤é…ç½®
func DefaultHollywoodActorPoolConfig() *HollywoodActorPoolConfig {
    return &HollywoodActorPoolConfig{
        PoolSize:          256,
        InboxSize:         1000,
        MaxRestarts:       3,
        EnableEventStream: true,
    }
}

// HollywoodActorPool Hollywood Actor æ± 
type HollywoodActorPool struct {
    config  *HollywoodActorPoolConfig
    engine  *actor.Engine
    actors  []*actor.PID // å›ºå®šæ•°é‡çš„ Actor PIDs
    metrics *HollywoodPoolMetrics
    
    ctx    context.Context
    cancel context.CancelFunc
    wg     sync.WaitGroup
}

// NewHollywoodActorPool åˆ›å»º Actor Pool
func NewHollywoodActorPool(config *HollywoodActorPoolConfig) (*HollywoodActorPool, error) {
    if config == nil {
        config = DefaultHollywoodActorPoolConfig()
    }
    
    ctx, cancel := context.WithCancel(context.Background())
    
    // åˆ›å»º Hollywood Engine
    engineConfig := actor.NewEngineConfig()
    engine, err := actor.NewEngine(engineConfig)
    if err != nil {
        cancel()
        return nil, fmt.Errorf("failed to create engine: %w", err)
    }
    
    pool := &HollywoodActorPool{
        config:  config,
        engine:  engine,
        actors:  make([]*actor.PID, config.PoolSize),
        metrics: NewHollywoodPoolMetrics(),
        ctx:     ctx,
        cancel:  cancel,
    }
    
    // åˆ›å»ºå›ºå®šæ•°é‡çš„ Actor
    for i := 0; i < config.PoolSize; i++ {
        pid := pool.spawnPoolActor(i)
        pool.actors[i] = pid
    }
    
    // è®¢é˜…äº‹ä»¶æµ
    if config.EnableEventStream {
        pool.subscribeEventStream()
    }
    
    return pool, nil
}

// spawnPoolActor åˆ›å»ºå•ä¸ª Pool Actor
func (p *HollywoodActorPool) spawnPoolActor(index int) *actor.PID {
    props := actor.PropsFromProducer(func() actor.Receiver {
        return NewPoolActor(index, p.metrics)
    })
    
    props = props.
        WithMaxRestarts(p.config.MaxRestarts).
        WithInboxSize(p.config.InboxSize)
    
    actorName := fmt.Sprintf("pool-actor-%d", index)
    return p.engine.Spawn(props, actorName)
}

// ProcessMessage å¤„ç†æ¶ˆæ¯
func (p *HollywoodActorPool) ProcessMessage(ctx context.Context, msg *AggregateMessage) error {
    if msg.AggregateID == "" {
        return fmt.Errorf("aggregateID is required")
    }
    
    // 1. å“ˆå¸Œè·¯ç”±åˆ°å¯¹åº”çš„ Actor
    actorIndex := p.hashToIndex(msg.AggregateID)
    pid := p.actors[actorIndex]
    
    // 2. å‘é€æ¶ˆæ¯åˆ° Actor
    p.engine.Send(pid, &DomainEventMessage{
        AggregateID: msg.AggregateID,
        EventData:   msg.Value,
        Headers:     msg.Headers,
        Timestamp:   msg.Timestamp,
        Context:     ctx,
        Done:        msg.Done,
        Handler:     msg.Handler,
    })
    
    p.metrics.MessagesSent.Add(1)
    return nil
}

// hashToIndex å“ˆå¸Œåˆ° Actor ç´¢å¼•
func (p *HollywoodActorPool) hashToIndex(aggregateID string) int {
    h := fnv.New32a()
    h.Write([]byte(aggregateID))
    return int(h.Sum32() % uint32(p.config.PoolSize))
}

// subscribeEventStream è®¢é˜…äº‹ä»¶æµ
func (p *HollywoodActorPool) subscribeEventStream() {
    // è®¢é˜… DeadLetter äº‹ä»¶
    p.engine.Subscribe(actor.DeadLetterEvent{}, p.engine.SpawnFunc(
        func(ctx *actor.Context) {
            if msg, ok := ctx.Message().(actor.DeadLetterEvent); ok {
                fmt.Printf("[Hollywood Pool] DeadLetter: %+v\n", msg)
                p.metrics.DeadLetters.Add(1)
            }
        },
        "deadletter-monitor",
    ))
    
    // è®¢é˜… ActorRestarted äº‹ä»¶
    p.engine.Subscribe(actor.ActorRestartedEvent{}, p.engine.SpawnFunc(
        func(ctx *actor.Context) {
            if msg, ok := ctx.Message().(actor.ActorRestartedEvent); ok {
                fmt.Printf("[Hollywood Pool] ActorRestarted: %+v\n", msg)
                p.metrics.ActorsRestarted.Add(1)
            }
        },
        "restart-monitor",
    ))
}

// Stop åœæ­¢ Actor Pool
func (p *HollywoodActorPool) Stop() error {
    p.cancel()
    
    // åœæ­¢æ‰€æœ‰ Actor
    for _, pid := range p.actors {
        p.engine.Poison(pid)
    }
    
    p.wg.Wait()
    return nil
}

// GetMetrics è·å–ç›‘æ§æŒ‡æ ‡
func (p *HollywoodActorPool) GetMetrics() map[string]interface{} {
    return p.metrics.Report()
}
```

---

### 2. pool_actor.go

```go
package eventbus

import (
    "context"
    "fmt"
    "time"
    
    "github.com/anthdm/hollywood/actor"
)

// PoolActor Pool ä¸­çš„å•ä¸ª Actor
type PoolActor struct {
    index   int
    metrics *HollywoodPoolMetrics
    
    // ç»Ÿè®¡ä¿¡æ¯
    messagesProcessed int64
}

// NewPoolActor åˆ›å»º Pool Actor
func NewPoolActor(index int, metrics *HollywoodPoolMetrics) actor.Receiver {
    return &PoolActor{
        index:   index,
        metrics: metrics,
    }
}

// Receive Actor æ¶ˆæ¯å¤„ç†å…¥å£
func (pa *PoolActor) Receive(ctx *actor.Context) {
    switch msg := ctx.Message().(type) {
    case actor.Started:
        pa.onStarted(ctx)
        
    case actor.Stopped:
        pa.onStopped(ctx)
        
    case actor.Restarting:
        pa.onRestarting(ctx)
        
    case *DomainEventMessage:
        pa.handleDomainEvent(ctx, msg)
    }
}

// onStarted Actor å¯åŠ¨
func (pa *PoolActor) onStarted(ctx *actor.Context) {
    fmt.Printf("[PoolActor-%d] Started\n", pa.index)
}

// onStopped Actor åœæ­¢
func (pa *PoolActor) onStopped(ctx *actor.Context) {
    fmt.Printf("[PoolActor-%d] Stopped, processed %d messages\n", 
        pa.index, pa.messagesProcessed)
}

// onRestarting Actor é‡å¯
func (pa *PoolActor) onRestarting(ctx *actor.Context) {
    fmt.Printf("[PoolActor-%d] Restarting due to panic\n", pa.index)
}

// handleDomainEvent å¤„ç†é¢†åŸŸäº‹ä»¶
func (pa *PoolActor) handleDomainEvent(ctx *actor.Context, msg *DomainEventMessage) {
    startTime := time.Now()
    
    // è°ƒç”¨ä¸šåŠ¡å¤„ç†å™¨
    var err error
    if msg.Handler != nil {
        err = msg.Handler(msg.Context, msg.EventData)
    } else {
        err = fmt.Errorf("no handler provided")
    }
    
    // è®°å½•å»¶è¿Ÿ
    latency := time.Since(startTime)
    pa.metrics.RecordLatency(latency)
    
    // æ›´æ–°ç»Ÿè®¡
    pa.messagesProcessed++
    
    if err != nil {
        pa.metrics.MessagesFailed.Add(1)
    } else {
        pa.metrics.MessagesProcessed.Add(1)
    }
    
    // è¿”å›å¤„ç†ç»“æœ
    if msg.Done != nil {
        select {
        case msg.Done <- err:
        default:
        }
    }
    
    // å¦‚æœå¤„ç†å¤±è´¥,è§¦å‘ panic (è®© Supervisor å¤„ç†)
    if err != nil {
        panic(fmt.Errorf("failed to process event: %w", err))
    }
}
```

---

### 3. hollywood_pool_metrics.go

#### ç›‘æ§æ–¹æ¡ˆé€‰æ‹©

**æ¨èæ–¹æ¡ˆ: æ··åˆæ–¹æ¡ˆ (æ¥å£æ³¨å…¥ + Middleware) â­â­â­â­â­**

**æ ¸å¿ƒæ€æƒ³**:
- **æ¥å£å®šä¹‰**: ä½¿ç”¨æ¥å£æ³¨å…¥ (ä¸ EventBus ä¸€è‡´,ä¾èµ–å€’ç½®)
- **Middleware å®ç°**: Middleware ä¾èµ–æ¥å£,è‡ªåŠ¨è®°å½•æ¶ˆæ¯å¤„ç†
- **æ‰‹åŠ¨è°ƒç”¨**: ç‰¹æ®Šåœºæ™¯æ‰‹åŠ¨è°ƒç”¨æ¥å£ (Middleware æ— æ³•å¤„ç†çš„åœºæ™¯)

**ä¼˜åŠ¿**:
- âœ… ä¸ EventBus ç›‘æ§æ¶æ„ä¿æŒä¸€è‡´ (æ¥å£æ³¨å…¥)
- âœ… æ ¸å¿ƒä»£ç ä¸ä¾èµ– Prometheus (ä¾èµ–å€’ç½®åŸåˆ™)
- âœ… è‡ªåŠ¨è®°å½•æ¶ˆæ¯å¤„ç† (Middleware è‡ªåŠ¨æ‹¦æˆª)
- âœ… çµæ´»æ€§é«˜ (ç‰¹æ®Šåœºæ™¯å¯æ‰‹åŠ¨è°ƒç”¨)
- âœ… æ˜“äºå•å…ƒæµ‹è¯• (å¯æ³¨å…¥ NoOp æˆ– InMemory å®ç°)
- âœ… æ”¯æŒå¤šç§ç›‘æ§ç³»ç»Ÿ (Prometheus, StatsD, Datadog, etc.)
- âœ… Hollywood åŸç”Ÿæ”¯æŒ (åˆ©ç”¨ Middleware æœºåˆ¶)

**æ¶æ„**:
```
æ¥å£æ³¨å…¥ (ActorPoolMetricsCollector)
    â†“
    â”œâ”€â†’ Middleware (ä¾èµ–æ¥å£,è‡ªåŠ¨æ‹¦æˆª) âœ…
    â”œâ”€â†’ æ‰‹åŠ¨è°ƒç”¨ (ç‰¹æ®Šåœºæ™¯)
    â””â”€â†’ EventStream è®¢é˜… (Actor é‡å¯/æ­»ä¿¡) âœ…
```

**å…¶ä»–æ–¹æ¡ˆå¯¹æ¯”**:

| æ–¹æ¡ˆ | ä¼˜åŠ¿ | åŠ£åŠ¿ | æ¨èåº¦ |
|------|------|------|--------|
| **çº¯æ¥å£æ³¨å…¥** | ä¸ EventBus ä¸€è‡´ | éœ€è¦æ‰‹åŠ¨è°ƒç”¨,å®¹æ˜“é—æ¼ | â­â­â­ |
| **çº¯ Middleware** | è‡ªåŠ¨æ‹¦æˆª | ä¸ EventBus ä¸ä¸€è‡´,ä¾èµ– Hollywood | â­â­â­ |
| **æ··åˆæ–¹æ¡ˆ** â­ | å…¼é¡¾ä¸¤è€…ä¼˜åŠ¿ | éœ€è¦ç†è§£ä¸¤ç§æœºåˆ¶ | â­â­â­â­â­ |

**è¯¦ç»†å®ç°**: å‚è€ƒ `hollywood-actor-pool-prometheus-integration.md`

---

#### æ··åˆæ–¹æ¡ˆå®ç°

å‚è€ƒ EventBus çš„å®ç°æ–¹å¼,å®šä¹‰ `ActorPoolMetricsCollector` æ¥å£:

```go
package eventbus

import (
    "sort"
    "fmt"
    "time"

    "github.com/anthdm/hollywood/actor"
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
)

// ActorMetrics - å•ä¸ª Actor çš„ Prometheus ç›‘æ§æŒ‡æ ‡
type ActorMetrics struct {
    actorID    string
    msgCounter prometheus.Counter   // æ¶ˆæ¯è®¡æ•°
    msgLatency prometheus.Histogram // æ¶ˆæ¯å»¶è¿Ÿ
}

// NewActorMetrics åˆ›å»º Actor ç›‘æ§æŒ‡æ ‡
func NewActorMetrics(actorID string) *ActorMetrics {
    msgCounter := promauto.NewCounter(prometheus.CounterOpts{
        Name: "hollywood_actor_msg_total",
        Help: "Total number of messages processed by actor",
        ConstLabels: prometheus.Labels{"actor_id": actorID},
    })
    msgLatency := promauto.NewHistogram(prometheus.HistogramOpts{
        Name:    "hollywood_actor_msg_latency_seconds",
        Help:    "Message processing latency in seconds",
        Buckets: []float64{0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0},
        ConstLabels: prometheus.Labels{"actor_id": actorID},
    })
    return &ActorMetrics{
        actorID:    actorID,
        msgCounter: msgCounter,
        msgLatency: msgLatency,
    }
}

// WithMetrics è¿”å› Middleware å‡½æ•° (Hollywood æ ‡å‡† Middleware æ¥å£)
func (am *ActorMetrics) WithMetrics() func(actor.ReceiveFunc) actor.ReceiveFunc {
    return func(next actor.ReceiveFunc) actor.ReceiveFunc {
        return func(c *actor.Context) {
            start := time.Now()
            am.msgCounter.Inc()
            next(c) // è°ƒç”¨ä¸‹ä¸€ä¸ª Middleware æˆ–ä¸šåŠ¡é€»è¾‘
            duration := time.Since(start).Seconds()
            am.msgLatency.Observe(duration)
        }
    }
}

// åœ¨ Spawn Actor æ—¶æ³¨å…¥ Middleware
func (p *HollywoodActorPool) initActors() error {
    for i := 0; i < p.config.PoolSize; i++ {
        actorID := fmt.Sprintf("pool-actor-%d", i)

        // åˆ›å»º Actor ç›‘æ§æŒ‡æ ‡
        metrics := NewActorMetrics(actorID)

        // Spawn Actor å¹¶æ³¨å…¥ Metrics Middleware
        pid := p.engine.Spawn(
            func() actor.Receiver {
                return NewPoolActor(i, p.metrics)
            },
            actorID,
            actor.WithInboxSize(p.config.InboxSize),
            actor.WithMaxRestarts(p.config.MaxRestarts),
            actor.WithMiddleware(metrics.WithMetrics()), // â­ æ³¨å…¥ç›‘æ§ Middleware
        )

        p.actors[i] = pid
    }
    return nil
}
```

**Prometheus æŒ‡æ ‡è¾“å‡ºç¤ºä¾‹**:
```
# HELP hollywood_actor_msg_total Total number of messages processed by actor
# TYPE hollywood_actor_msg_total counter
hollywood_actor_msg_total{actor_id="pool-actor-0"} 12345
hollywood_actor_msg_total{actor_id="pool-actor-1"} 23456

# HELP hollywood_actor_msg_latency_seconds Message processing latency in seconds
# TYPE hollywood_actor_msg_latency_seconds histogram
hollywood_actor_msg_latency_seconds_bucket{actor_id="pool-actor-0",le="0.001"} 100
hollywood_actor_msg_latency_seconds_bucket{actor_id="pool-actor-0",le="0.005"} 500
hollywood_actor_msg_latency_seconds_bucket{actor_id="pool-actor-0",le="0.01"} 1000
...
```

---

#### æ–¹æ¡ˆ B: è‡ªå®šä¹‰ç›‘æ§æŒ‡æ ‡ (ç®€å•åœºæ™¯)

å¦‚æœä¸éœ€è¦ Prometheus,å¯ä»¥ä½¿ç”¨ç®€å•çš„å†…å­˜è®¡æ•°å™¨:

```go
package eventbus

import (
    "sync"
    "sync/atomic"
    "time"
)

// HollywoodPoolMetrics Actor Pool ç›‘æ§æŒ‡æ ‡ (ç®€å•ç‰ˆ)
type HollywoodPoolMetrics struct {
    // æ¶ˆæ¯æŒ‡æ ‡
    MessagesSent      atomic.Int64
    MessagesProcessed atomic.Int64
    MessagesFailed    atomic.Int64

    // Actor æŒ‡æ ‡
    ActorsRestarted atomic.Int64
    DeadLetters     atomic.Int64

    // å»¶è¿ŸæŒ‡æ ‡
    latencies []time.Duration
    mu        sync.RWMutex
}

// NewHollywoodPoolMetrics åˆ›å»ºç›‘æ§æŒ‡æ ‡
func NewHollywoodPoolMetrics() *HollywoodPoolMetrics {
    return &HollywoodPoolMetrics{
        latencies: make([]time.Duration, 0, 10000),
    }
}

// RecordLatency è®°å½•å»¶è¿Ÿ
func (hpm *HollywoodPoolMetrics) RecordLatency(d time.Duration) {
    hpm.mu.Lock()
    defer hpm.mu.Unlock()
    
    hpm.latencies = append(hpm.latencies, d)
    
    // ä¿ç•™æœ€è¿‘ 10000 æ¡
    if len(hpm.latencies) > 10000 {
        hpm.latencies = hpm.latencies[1:]
    }
}

// LatencyP99 è·å– P99 å»¶è¿Ÿ
func (hpm *HollywoodPoolMetrics) LatencyP99() time.Duration {
    hpm.mu.RLock()
    defer hpm.mu.RUnlock()
    
    if len(hpm.latencies) == 0 {
        return 0
    }
    
    sorted := make([]time.Duration, len(hpm.latencies))
    copy(sorted, hpm.latencies)
    sort.Slice(sorted, func(i, j int) bool {
        return sorted[i] < sorted[j]
    })
    
    idx := int(float64(len(sorted)) * 0.99)
    return sorted[idx]
}

// Report æŠ¥å‘ŠæŒ‡æ ‡
func (hpm *HollywoodPoolMetrics) Report() map[string]interface{} {
    return map[string]interface{}{
        "messages_sent":       hpm.MessagesSent.Load(),
        "messages_processed":  hpm.MessagesProcessed.Load(),
        "messages_failed":     hpm.MessagesFailed.Load(),
        "actors_restarted":    hpm.ActorsRestarted.Load(),
        "dead_letters":        hpm.DeadLetters.Load(),
        "latency_p99_ms":      hpm.LatencyP99().Milliseconds(),
    }
}
```

---

## ğŸ“ **é›†æˆåˆ° EventBus**

### ä¿®æ”¹ kafka.go

```go
// sdk/pkg/eventbus/kafka.go

type KafkaEventBus struct {
    // ... ç°æœ‰å­—æ®µ ...
    
    // æ–°å¢: Hollywood Actor Pool (æ›¿ä»£ globalKeyedPool)
    hollywoodPool *HollywoodActorPool
    useHollywood  bool // ç‰¹æ€§å¼€å…³
}

// åˆå§‹åŒ–æ—¶åˆ›å»º Hollywood Pool
func (bus *KafkaEventBus) initHollywoodPool() error {
    if !bus.config.UseHollywood {
        return nil
    }
    
    config := &HollywoodActorPoolConfig{
        PoolSize:          bus.config.Hollywood.PoolSize,    // 256/512/1024
        InboxSize:         bus.config.Hollywood.InboxSize,   // 1000
        MaxRestarts:       bus.config.Hollywood.MaxRestarts, // 3
        EnableEventStream: bus.config.Hollywood.EnableEventStream,
    }
    
    pool, err := NewHollywoodActorPool(config)
    if err != nil {
        return fmt.Errorf("failed to create hollywood pool: %w", err)
    }
    
    bus.hollywoodPool = pool
    return nil
}

// æ¶ˆæ¯å¤„ç†é€»è¾‘
func (bus *KafkaEventBus) processMessage(ctx context.Context, msg *Message, handler MessageHandler) error {
    // æå–èšåˆID
    aggregateID := extractAggregateID(msg)
    
    if aggregateID != "" {
        // ä½¿ç”¨ Hollywood Actor Pool æˆ– Keyed Worker Pool
        if bus.useHollywood && bus.hollywoodPool != nil {
            return bus.hollywoodPool.ProcessMessage(ctx, &AggregateMessage{
                AggregateID: aggregateID,
                Value:       msg.Value,
                Headers:     msg.Headers,
                Timestamp:   msg.Timestamp,
                Context:     ctx,
                Handler:     handler,
            })
        } else {
            // é™çº§: ä½¿ç”¨åŸæœ‰ Keyed Worker Pool
            return bus.globalKeyedPool.ProcessMessage(ctx, &AggregateMessage{...})
        }
    } else {
        // æ— èšåˆID,ç›´æ¥å¤„ç†
        return handler(ctx, msg.Value)
    }
}
```

---

## âš™ï¸ **é…ç½®ç¤ºä¾‹ä¸ Mailbox æ·±åº¦åˆ†æ**

### Mailbox (Inbox) é˜Ÿåˆ—æ·±åº¦é€‰æ‹©

#### å…³é”®è€ƒé‡å› ç´ 

```
Mailbox æ·±åº¦ = ç¼“å†²èƒ½åŠ› vs å†…å­˜å ç”¨ vs å»¶è¿Ÿ

å¤ªå° (< 100):
  âŒ èƒŒå‹é¢‘ç¹,ååé‡ä½
  âŒ æ— æ³•åº”å¯¹çªå‘æµé‡
  âœ… å»¶è¿Ÿä½ (æ¶ˆæ¯æ’é˜Ÿå°‘)
  âœ… å†…å­˜å ç”¨å°

é€‚ä¸­ (100-1000):
  âœ… å¹³è¡¡ååé‡å’Œå»¶è¿Ÿ
  âœ… å¯åº”å¯¹ä¸­ç­‰çªå‘æµé‡
  âœ… å†…å­˜å ç”¨å¯æ§
  âš ï¸ éœ€æ ¹æ®ä¸šåŠ¡è°ƒä¼˜

å¤ªå¤§ (> 10000):
  âœ… ååé‡é«˜
  âœ… å¯åº”å¯¹å¤§çªå‘æµé‡
  âŒ å»¶è¿Ÿé«˜ (æ¶ˆæ¯æ’é˜Ÿå¤š)
  âŒ å†…å­˜å ç”¨å¤§
  âŒ æ•…éšœæ¢å¤æ…¢ (å¤§é‡æ¶ˆæ¯ç§¯å‹)
```

#### è®¡ç®—å…¬å¼

```
å†…å­˜å ç”¨ = poolSize Ã— inboxSize Ã— avgMessageSize

ç¤ºä¾‹:
- poolSize=256, inboxSize=1000, avgMessageSize=200B
  â†’ 256 Ã— 1000 Ã— 200B = 51.2MB

- poolSize=256, inboxSize=10000, avgMessageSize=200B
  â†’ 256 Ã— 10000 Ã— 200B = 512MB

- poolSize=1024, inboxSize=10000, avgMessageSize=500B
  â†’ 1024 Ã— 10000 Ã— 500B = 5GB âš ï¸ è¿‡å¤§!
```

#### æ¨èé…ç½®çŸ©é˜µ

| åœºæ™¯ | poolSize | inboxSize | å†…å­˜å ç”¨ | é€‚ç”¨æƒ…å†µ |
|------|----------|-----------|----------|----------|
| **ä½å»¶è¿Ÿä¼˜å…ˆ** | 256 | 100 | ~5MB | å®æ—¶äº¤æ˜“,å¿«é€Ÿå“åº” |
| **æ ‡å‡†å‡è¡¡** | 256 | 1000 | ~50MB | é€šç”¨åœºæ™¯ âœ… æ¨è |
| **é«˜åå** | 512 | 5000 | ~500MB | å¤§æ‰¹é‡å¤„ç† |
| **è¶…é«˜åå** | 1024 | 10000 | ~2GB | æç«¯é«˜å¹¶å‘ |
| **å†…å­˜å—é™** | 128 | 500 | ~13MB | èµ„æºç´§å¼ ç¯å¢ƒ |

#### ä¸ Keyed Worker Pool å¯¹æ¯”

```yaml
# Keyed Worker Pool (å½“å‰)
keyedWorkerPool:
  workerCount: 256
  queueSize: 1000        # æ¯ä¸ª Worker çš„é˜Ÿåˆ—æ·±åº¦
  # å†…å­˜: 256 Ã— 1000 Ã— 200B = 51.2MB

# Hollywood Actor Pool (ç›®æ ‡)
hollywood:
  poolSize: 256
  inboxSize: 1000        # æ¯ä¸ª Actor çš„ Mailbox æ·±åº¦
  # å†…å­˜: 256 Ã— 1000 Ã— 200B = 51.2MB

# ç»“è®º: å†…å­˜å ç”¨ç›¸åŒ,ä½† Hollywood æä¾›æ›´å¥½çš„å¯é æ€§
```

---

### é…ç½®ç¤ºä¾‹

```yaml
# config/hollywood-pool-config.yaml
eventbus:
  type: kafka
  kafka:
    brokers: ["localhost:9092"]

  # å¯ç”¨ Hollywood Actor Pool
  useHollywood: true

  hollywood:
    # Pool é…ç½®
    poolSize: 256        # Actor æ•°é‡ (256/512/1024)
    inboxSize: 1000      # Mailbox æ·±åº¦ (100/1000/5000/10000)
    maxRestarts: 3       # æœ€å¤§é‡å¯æ¬¡æ•°

    # ç›‘æ§é…ç½®
    enableEventStream: true
```

### ä¸åŒåœºæ™¯çš„æ¨èé…ç½®

#### åœºæ™¯ 1: è®¢å•ç³»ç»Ÿ (ä½å»¶è¿Ÿä¼˜å…ˆ)

```yaml
hollywood:
  poolSize: 256
  inboxSize: 500         # è¾ƒå° Mailbox,å‡å°‘æ’é˜Ÿå»¶è¿Ÿ
  maxRestarts: 3
  enableEventStream: true

# é¢„æœŸæ€§èƒ½:
# - P99 å»¶è¿Ÿ: 20-30ms
# - ååé‡: 50K-80K TPS
# - å†…å­˜: ~25MB
```

#### åœºæ™¯ 2: æ—¥å¿—èšåˆ (é«˜ååä¼˜å…ˆ)

```yaml
hollywood:
  poolSize: 512
  inboxSize: 10000       # å¤§ Mailbox,ç¼“å†²çªå‘æµé‡
  maxRestarts: 3
  enableEventStream: true

# é¢„æœŸæ€§èƒ½:
# - P99 å»¶è¿Ÿ: 100-200ms
# - ååé‡: 200K-300K TPS
# - å†…å­˜: ~1GB
```

#### åœºæ™¯ 3: ç‰©è”ç½‘æ•°æ® (è¶…é«˜åå)

```yaml
hollywood:
  poolSize: 1024
  inboxSize: 5000        # å¹³è¡¡ååå’Œå†…å­˜
  maxRestarts: 3
  enableEventStream: true

# é¢„æœŸæ€§èƒ½:
# - P99 å»¶è¿Ÿ: 50-100ms
# - ååé‡: 300K-500K TPS
# - å†…å­˜: ~1GB
```

#### åœºæ™¯ 4: è¾¹ç¼˜è®¡ç®— (å†…å­˜å—é™)

```yaml
hollywood:
  poolSize: 128
  inboxSize: 200         # æœ€å°åŒ–å†…å­˜å ç”¨
  maxRestarts: 3
  enableEventStream: true

# é¢„æœŸæ€§èƒ½:
# - P99 å»¶è¿Ÿ: 10-20ms
# - ååé‡: 20K-30K TPS
# - å†…å­˜: ~5MB
```

---

## ğŸ“Š **æ€§èƒ½å¯¹æ¯”ä¸ Mailbox æ·±åº¦å½±å“**

### Keyed Worker Pool vs Hollywood Actor Pool

| æŒ‡æ ‡ | Keyed Worker Pool | Hollywood Actor Pool | è¯´æ˜ |
|------|------------------|---------------------|------|
| **æ¶æ„** | å›ºå®š goroutine + channel | å›ºå®š Actor + Hollywood | æ•°é‡ç›¸åŒ |
| **é˜Ÿåˆ—æ·±åº¦** | queueSize=1000 | inboxSize=1000 | ç›¸åŒ |
| **Supervisor** | âŒ æ—  | âœ… è‡ªåŠ¨é‡å¯ | å…³é”®å·®å¼‚ |
| **äº‹ä»¶æµç›‘æ§** | âŒ æ—  | âœ… DeadLetter, Restart | å…³é”®å·®å¼‚ |
| **æ¶ˆæ¯ä¿è¯** | âš ï¸ é˜Ÿåˆ—æ»¡ä¸¢å¤± | âœ… Buffer ä¿è¯ (Inbox æœªæ»¡æ—¶) | å…³é”®å·®å¼‚ |
| **æ•…éšœéš”ç¦»** | âš ï¸ Worker çº§ | âœ… Actor çº§ (æ›´ç»†ç²’åº¦,éå®Œç¾) | å…³é”®å·®å¼‚ |
| **å†…å­˜å ç”¨** | ~50MB (256 * 1000 * 200B) | ~50MB (ç›¸åŒ) | ç›¸åŒ |
| **Goroutine** | 256 (å›ºå®š) | 256 (å›ºå®š) | ç›¸åŒ |
| **ååé‡** | 100K TPS | 100-120K TPS | ç•¥æœ‰æå‡ |
| **å»¶è¿Ÿ** | P99 50ms | P99 40-50ms | ç•¥æœ‰æ”¹å–„ |

### Mailbox æ·±åº¦å¯¹æ€§èƒ½çš„å½±å“

| inboxSize | ååé‡ | P99å»¶è¿Ÿ | å†…å­˜å ç”¨ | èƒŒå‹é¢‘ç‡ | é€‚ç”¨åœºæ™¯ |
|-----------|--------|---------|----------|----------|----------|
| **100** | 50K TPS | 10-20ms | ~5MB | é«˜ | ä½å»¶è¿Ÿä¼˜å…ˆ |
| **500** | 80K TPS | 20-30ms | ~25MB | ä¸­ | å‡è¡¡åœºæ™¯ |
| **1000** | 100K TPS | 40-50ms | ~50MB | ä½ | æ ‡å‡†é…ç½® âœ… |
| **5000** | 200K TPS | 80-100ms | ~250MB | æä½ | é«˜åå |
| **10000** | 300K TPS | 150-200ms | ~500MB | æ—  | æç«¯é«˜åå |

**å…³é”®æ´å¯Ÿ**:
- âœ… **inboxSize=1000**: æœ€ä½³å¹³è¡¡ç‚¹,é€‚åˆ80%çš„åœºæ™¯
- âš ï¸ **inboxSize > 5000**: å»¶è¿Ÿæ˜¾è‘—å¢åŠ ,éœ€è°¨æ…è¯„ä¼°
- âš ï¸ **inboxSize < 500**: èƒŒå‹é¢‘ç¹,å¯èƒ½å½±å“ååé‡

---

## ğŸ“ˆ **Mailbox æ·±åº¦ç›‘æ§ä¸è°ƒä¼˜**

### ç›‘æ§æ–¹æ¡ˆ: ä½¿ç”¨ Hollywood Middleware + Prometheus â­

Hollywood æ¡†æ¶é€šè¿‡ **Middleware** æœºåˆ¶å¯ä»¥è½»æ¾é›†æˆ Prometheus ç›‘æ§,åŒ…æ‹¬ Mailbox æ·±åº¦ç›‘æ§ã€‚

#### å®Œæ•´çš„ç›‘æ§æŒ‡æ ‡å®ç°

```go
package eventbus

import (
    "fmt"
    "sync/atomic"
    "time"

    "github.com/anthdm/hollywood/actor"
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
)

// PoolActorMetrics - åŒ…å« Mailbox ç›‘æ§çš„å®Œæ•´æŒ‡æ ‡
type PoolActorMetrics struct {
    actorID   string
    inboxSize int

    // æ¶ˆæ¯æŒ‡æ ‡
    msgCounter prometheus.Counter
    msgLatency prometheus.Histogram
    msgFailed  prometheus.Counter

    // Mailbox æŒ‡æ ‡ â­ å…³é”®
    inboxDepth       prometheus.Gauge     // å½“å‰ Inbox æ·±åº¦
    inboxUtilization prometheus.Gauge     // Inbox åˆ©ç”¨ç‡ (0-1)
    inboxFull        prometheus.Counter   // Inbox æ»¡è½½æ¬¡æ•°
}

// NewPoolActorMetrics åˆ›å»ºç›‘æ§æŒ‡æ ‡
func NewPoolActorMetrics(actorID string, inboxSize int) *PoolActorMetrics {
    return &PoolActorMetrics{
        actorID:   actorID,
        inboxSize: inboxSize,

        msgCounter: promauto.NewCounter(prometheus.CounterOpts{
            Name: "hollywood_pool_actor_msg_total",
            Help: "Total messages processed",
            ConstLabels: prometheus.Labels{"actor_id": actorID},
        }),
        msgLatency: promauto.NewHistogram(prometheus.HistogramOpts{
            Name:    "hollywood_pool_actor_msg_latency_seconds",
            Help:    "Message processing latency",
            Buckets: []float64{0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0},
            ConstLabels: prometheus.Labels{"actor_id": actorID},
        }),
        msgFailed: promauto.NewCounter(prometheus.CounterOpts{
            Name: "hollywood_pool_actor_msg_failed_total",
            Help: "Total failed messages",
            ConstLabels: prometheus.Labels{"actor_id": actorID},
        }),

        // Mailbox ç›‘æ§ â­
        inboxDepth: promauto.NewGauge(prometheus.GaugeOpts{
            Name: "hollywood_pool_actor_inbox_depth",
            Help: "Current inbox depth",
            ConstLabels: prometheus.Labels{"actor_id": actorID},
        }),
        inboxUtilization: promauto.NewGauge(prometheus.GaugeOpts{
            Name: "hollywood_pool_actor_inbox_utilization",
            Help: "Inbox utilization ratio (0-1)",
            ConstLabels: prometheus.Labels{"actor_id": actorID},
        }),
        inboxFull: promauto.NewCounter(prometheus.CounterOpts{
            Name: "hollywood_pool_actor_inbox_full_total",
            Help: "Total times inbox was full",
            ConstLabels: prometheus.Labels{"actor_id": actorID},
        }),
    }
}

// WithMetrics è¿”å› Middleware (Hollywood æ ‡å‡†æ¥å£)
func (pam *PoolActorMetrics) WithMetrics() func(actor.ReceiveFunc) actor.ReceiveFunc {
    return func(next actor.ReceiveFunc) actor.ReceiveFunc {
        return func(c *actor.Context) {
            start := time.Now()
            pam.msgCounter.Inc()

            // è°ƒç”¨ä¸šåŠ¡é€»è¾‘
            next(c)

            // è®°å½•å»¶è¿Ÿ
            duration := time.Since(start).Seconds()
            pam.msgLatency.Observe(duration)
        }
    }
}

// RecordInboxDepth è®°å½• Inbox æ·±åº¦ (åœ¨ PoolActor å†…éƒ¨è°ƒç”¨)
func (pam *PoolActorMetrics) RecordInboxDepth(depth int) {
    pam.inboxDepth.Set(float64(depth))

    utilization := float64(depth) / float64(pam.inboxSize)
    pam.inboxUtilization.Set(utilization)

    if depth >= pam.inboxSize {
        pam.inboxFull.Inc()
    }
}
```

#### åœ¨ PoolActor ä¸­é›†æˆ

```go
// PoolActor ç»´æŠ¤ Inbox æ·±åº¦è®¡æ•°å™¨
type PoolActor struct {
    index      int
    metrics    *PoolActorMetrics
    inboxDepth atomic.Int32  // Inbox æ·±åº¦è®¡æ•°å™¨
}

func (pa *PoolActor) Receive(ctx *actor.Context) {
    // æ¯æ¬¡æ”¶åˆ°æ¶ˆæ¯,å‡å°‘è®¡æ•°å™¨
    pa.inboxDepth.Add(-1)

    switch msg := ctx.Message().(type) {
    case *DomainEventMessage:
        start := time.Now()

        err := msg.Handler(ctx.Context(), msg.Value)

        if err != nil {
            pa.metrics.msgFailed.Inc()
        }

        // è®°å½• Mailbox æ·±åº¦
        depth := int(pa.inboxDepth.Load())
        pa.metrics.RecordInboxDepth(depth)
    }
}

// å‘é€æ¶ˆæ¯æ—¶å¢åŠ è®¡æ•°å™¨
func (p *HollywoodActorPool) ProcessMessage(ctx context.Context, msg *AggregateMessage) error {
    actorIndex := p.hashToIndex(msg.AggregateID)

    // å¢åŠ  Inbox æ·±åº¦è®¡æ•°å™¨ (éœ€è¦è®¿é—® PoolActor å®ä¾‹)
    // å¯ä»¥é€šè¿‡ map ç»´æŠ¤ actorIndex -> PoolActor çš„æ˜ å°„

    pid := p.actors[actorIndex]
    p.engine.Send(pid, &DomainEventMessage{...})
    return nil
}
```

#### Prometheus æŒ‡æ ‡è¾“å‡ºç¤ºä¾‹

```
# Mailbox æ·±åº¦
hollywood_pool_actor_inbox_depth{actor_id="pool-actor-0"} 850
hollywood_pool_actor_inbox_depth{actor_id="pool-actor-1"} 120

# Mailbox åˆ©ç”¨ç‡
hollywood_pool_actor_inbox_utilization{actor_id="pool-actor-0"} 0.85
hollywood_pool_actor_inbox_utilization{actor_id="pool-actor-1"} 0.12

# Mailbox æ»¡è½½æ¬¡æ•°
hollywood_pool_actor_inbox_full_total{actor_id="pool-actor-0"} 5
hollywood_pool_actor_inbox_full_total{actor_id="pool-actor-1"} 0
```

### å‘Šè­¦è§„åˆ™

```yaml
# Prometheus å‘Šè­¦è§„åˆ™
groups:
  - name: hollywood_mailbox_alerts
    rules:
      # Inbox åˆ©ç”¨ç‡è¿‡é«˜
      - alert: HighInboxUtilization
        expr: avg(hollywood_inbox_depth / hollywood_inbox_size) > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Mailbox åˆ©ç”¨ç‡è¶…è¿‡ 80%"
          description: "å½“å‰åˆ©ç”¨ç‡: {{ $value }}, è€ƒè™‘å¢åŠ  inboxSize"

      # Inbox é¢‘ç¹æ»¡è½½
      - alert: FrequentInboxFull
        expr: rate(hollywood_inbox_full_total[5m]) > 10
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Mailbox é¢‘ç¹æ»¡è½½"
          description: "5åˆ†é’Ÿå†…æ»¡è½½ {{ $value }} æ¬¡, éœ€ç«‹å³å¢åŠ  inboxSize"

      # å»¶è¿Ÿä¸ Inbox æ·±åº¦ç›¸å…³æ€§
      - alert: HighLatencyDueToInbox
        expr: |
          (histogram_quantile(0.99, hollywood_processing_latency_seconds) > 0.1)
          and
          (avg(hollywood_inbox_depth) > 5000)
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "é«˜å»¶è¿Ÿå¯èƒ½ç”± Mailbox ç§¯å‹å¯¼è‡´"
          description: "P99å»¶è¿Ÿ: {{ $value }}s, å¹³å‡Inboxæ·±åº¦: {{ $value2 }}"
```

### åŠ¨æ€è°ƒä¼˜ç­–ç•¥

#### ç­–ç•¥ 1: åŸºäºåˆ©ç”¨ç‡è‡ªåŠ¨è°ƒæ•´ (è¿è¡Œæ—¶)

```go
// åŠ¨æ€è°ƒæ•´ Inbox å¤§å° (éœ€è¦é‡å¯ Actor)
func (pool *HollywoodActorPool) autoTuneInboxSize() {
    ticker := time.NewTicker(5 * time.Minute)
    defer ticker.Stop()

    for {
        select {
        case <-ticker.C:
            avgUtilization := pool.metrics.GetAvgInboxUtilization()

            if avgUtilization > 0.8 {
                // åˆ©ç”¨ç‡è¿‡é«˜,å»ºè®®å¢åŠ 
                log.Warnf("Inbox utilization high: %.2f, consider increasing inboxSize from %d to %d",
                    avgUtilization, pool.config.InboxSize, pool.config.InboxSize*2)
            } else if avgUtilization < 0.2 {
                // åˆ©ç”¨ç‡è¿‡ä½,å»ºè®®å‡å°‘
                log.Infof("Inbox utilization low: %.2f, consider decreasing inboxSize from %d to %d",
                    avgUtilization, pool.config.InboxSize, pool.config.InboxSize/2)
            }
        }
    }
}
```

#### ç­–ç•¥ 2: åŸºäºå»¶è¿Ÿåé¦ˆè°ƒæ•´

```go
// æ ¹æ®å»¶è¿Ÿè°ƒæ•´ Inbox å¤§å°
func (pool *HollywoodActorPool) tuneByLatency() {
    p99Latency := pool.metrics.LatencyP99()
    avgInboxDepth := pool.metrics.GetAvgInboxDepth()

    // å»¶è¿Ÿè¿‡é«˜ + Inbox æ·±åº¦å¤§ â†’ å‡å° inboxSize
    if p99Latency > 100*time.Millisecond && avgInboxDepth > 5000 {
        log.Warnf("High latency (%v) with deep inbox (%d), consider reducing inboxSize",
            p99Latency, avgInboxDepth)
    }

    // èƒŒå‹é¢‘ç¹ + Inbox æ·±åº¦å° â†’ å¢åŠ  inboxSize
    if pool.metrics.BackpressureRate() > 10 && avgInboxDepth < 500 {
        log.Warnf("Frequent backpressure with shallow inbox (%d), consider increasing inboxSize",
            avgInboxDepth)
    }
}
```

### è°ƒä¼˜å†³ç­–æ ‘

```
å¼€å§‹
  â†“
æ˜¯å¦æœ‰èƒŒå‹å‘Šè­¦?
  â”œâ”€ æ˜¯ â†’ Inbox åˆ©ç”¨ç‡ > 80%?
  â”‚       â”œâ”€ æ˜¯ â†’ å¢åŠ  inboxSize (1000 â†’ 2000)
  â”‚       â””â”€ å¦ â†’ æ£€æŸ¥ä¸šåŠ¡å¤„ç†é€Ÿåº¦
  â”‚
  â””â”€ å¦ â†’ P99 å»¶è¿Ÿ > 100ms?
          â”œâ”€ æ˜¯ â†’ å¹³å‡ Inbox æ·±åº¦ > 5000?
          â”‚       â”œâ”€ æ˜¯ â†’ å‡å° inboxSize (10000 â†’ 5000)
          â”‚       â””â”€ å¦ â†’ ä¼˜åŒ–ä¸šåŠ¡é€»è¾‘
          â”‚
          â””â”€ å¦ â†’ å½“å‰é…ç½®åˆç† âœ…
```

### å®æˆ˜è°ƒä¼˜æ¡ˆä¾‹

#### æ¡ˆä¾‹ 1: è®¢å•ç³»ç»Ÿå»¶è¿Ÿè¿‡é«˜

**é—®é¢˜**:
- P99 å»¶è¿Ÿ: 200ms (ç›®æ ‡: < 50ms)
- å¹³å‡ Inbox æ·±åº¦: 8000
- é…ç½®: poolSize=256, inboxSize=10000

**åˆ†æ**:
- Inbox è¿‡å¤§å¯¼è‡´æ¶ˆæ¯æ’é˜Ÿæ—¶é—´é•¿
- å†…å­˜å ç”¨: 256 Ã— 10000 Ã— 200B = 512MB

**è§£å†³**:
```yaml
hollywood:
  poolSize: 512        # å¢åŠ  Actor æ•°é‡,åˆ†æ•£è´Ÿè½½
  inboxSize: 1000      # å‡å° Inbox,é™ä½æ’é˜Ÿå»¶è¿Ÿ
  # å†…å­˜: 512 Ã— 1000 Ã— 200B = 102MB
```

**ç»“æœ**:
- P99 å»¶è¿Ÿ: 200ms â†’ 40ms âœ…
- å†…å­˜å ç”¨: 512MB â†’ 102MB âœ…

#### æ¡ˆä¾‹ 2: æ—¥å¿—èšåˆèƒŒå‹é¢‘ç¹

**é—®é¢˜**:
- èƒŒå‹å‘Šè­¦é¢‘ç¹ (æ¯åˆ†é’Ÿ 50+ æ¬¡)
- Inbox åˆ©ç”¨ç‡: 95%
- é…ç½®: poolSize=256, inboxSize=1000

**åˆ†æ**:
- Inbox å¤ªå°,æ— æ³•ç¼“å†²çªå‘æµé‡
- ååé‡å—é™

**è§£å†³**:
```yaml
hollywood:
  poolSize: 512        # å¢åŠ  Actor æ•°é‡
  inboxSize: 5000      # å¢åŠ  Inbox,ç¼“å†²çªå‘
  # å†…å­˜: 512 Ã— 5000 Ã— 200B = 512MB
```

**ç»“æœ**:
- èƒŒå‹å‘Šè­¦: 50/min â†’ 0 âœ…
- ååé‡: 100K TPS â†’ 250K TPS âœ…
- å»¶è¿Ÿ: P99 50ms â†’ 80ms (å¯æ¥å—)

---

## ğŸ¯ **æ ¸å¿ƒä¼˜åŠ¿**

### ç›¸æ¯” Keyed Worker Pool

1. âœ… **Supervisor æœºåˆ¶**: Actor panic è‡ªåŠ¨é‡å¯,ä¸å½±å“å…¶ä»– Actor
2. âœ… **äº‹ä»¶æµç›‘æ§**: DeadLetter, ActorRestarted äº‹ä»¶
3. âœ… **æ¶ˆæ¯ä¿è¯**: Buffer æœºåˆ¶ç¡®ä¿æ¶ˆæ¯ä¸ä¸¢å¤± (Inbox æœªæ»¡æ—¶)
4. âœ… **æ•…éšœéš”ç¦»**: Actor çº§éš”ç¦» (ä¸€ä¸ª Actor panic ä¸å½±å“å…¶ä»– Actor)
   - âš ï¸ æ³¨æ„: å…±äº«åŒä¸€ Actor çš„èšåˆä»ä¼šç›¸äº’å½±å“ (å¤´éƒ¨é˜»å¡)
   - âœ… ä½†ä¼˜äº Worker çº§éš”ç¦» (Worker panic å½±å“æ‰€æœ‰è·¯ç”±åˆ°è¯¥ Worker çš„èšåˆ)
4. âœ… **æ›´å¥½çš„å¯è§‚æµ‹æ€§**: äº‹ä»¶æµ + è¯¦ç»†æŒ‡æ ‡ + Mailbox ç›‘æ§
5. âœ… **ä»£ç ç®€æ´**: Hollywood å°è£…äº†å¾ˆå¤šåº•å±‚ç»†èŠ‚
6. âœ… **çµæ´»è°ƒä¼˜**: Mailbox æ·±åº¦å¯æ ¹æ®ç›‘æ§åŠ¨æ€è°ƒæ•´

### ç›¸æ¯” "ä¸€ä¸ªèšåˆIDä¸€ä¸ªActor"

1. âœ… **å›ºå®šèµ„æº**: 256ä¸ªActor,å†…å­˜å¯æ§
2. âœ… **é€‚åˆåƒä¸‡çº§èšåˆ**: ä¸ä¼šåˆ›å»ºåƒä¸‡ä¸ªActor
3. âœ… **æ€§èƒ½ç¨³å®š**: èµ„æºå ç”¨å›ºå®š,æ— åŠ¨æ€åˆ›å»º/é”€æ¯å¼€é”€
4. âœ… **ç®€å•éƒ¨ç½²**: å•æœºéƒ¨ç½²,æ— åˆ†å¸ƒå¼å¤æ‚åº¦
5. âœ… **Mailbox å¯é¢„æµ‹**: æ€»å†…å­˜ = poolSize Ã— inboxSize Ã— avgMessageSize

---

## ğŸš€ **è¿ç§»æ­¥éª¤**

### Phase 1: å®ç° (2-3å¤©)

1. å®ç° `hollywood_actor_pool.go`
2. å®ç° `pool_actor.go`
3. å®ç° `hollywood_pool_metrics.go`
4. é›†æˆåˆ° `kafka.go` å’Œ `nats.go`

### Phase 2: æµ‹è¯• (2-3å¤©)

1. å•å…ƒæµ‹è¯•
2. é›†æˆæµ‹è¯•
3. æ€§èƒ½æµ‹è¯•

### Phase 3: ç°åº¦ä¸Šçº¿ (1-2å¤©)

1. ç‰¹æ€§å¼€å…³: `useHollywood: false` â†’ `true`
2. ç›‘æ§å¯¹æ¯”
3. å…¨é‡ä¸Šçº¿

**æ€»å·¥æœŸ: 5-8å¤©**

---

## ğŸš¨ **æ•…éšœåœºæ™¯åˆ†æ**

### åœºæ™¯ 1: Actor Panic

**ç°è±¡**: Actor å¤„ç†æ¶ˆæ¯æ—¶ panic

**å¤„ç†æµç¨‹**:
1. Supervisor æ•è· panic
2. è®°å½• `actor_restarted` æŒ‡æ ‡
3. è‡ªåŠ¨é‡å¯ Actor (æœ€å¤š 3 æ¬¡)
4. é‡å¯æœŸé—´æ¶ˆæ¯ç¼“å­˜åœ¨ Inbox
5. é‡å¯æˆåŠŸåç»§ç»­å¤„ç†

**ç›‘æ§æŒ‡æ ‡**:
```promql
# Actor é‡å¯æ¬¡æ•°
rate(actor_pool_actors_restarted_total[5m])

# Actor é‡å¯é¢‘ç‡å‘Šè­¦
rate(actor_pool_actors_restarted_total[5m]) > 0.1
```

**å¤„ç†å»ºè®®**:
- é‡å¯é¢‘ç‡ < 1æ¬¡/åˆ†é’Ÿ: æ­£å¸¸,æ— éœ€å¤„ç†
- é‡å¯é¢‘ç‡ > 5æ¬¡/åˆ†é’Ÿ: å‘Šè­¦,æ£€æŸ¥ä¸šåŠ¡ä»£ç 
- é‡å¯é¢‘ç‡ > 10æ¬¡/åˆ†é’Ÿ: ä¸¥é‡,è€ƒè™‘å›æ»š

---

### åœºæ™¯ 2: Inbox æ»¡è½½

**ç°è±¡**: Inbox é˜Ÿåˆ—æ»¡ (1000æ¡æ¶ˆæ¯)

**å¤„ç†æµç¨‹**:
1. è§¦å‘èƒŒå‹,é˜»å¡å‘é€æ–¹
2. è®°å½• `inbox_full` æŒ‡æ ‡
3. å‘Šè­¦é€šçŸ¥è¿ç»´
4. è¿ç»´ä»‹å…¥: å¢åŠ  inboxSize æˆ– poolSize

**ç›‘æ§æŒ‡æ ‡**:
```promql
# Inbox åˆ©ç”¨ç‡
avg(actor_pool_inbox_utilization)

# Inbox æ»¡è½½é¢‘ç‡
rate(actor_pool_inbox_full_total[5m])

# Inbox æ»¡è½½å‘Šè­¦
rate(actor_pool_inbox_full_total[5m]) > 10
```

**å¤„ç†å»ºè®®**:
- Inbox åˆ©ç”¨ç‡ < 0.8: æ­£å¸¸
- Inbox åˆ©ç”¨ç‡ > 0.8: è€ƒè™‘å¢åŠ  inboxSize
- Inbox æ»¡è½½é¢‘ç‡ > 10æ¬¡/åˆ†é’Ÿ: å¢åŠ  poolSize æˆ– inboxSize

---

### åœºæ™¯ 3: Supervisor é‡å¯å¤±è´¥

**ç°è±¡**: Actor é‡å¯ 3 æ¬¡åä»ç„¶å¤±è´¥

**å¤„ç†æµç¨‹**:
1. Actor åœæ­¢
2. åç»­æ¶ˆæ¯è·¯ç”±åˆ°æ­»ä¿¡é˜Ÿåˆ—
3. è®°å½• `dead_letter` æŒ‡æ ‡
4. å‘Šè­¦é€šçŸ¥è¿ç»´
5. è¿ç»´ä»‹å…¥: ä¿®å¤ä»£ç æˆ–æ•°æ®

**ç›‘æ§æŒ‡æ ‡**:
```promql
# æ­»ä¿¡æ•°é‡
rate(actor_pool_dead_letters_total[5m])

# æ­»ä¿¡å‘Šè­¦
rate(actor_pool_dead_letters_total[5m]) > 1
```

**å¤„ç†å»ºè®®**:
- ç«‹å³å‘Šè­¦
- æ£€æŸ¥ä¸šåŠ¡ä»£ç 
- æ£€æŸ¥æ•°æ®æ˜¯å¦å¼‚å¸¸
- ä¿®å¤åé‡å¯æœåŠ¡

---

### åœºæ™¯ 4: å†…å­˜å ç”¨è¿‡é«˜

**ç°è±¡**: å†…å­˜å ç”¨ > 2GB (æ­£å¸¸ < 100MB)

**å¯èƒ½åŸå› **:
1. inboxSize è®¾ç½®è¿‡å¤§
2. æ¶ˆæ¯ç§¯å‹ä¸¥é‡
3. å†…å­˜æ³„æ¼

**å¤„ç†æµç¨‹**:
1. æ£€æŸ¥ Inbox æ·±åº¦
2. æ£€æŸ¥æ¶ˆæ¯å¤„ç†é€Ÿåº¦
3. æ£€æŸ¥æ˜¯å¦æœ‰å†…å­˜æ³„æ¼
4. è°ƒæ•´ inboxSize æˆ– poolSize

**ç›‘æ§æŒ‡æ ‡**:
```promql
# å†…å­˜å ç”¨
process_resident_memory_bytes

# Inbox æ·±åº¦
avg(actor_pool_inbox_depth)
```

---

## âœ… **æ€»ç»“**

è¿™ä¸ªæ–¹æ¡ˆ:
- âœ… **è§£å†³äº†åƒä¸‡çº§èšåˆIDé—®é¢˜**: ä½¿ç”¨å›ºå®š Actor Pool
- âœ… **ä¿æŒäº†èµ„æºå¯æ§**: 256ä¸ªActor,å†…å­˜å›ºå®š
- âœ… **è·å¾—äº† Hollywood ä¼˜åŠ¿**: Supervisor + äº‹ä»¶æµ + æ¶ˆæ¯ä¿è¯
- âœ… **ç®€åŒ–äº†éƒ¨ç½²**: å•æœºéƒ¨ç½²,æ— åˆ†å¸ƒå¼å¤æ‚åº¦
- âœ… **è¿ç§»æˆæœ¬ä½**: æ¶æ„ç±»ä¼¼ Keyed Worker Pool,æ”¹åŠ¨å°

### é‡è¦è¯´æ˜

âš ï¸ **æ€§èƒ½ä¸æ¶æ„é™åˆ¶**:

1. **æ€§èƒ½æŒå¹³**: å›ºå®š Actor Pool ä¸ Keyed Worker Pool åœ¨æ€§èƒ½ä¸Š**åŸºæœ¬æŒå¹³** (Â±5%)
   - æ¶æ„è·¯ç”±ç›¸åŒ,ååé‡å’Œå»¶è¿Ÿä¸ä¼šæœ‰æ˜¾è‘—æå‡
   - Supervisor/Middleware å¯èƒ½å¼•å…¥è½»å¾®å¼€é”€ (é€šå¸¸ < 5%)

2. **å¤´éƒ¨é˜»å¡**: å›ºå®š Actor Pool ä¸ Keyed Worker Pool åœ¨å¤´éƒ¨é˜»å¡é—®é¢˜ä¸Š**å®Œå…¨ç›¸åŒ**
   - ä¸¤è€…éƒ½ä½¿ç”¨ Hash(aggregateID) % 256 è·¯ç”±
   - ä¸åŒèšåˆIDå¯èƒ½è·¯ç”±åˆ°åŒä¸€ä¸ª Actor/Worker
   - Actor/Worker å†…éƒ¨ä¸²è¡Œå¤„ç†,å­˜åœ¨å¤´éƒ¨é˜»å¡
   - è¿™æ˜¯åƒä¸‡çº§èšåˆIDåœºæ™¯ä¸‹çš„å¿…ç„¶æƒè¡¡

3. **æ•…éšœéš”ç¦»**: Actor çº§éš”ç¦»ä¼˜äº Worker çº§,ä½†**éå®Œç¾éš”ç¦»**
   - âœ… ä¸€ä¸ª Actor panic ä¸å½±å“å…¶ä»– Actor (Supervisor è‡ªåŠ¨é‡å¯)
   - âŒ å…±äº«åŒä¸€ Actor çš„èšåˆä»ä¼šç›¸äº’å½±å“ (å¤´éƒ¨é˜»å¡)

âœ… **æ ¸å¿ƒä»·å€¼**: ä¸åœ¨äºæ€§èƒ½æå‡,è€Œåœ¨äº **Supervisor æœºåˆ¶ã€äº‹ä»¶æµç›‘æ§ã€æ¶ˆæ¯ä¿è¯ã€æ›´å¥½çš„æ•…éšœéš”ç¦»ä¸å¯è§‚æµ‹æ€§**

**è¿™æ˜¯æœ€é€‚åˆ jxt-core åƒä¸‡çº§èšåˆIDåœºæ™¯çš„æ–¹æ¡ˆ!** ğŸ¯

