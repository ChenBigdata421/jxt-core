package eventbus

import (
	"context"
	"encoding/json"
	"fmt"
	"sync/atomic"
	"testing"
	"time"
)

// TestConsumerWarmupAnalysis åˆ†æConsumeré¢„çƒ­é—®é¢˜
func TestConsumerWarmupAnalysis(t *testing.T) {
	config := &KafkaConfig{
		Brokers:  []string{"localhost:29094"},
		ClientID: "warmup-analysis-test",
		Producer: ProducerConfig{
			MaxMessageBytes: 1024 * 1024,
			RequiredAcks:    1,
			Timeout:         5 * time.Second,
			Compression:     "none",
			MaxInFlight:     10,
		},
		Consumer: ConsumerConfig{
			GroupID:            "warmup-analysis-group",
			AutoOffsetReset:    "earliest",
			SessionTimeout:     6 * time.Second,
			HeartbeatInterval:  2 * time.Second,
			MaxProcessingTime:  3 * time.Second,
			FetchMinBytes:      1024 * 1024,
			FetchMaxBytes:      50 * 1024 * 1024,
			FetchMaxWait:       50 * time.Millisecond,
			MaxPollRecords:     1000,
			EnableAutoCommit:   true,
			AutoCommitInterval: 500 * time.Millisecond,
		},
	}

	eventBus, err := NewKafkaEventBus(config)
	if err != nil {
		t.Fatalf("Failed to create EventBus: %v", err)
	}
	defer eventBus.Close()

	kafkaBus := eventBus.(*kafkaEventBus)
	testTopic := "warmup.analysis.test"
	kafkaBus.allPossibleTopics = []string{testTopic}

	ctx, cancel := context.WithTimeout(context.Background(), 2*time.Minute)
	defer cancel()

	// è®°å½•æ—¶é—´ç‚¹
	var (
		subscribeTime    time.Time
		firstMessageTime time.Time
		receivedCount    int64
	)

	handler := func(ctx context.Context, message []byte) error {
		if atomic.AddInt64(&receivedCount, 1) == 1 {
			firstMessageTime = time.Now()
		}
		return nil
	}

	t.Logf("ğŸ” Starting Consumer Warmup Analysis...")

	// 1. è®°å½•è®¢é˜…æ—¶é—´
	subscribeStart := time.Now()
	err = eventBus.Subscribe(ctx, testTopic, handler)
	if err != nil {
		t.Fatalf("Failed to subscribe: %v", err)
	}
	subscribeTime = time.Now()
	subscribeLatency := subscribeTime.Sub(subscribeStart)

	t.Logf("ğŸ“Š Subscribe completed in: %v", subscribeLatency)

	// 2. æµ‹è¯•ä¸åŒé¢„çƒ­æ—¶é—´çš„æ•ˆæœ
	warmupTimes := []time.Duration{
		0 * time.Second,    // æ— é¢„çƒ­
		1 * time.Second,    // 1ç§’é¢„çƒ­
		3 * time.Second,    // 3ç§’é¢„çƒ­
		5 * time.Second,    // 5ç§’é¢„çƒ­
		10 * time.Second,   // 10ç§’é¢„çƒ­
	}

	for _, warmupTime := range warmupTimes {
		t.Logf("\nğŸ§ª Testing with %v warmup time...", warmupTime)
		
		// é‡ç½®è®¡æ•°å™¨
		atomic.StoreInt64(&receivedCount, 0)
		firstMessageTime = time.Time{}

		// é¢„çƒ­ç­‰å¾…
		if warmupTime > 0 {
			t.Logf("â³ Warming up for %v...", warmupTime)
			time.Sleep(warmupTime)
		}

		// å‘é€æµ‹è¯•æ¶ˆæ¯
		messageCount := 50
		sendStart := time.Now()
		
		for i := 0; i < messageCount; i++ {
			message := map[string]interface{}{
				"id":       fmt.Sprintf("warmup-msg-%d", i),
				"content":  fmt.Sprintf("Warmup test message %d", i),
				"sendTime": time.Now().Format(time.RFC3339Nano),
				"index":    i,
			}

			messageBytes, _ := json.Marshal(message)
			err := eventBus.Publish(ctx, testTopic, messageBytes)
			if err != nil {
				t.Logf("Failed to publish message %d: %v", i, err)
			}
		}
		sendEnd := time.Now()
		sendDuration := sendEnd.Sub(sendStart)

		t.Logf("ğŸ“¤ Sent %d messages in %v (%.2f msg/s)", 
			messageCount, sendDuration, float64(messageCount)/sendDuration.Seconds())

		// ç­‰å¾…æ¶ˆæ¯å¤„ç†
		waitTime := 15 * time.Second
		time.Sleep(waitTime)

		// åˆ†æç»“æœ
		finalCount := atomic.LoadInt64(&receivedCount)
		successRate := float64(finalCount) / float64(messageCount) * 100

		var firstMessageLatency time.Duration
		if !firstMessageTime.IsZero() {
			firstMessageLatency = firstMessageTime.Sub(sendStart)
		}

		t.Logf("ğŸ“Š Results for %v warmup:", warmupTime)
		t.Logf("   ğŸ“¥ Received: %d/%d (%.2f%%)", finalCount, messageCount, successRate)
		t.Logf("   â±ï¸  First message latency: %v", firstMessageLatency)
		t.Logf("   ğŸš€ Effective throughput: %.2f msg/s", 
			float64(finalCount)/waitTime.Seconds())
	}
}

// TestProducerBottleneckAnalysis åˆ†æProducerç“¶é¢ˆ
func TestProducerBottleneckAnalysis(t *testing.T) {
	configs := []struct {
		name        string
		maxInFlight int
		compression string
	}{
		{"Default", 10, "none"},
		{"HighConcurrency", 50, "none"},
		{"WithCompression", 10, "snappy"},
		{"Optimized", 50, "snappy"},
	}

	for _, cfg := range configs {
		t.Logf("\nğŸ§ª Testing Producer config: %s", cfg.name)
		
		config := &KafkaConfig{
			Brokers:  []string{"localhost:29094"},
			ClientID: fmt.Sprintf("producer-analysis-%s", cfg.name),
			Producer: ProducerConfig{
				MaxMessageBytes: 1024 * 1024,
				RequiredAcks:    1,
				Timeout:         5 * time.Second,
				Compression:     cfg.compression,
				MaxInFlight:     cfg.maxInFlight,
			},
			Consumer: ConsumerConfig{
				GroupID:            fmt.Sprintf("producer-analysis-%s-group", cfg.name),
				AutoOffsetReset:    "earliest",
				SessionTimeout:     6 * time.Second,
				HeartbeatInterval:  2 * time.Second,
				MaxProcessingTime:  3 * time.Second,
			},
		}

		eventBus, err := NewKafkaEventBus(config)
		if err != nil {
			t.Fatalf("Failed to create EventBus: %v", err)
		}

		testTopic := fmt.Sprintf("producer.analysis.%s", cfg.name)
		ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)

		// æµ‹è¯•å‘é€æ€§èƒ½
		messageCount := 200
		sendStart := time.Now()
		errors := 0

		for i := 0; i < messageCount; i++ {
			message := map[string]interface{}{
				"id":      fmt.Sprintf("producer-msg-%d", i),
				"content": fmt.Sprintf("Producer test message %d", i),
				"config":  cfg.name,
			}

			messageBytes, _ := json.Marshal(message)
			err := eventBus.Publish(ctx, testTopic, messageBytes)
			if err != nil {
				errors++
				if errors <= 5 {
					t.Logf("Publish error %d: %v", errors, err)
				}
			}
		}

		sendEnd := time.Now()
		sendDuration := sendEnd.Sub(sendStart)
		sendRate := float64(messageCount-errors) / sendDuration.Seconds()

		t.Logf("ğŸ“Š Producer Results for %s:", cfg.name)
		t.Logf("   ğŸ“¤ Sent: %d/%d (%.2f%% success)", messageCount-errors, messageCount, 
			float64(messageCount-errors)/float64(messageCount)*100)
		t.Logf("   â±ï¸  Duration: %v", sendDuration)
		t.Logf("   ğŸš€ Send rate: %.2f msg/s", sendRate)
		t.Logf("   âš ï¸ Errors: %d", errors)

		eventBus.Close()
		cancel()
	}
}

// TestBatchProcessingAnalysis åˆ†ææ‰¹é‡å¤„ç†æ•ˆåº”
func TestBatchProcessingAnalysis(t *testing.T) {
	batchSizes := []int{100, 500, 1000, 2000}

	for _, batchSize := range batchSizes {
		t.Logf("\nğŸ§ª Testing batch size: %d", batchSize)

		config := &KafkaConfig{
			Brokers:  []string{"localhost:29094"},
			ClientID: fmt.Sprintf("batch-analysis-%d", batchSize),
			Producer: ProducerConfig{
				MaxMessageBytes: 1024 * 1024,
				RequiredAcks:    1,
				Timeout:         5 * time.Second,
				Compression:     "none",
				MaxInFlight:     10,
			},
			Consumer: ConsumerConfig{
				GroupID:            fmt.Sprintf("batch-analysis-%d-group", batchSize),
				AutoOffsetReset:    "earliest",
				SessionTimeout:     6 * time.Second,
				HeartbeatInterval:  2 * time.Second,
				MaxProcessingTime:  3 * time.Second,
				FetchMinBytes:      1024 * 1024,
				FetchMaxBytes:      50 * 1024 * 1024,
				FetchMaxWait:       50 * time.Millisecond,
				MaxPollRecords:     batchSize,
				EnableAutoCommit:   true,
				AutoCommitInterval: 500 * time.Millisecond,
			},
		}

		eventBus, err := NewKafkaEventBus(config)
		if err != nil {
			t.Fatalf("Failed to create EventBus: %v", err)
		}

		kafkaBus := eventBus.(*kafkaEventBus)
		testTopic := fmt.Sprintf("batch.analysis.%d", batchSize)
		kafkaBus.allPossibleTopics = []string{testTopic}

		ctx, cancel := context.WithTimeout(context.Background(), 45*time.Second)

		var receivedCount int64
		handler := func(ctx context.Context, message []byte) error {
			atomic.AddInt64(&receivedCount, 1)
			return nil
		}

		err = eventBus.Subscribe(ctx, testTopic, handler)
		if err != nil {
			t.Fatalf("Failed to subscribe: %v", err)
		}

		// é¢„çƒ­
		time.Sleep(5 * time.Second)

		// å‘é€æ¶ˆæ¯
		messageCount := 500
		sendStart := time.Now()

		for i := 0; i < messageCount; i++ {
			message := map[string]interface{}{
				"id":        fmt.Sprintf("batch-msg-%d", i),
				"content":   fmt.Sprintf("Batch test message %d", i),
				"batchSize": batchSize,
			}

			messageBytes, _ := json.Marshal(message)
			err := eventBus.Publish(ctx, testTopic, messageBytes)
			if err != nil {
				t.Logf("Failed to publish message %d: %v", i, err)
			}
		}

		sendEnd := time.Now()
		sendDuration := sendEnd.Sub(sendStart)

		// ç­‰å¾…å¤„ç†
		time.Sleep(20 * time.Second)

		finalCount := atomic.LoadInt64(&receivedCount)
		successRate := float64(finalCount) / float64(messageCount) * 100
		throughput := float64(finalCount) / (time.Since(sendStart).Seconds())

		t.Logf("ğŸ“Š Batch Results for size %d:", batchSize)
		t.Logf("   ğŸ“¤ Send rate: %.2f msg/s", float64(messageCount)/sendDuration.Seconds())
		t.Logf("   ğŸ“¥ Received: %d/%d (%.2f%%)", finalCount, messageCount, successRate)
		t.Logf("   ğŸš€ Throughput: %.2f msg/s", throughput)

		eventBus.Close()
		cancel()
	}
}
