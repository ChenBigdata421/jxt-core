package eventbus

import (
	"context"
	"encoding/json"
	"fmt"
	"sync"
	"sync/atomic"
	"testing"
	"time"

	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

// TestKafkaUnifiedConsumerSimple ç®€åŒ–çš„UnifiedConsumeræµ‹è¯•
func TestKafkaUnifiedConsumerSimple(t *testing.T) {
	t.Log("ğŸš€ å¼€å§‹Kafka UnifiedConsumerç®€åŒ–æµ‹è¯•")

	// åˆ›å»ºç®€åŒ–çš„Kafkaé…ç½®
	kafkaConfig := &KafkaConfig{
		Brokers: []string{"localhost:29092"},
		Producer: ProducerConfig{
			RequiredAcks:     1,
			Compression:      "none",
			FlushFrequency:   50 * time.Millisecond,
			FlushMessages:    10,
			Timeout:          10 * time.Second,
			FlushBytes:       1024,
			RetryMax:         1,
			BatchSize:        1024,
			BufferSize:       1024 * 1024,
			Idempotent:       false,
			MaxMessageBytes:  1024 * 1024,
			PartitionerType:  "hash",
			LingerMs:         0,
			CompressionLevel: 1,
			MaxInFlight:      5,
		},
		Consumer: ConsumerConfig{
			GroupID:           "simple-test-group",
			AutoOffsetReset:   "earliest",
			SessionTimeout:    10 * time.Second,
			HeartbeatInterval: 3 * time.Second,
			MaxProcessingTime: 5 * time.Second,
			FetchMinBytes:     1,
			FetchMaxBytes:     1024 * 1024,
			FetchMaxWait:      250 * time.Millisecond,
		},
		ClientID:            "simple-test-client",
		HealthCheckInterval: 30 * time.Second,
	}

	// åˆ›å»ºEventBus
	eventBus, err := NewKafkaEventBus(kafkaConfig)
	require.NoError(t, err)
	defer eventBus.Close()

	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	// æµ‹è¯•é…ç½®
	topicCount := 3
	messagesPerTopic := 10
	aggregateCount := 5

	// ç”Ÿæˆtopicåˆ—è¡¨
	topics := make([]string, topicCount)
	for i := 0; i < topicCount; i++ {
		topics[i] = fmt.Sprintf("simple-test-topic-%d", i)
	}

	// æ¶ˆæ¯è®¡æ•°å™¨
	var receivedCount int64
	var processedMessages sync.Map

	// è®¾ç½®è®¢é˜…è€…
	t.Log("ğŸ“¡ è®¾ç½®è®¢é˜…è€…...")
	for _, topic := range topics {
		topicName := topic // é¿å…é—­åŒ…é—®é¢˜
		handler := func(ctx context.Context, message []byte) error {
			// è§£ææ¶ˆæ¯
			var envelope SimpleTestEnvelope
			if err := json.Unmarshal(message, &envelope); err != nil {
				t.Logf("âŒ è§£ææ¶ˆæ¯å¤±è´¥: %v", err)
				return err
			}

			// è®°å½•æ¶ˆæ¯
			key := fmt.Sprintf("%s-%s-%d", topicName, envelope.AggregateID, envelope.Sequence)
			processedMessages.Store(key, envelope)
			
			count := atomic.AddInt64(&receivedCount, 1)
			if count%10 == 0 {
				t.Logf("ğŸ“¨ å·²å¤„ç† %d æ¡æ¶ˆæ¯", count)
			}
			
			return nil
		}

		err := eventBus.Subscribe(ctx, topicName, handler)
		require.NoError(t, err)
	}

	// ç­‰å¾…è®¢é˜…è€…å‡†å¤‡å°±ç»ª
	time.Sleep(2 * time.Second)

	// å‘é€æµ‹è¯•æ¶ˆæ¯
	t.Log("ğŸ“¤ å‘é€æµ‹è¯•æ¶ˆæ¯...")
	totalMessages := topicCount * messagesPerTopic
	
	for i, topic := range topics {
		for j := 0; j < messagesPerTopic; j++ {
			aggregateID := fmt.Sprintf("agg-%d", j%aggregateCount)
			envelope := SimpleTestEnvelope{
				AggregateID: aggregateID,
				EventType:   "TestEvent",
				Sequence:    int64(j),
				Timestamp:   time.Now(),
				Data:        fmt.Sprintf("Test data for topic %d, message %d", i, j),
			}

			messageBytes, err := json.Marshal(envelope)
			require.NoError(t, err)

			err = eventBus.Publish(ctx, topic, messageBytes)
			require.NoError(t, err)
		}
	}

	t.Logf("âœ… å‘é€å®Œæˆï¼Œæ€»è®¡ %d æ¡æ¶ˆæ¯", totalMessages)

	// ç­‰å¾…æ¶ˆæ¯å¤„ç†å®Œæˆ
	t.Log("â³ ç­‰å¾…æ¶ˆæ¯å¤„ç†å®Œæˆ...")
	timeout := time.After(20 * time.Second)
	ticker := time.NewTicker(1 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-timeout:
			t.Logf("âš ï¸ ç­‰å¾…è¶…æ—¶ï¼Œå·²å¤„ç† %d/%d æ¡æ¶ˆæ¯", atomic.LoadInt64(&receivedCount), totalMessages)
			goto validate
		case <-ticker.C:
			received := atomic.LoadInt64(&receivedCount)
			t.Logf("ğŸ“Š è¿›åº¦: %d/%d æ¡æ¶ˆæ¯", received, totalMessages)
			if received >= int64(totalMessages) {
				t.Log("âœ… æ‰€æœ‰æ¶ˆæ¯å¤„ç†å®Œæˆ")
				goto validate
			}
		}
	}

validate:
	// éªŒè¯ç»“æœ
	t.Log("ğŸ” éªŒè¯æµ‹è¯•ç»“æœ...")
	
	finalCount := atomic.LoadInt64(&receivedCount)
	t.Logf("ğŸ“ˆ æœ€ç»ˆç»Ÿè®¡: æ”¶åˆ° %d/%d æ¡æ¶ˆæ¯", finalCount, totalMessages)
	
	// åŸºæœ¬éªŒè¯
	assert.True(t, finalCount > 0, "åº”è¯¥æ”¶åˆ°è‡³å°‘ä¸€äº›æ¶ˆæ¯")
	
	if finalCount >= int64(totalMessages) {
		t.Log("ğŸ‰ æµ‹è¯•å®Œå…¨æˆåŠŸï¼æ‰€æœ‰æ¶ˆæ¯éƒ½å·²å¤„ç†")
	} else {
		t.Logf("âš ï¸ éƒ¨åˆ†æˆåŠŸï¼šå¤„ç†äº† %.1f%% çš„æ¶ˆæ¯", float64(finalCount)/float64(totalMessages)*100)
	}

	// éªŒè¯æ¶ˆæ¯å†…å®¹
	messageCount := 0
	processedMessages.Range(func(key, value interface{}) bool {
		messageCount++
		return true
	})
	
	t.Logf("ğŸ“‹ æ¶ˆæ¯è¯¦æƒ…: å­˜å‚¨äº† %d æ¡æœ‰æ•ˆæ¶ˆæ¯", messageCount)
	
	// è¾“å‡ºæµ‹è¯•æ€»ç»“
	separator := "=================================================="
	t.Log("\n" + separator)
	t.Log("ğŸ¯ Kafka UnifiedConsumer ç®€åŒ–æµ‹è¯•æ€»ç»“")
	t.Log(separator)
	t.Logf("âœ… Kafkaè¿æ¥: æˆåŠŸ")
	t.Logf("âœ… å¤šTopicè®¢é˜…: %dä¸ªtopic", topicCount)
	t.Logf("âœ… æ¶ˆæ¯å‘é€: %dæ¡æ¶ˆæ¯", totalMessages)
	t.Logf("âœ… æ¶ˆæ¯æ¥æ”¶: %dæ¡æ¶ˆæ¯", finalCount)
	t.Logf("âœ… æˆåŠŸç‡: %.1f%%", float64(finalCount)/float64(totalMessages)*100)
	t.Log(separator)
}

// SimpleTestEnvelope ç®€åŒ–æµ‹è¯•ç”¨çš„æ¶ˆæ¯å°è£…
type SimpleTestEnvelope struct {
	AggregateID string    `json:"aggregateId"`
	EventType   string    `json:"eventType"`
	Sequence    int64     `json:"sequence"`
	Timestamp   time.Time `json:"timestamp"`
	Data        string    `json:"data"`
}
