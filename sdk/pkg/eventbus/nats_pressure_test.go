package eventbus

import (
	"context"
	"encoding/json"
	"fmt"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
	"runtime"
	"sync"
	"sync/atomic"
	"testing"
	"time"
)

// ğŸ¯ NATS JetStream é«˜å‹åŠ›æµ‹è¯•
// ä¸Kafkaé«˜å‹åŠ›æµ‹è¯•è¿›è¡Œå…¬å¹³å¯¹æ¯”
// NATSHighPressureMetrics NATSé«˜å‹åŠ›æµ‹è¯•æŒ‡æ ‡
type NATSHighPressureMetrics struct {
	// å‘é€æŒ‡æ ‡
	MessagesSent     int64 // å‘é€æ¶ˆæ¯æ€»æ•°
	SendErrors       int64 // å‘é€é”™è¯¯æ•°
	SendLatencySum   int64 // å‘é€å»¶è¿Ÿæ€»å’Œ(å¾®ç§’)
	SendLatencyCount int64 // å‘é€å»¶è¿Ÿè®¡æ•°
	// æ¥æ”¶æŒ‡æ ‡
	MessagesReceived    int64 // æ¥æ”¶æ¶ˆæ¯æ€»æ•°
	ProcessErrors       int64 // å¤„ç†é”™è¯¯æ•°
	ProcessLatencySum   int64 // å¤„ç†å»¶è¿Ÿæ€»å’Œ(å¾®ç§’)
	ProcessLatencyCount int64 // å¤„ç†å»¶è¿Ÿè®¡æ•°
	// æ€§èƒ½æŒ‡æ ‡
	StartTime         time.Time // å¼€å§‹æ—¶é—´
	EndTime           time.Time // ç»“æŸæ—¶é—´
	OrderViolations   int64     // é¡ºåºè¿åæ¬¡æ•°
	DuplicateMessages int64     // é‡å¤æ¶ˆæ¯æ¬¡æ•°
}

// NATSHighPressureTestMessage NATSé«˜å‹åŠ›æµ‹è¯•æ¶ˆæ¯
type NATSHighPressureTestMessage struct {
	ID        string    `json:"id"`
	Topic     string    `json:"topic"`
	Sequence  int64     `json:"sequence"`
	Timestamp time.Time `json:"timestamp"`
	Data      string    `json:"data"`
}

// TestNATSJetStreamHighPressure NATS JetStreamé«˜å‹åŠ›æµ‹è¯•
func TestNATSJetStreamHighPressure(t *testing.T) {
	if testing.Short() {
		t.Skip("Skipping NATS JetStream high pressure test in short mode")
	}
	metrics := &NATSHighPressureMetrics{
		StartTime: time.Now(),
	}
	// ğŸš€ NATS JetStreamé«˜æ€§èƒ½é…ç½®
	natsConfig := &NATSConfig{
		URLs:                []string{"nats://localhost:4223"},
		ClientID:            "nats-jetstream-high-pressure-client",
		MaxReconnects:       10,
		ReconnectWait:       1 * time.Second,
		ConnectionTimeout:   30 * time.Second,
		HealthCheckInterval: 60 * time.Second,
		JetStream: JetStreamConfig{
			Enabled: true, // å¯ç”¨JetStream
			Stream: StreamConfig{
				Name:      "HIGH_PRESSURE_STREAM",
				Subjects:  []string{"high.pressure.>"},
				Storage:   "memory", // ä½¿ç”¨å†…å­˜å­˜å‚¨ä»¥è·å¾—æœ€é«˜æ€§èƒ½
				Retention: "limits",
				MaxAge:    24 * time.Hour,
				MaxBytes:  100 * 1024 * 1024, // 100MB
				MaxMsgs:   100000,
				Replicas:  1, // å•å‰¯æœ¬ä»¥è·å¾—æœ€é«˜æ€§èƒ½
				Discard:   "old",
			},
			Consumer: NATSConsumerConfig{
				DurableName:   "high-pressure-consumer",
				DeliverPolicy: "all",
				AckPolicy:     "explicit",
				ReplayPolicy:  "instant",
				MaxAckPending: 1000, // å¢åŠ å¾…ç¡®è®¤æ¶ˆæ¯æ•°
				MaxWaiting:    512,
				MaxDeliver:    3,
				BackOff:       []time.Duration{1 * time.Second, 2 * time.Second, 4 * time.Second},
			},
			PublishTimeout: 10 * time.Second,
		},
	}
	eventBus, err := NewNATSEventBus(natsConfig)
	require.NoError(t, err, "Failed to create NATS JetStream EventBus")
	defer eventBus.Close()
	// ç­‰å¾…JetStreamåˆå§‹åŒ–
	t.Logf("â³ Waiting for NATS JetStream to initialize...")
	time.Sleep(5 * time.Second)
	t.Logf("ğŸš€ Starting NATS JetStream High Pressure Test")
	// è¿è¡Œé«˜å‹åŠ›æµ‹è¯• - ä¸Kafkaç›¸åŒçš„å‚æ•°
	runNATSHighPressureTest(t, eventBus, metrics)
	// åˆ†æç»“æœ
	analyzeNATSHighPressureResults(t, metrics)
}

// runNATSHighPressureTest è¿è¡ŒNATSé«˜å‹åŠ›æµ‹è¯•
func runNATSHighPressureTest(t *testing.T, eventBus EventBus, metrics *NATSHighPressureMetrics) {
	ctx, cancel := context.WithTimeout(context.Background(), 120*time.Second)
	defer cancel()
	// ğŸ”¥ ä¸Kafkaæµ‹è¯•ç›¸åŒçš„å‚æ•°
	topics := []string{
		"high.pressure.topic.1",
		"high.pressure.topic.2",
		"high.pressure.topic.3",
		"high.pressure.topic.4",
		"high.pressure.topic.5",
	}
	messagesPerTopic := 2000 // æ¯ä¸ªtopic 2000æ¡æ¶ˆæ¯ï¼Œæ€»è®¡10,000æ¡
	t.Logf("ğŸ“Š Test Config: %d topics, %d msgs/topic, total: %d messages",
		len(topics), messagesPerTopic, len(topics)*messagesPerTopic)
	// è®¾ç½®æ¶ˆæ¯å¤„ç†å™¨
	var wg sync.WaitGroup
	setupNATSHighPressureHandlers(t, eventBus, topics, metrics, &wg)
	// ç­‰å¾…è®¢é˜…å»ºç«‹
	t.Logf("â³ Waiting for subscriptions to stabilize...")
	time.Sleep(3 * time.Second)
	// å¼€å§‹å‘é€æ¶ˆæ¯
	metrics.StartTime = time.Now()
	sendNATSHighPressureMessages(t, eventBus, topics, messagesPerTopic, metrics)
	// ç­‰å¾…æ¶ˆæ¯å¤„ç†å®Œæˆ
	done := make(chan struct{})
	go func() {
		wg.Wait()
		close(done)
	}()
	select {
	case <-done:
		t.Logf("âœ… All messages processed successfully")
	case <-time.After(90 * time.Second):
		t.Logf("â° Test timeout reached")
	case <-ctx.Done():
		t.Logf("ğŸ›‘ Context cancelled")
	}
	metrics.EndTime = time.Now()
}

// setupNATSHighPressureHandlers è®¾ç½®NATSé«˜å‹åŠ›å¤„ç†å™¨
func setupNATSHighPressureHandlers(t *testing.T, eventBus EventBus, topics []string, metrics *NATSHighPressureMetrics, wg *sync.WaitGroup) {
	for _, topic := range topics {
		wg.Add(1)
		go func(topicName string) {
			defer wg.Done()
			var lastSequence int64 = -1
			receivedMessages := make(map[string]bool) // æ£€æµ‹é‡å¤æ¶ˆæ¯
			handler := func(ctx context.Context, message []byte) error {
				// è§£ææ¶ˆæ¯
				var testMsg NATSHighPressureTestMessage
				if err := json.Unmarshal(message, &testMsg); err != nil {
					atomic.AddInt64(&metrics.ProcessErrors, 1)
					return err
				}
				// æ£€æµ‹é‡å¤æ¶ˆæ¯
				if receivedMessages[testMsg.ID] {
					atomic.AddInt64(&metrics.DuplicateMessages, 1)
					t.Logf("âš ï¸ Duplicate message detected: %s in topic %s", testMsg.ID, topicName)
				}
				receivedMessages[testMsg.ID] = true
				// æ£€æµ‹é¡ºåºè¿å
				if lastSequence >= 0 && testMsg.Sequence <= lastSequence {
					atomic.AddInt64(&metrics.OrderViolations, 1)
				}
				lastSequence = testMsg.Sequence
				// è®°å½•å¤„ç†å»¶è¿Ÿ
				processingTime := time.Since(testMsg.Timestamp).Microseconds()
				atomic.AddInt64(&metrics.ProcessLatencySum, processingTime)
				atomic.AddInt64(&metrics.ProcessLatencyCount, 1)
				// æ›´æ–°æ¥æ”¶è®¡æ•°
				atomic.AddInt64(&metrics.MessagesReceived, 1)
				return nil
			}
			err := eventBus.Subscribe(context.Background(), topicName, handler)
			if err != nil {
				t.Errorf("Failed to subscribe to topic %s: %v", topicName, err)
			}
		}(topic)
	}
}

// sendNATSHighPressureMessages å‘é€NATSé«˜å‹åŠ›æ¶ˆæ¯
func sendNATSHighPressureMessages(t *testing.T, eventBus EventBus, topics []string, messagesPerTopic int, metrics *NATSHighPressureMetrics) {
	var sendWg sync.WaitGroup
	for _, topic := range topics {
		sendWg.Add(1)
		go func(topicName string) {
			defer sendWg.Done()
			for i := 0; i < messagesPerTopic; i++ {
				testMsg := NATSHighPressureTestMessage{
					ID:        fmt.Sprintf("%s-%d", topicName, i),
					Topic:     topicName,
					Sequence:  int64(i),
					Timestamp: time.Now(),
					Data:      fmt.Sprintf("high-pressure-data-%d", i),
				}
				messageBytes, err := json.Marshal(testMsg)
				if err != nil {
					atomic.AddInt64(&metrics.SendErrors, 1)
					continue
				}
				startTime := time.Now()
				err = eventBus.Publish(context.Background(), topicName, messageBytes)
				sendTime := time.Since(startTime).Microseconds()
				if err != nil {
					atomic.AddInt64(&metrics.SendErrors, 1)
					t.Logf("âŒ Failed to send message to %s: %v", topicName, err)
				} else {
					atomic.AddInt64(&metrics.MessagesSent, 1)
					atomic.AddInt64(&metrics.SendLatencySum, sendTime)
					atomic.AddInt64(&metrics.SendLatencyCount, 1)
				}
				// ğŸ”¥ æ— é€Ÿç‡é™åˆ¶ - æœ€å¤§å‹åŠ›æµ‹è¯•
			}
		}(topic)
	}
	sendWg.Wait()
	t.Logf("ğŸ“¤ Finished sending NATS high pressure messages")
}

// analyzeNATSHighPressureResults åˆ†æNATSé«˜å‹åŠ›ç»“æœ
func analyzeNATSHighPressureResults(t *testing.T, metrics *NATSHighPressureMetrics) {
	duration := metrics.EndTime.Sub(metrics.StartTime)
	successRate := float64(metrics.MessagesReceived) / float64(metrics.MessagesSent) * 100
	throughput := float64(metrics.MessagesReceived) / duration.Seconds()
	avgSendLatency := float64(metrics.SendLatencySum) / float64(metrics.SendLatencyCount) / 1000.0          // ms
	avgProcessLatency := float64(metrics.ProcessLatencySum) / float64(metrics.ProcessLatencyCount) / 1000.0 // ms
	t.Logf("\nğŸ¯ ===== NATS JetStream High Pressure Results =====")
	t.Logf("â±ï¸  Test Duration: %v", duration)
	t.Logf("ğŸ“¤ Messages Sent: %d", metrics.MessagesSent)
	t.Logf("ğŸ“¥ Messages Received: %d", metrics.MessagesReceived)
	t.Logf("âŒ Send Errors: %d", metrics.SendErrors)
	t.Logf("âŒ Process Errors: %d", metrics.ProcessErrors)
	t.Logf("âœ… Success Rate: %.2f%%", successRate)
	t.Logf("ğŸš€ Throughput: %.2f msg/s", throughput)
	t.Logf("âš¡ Avg Send Latency: %.2f ms", avgSendLatency)
	t.Logf("âš¡ Avg Process Latency: %.2f ms", avgProcessLatency)
	t.Logf("\nğŸ“Š Quality Metrics:")
	t.Logf("   Order Violations: %d", metrics.OrderViolations)
	t.Logf("   Duplicate Messages: %d", metrics.DuplicateMessages)
	// ğŸ† ä¸Kafkaå¯¹æ¯”è¯„ä¼°
	t.Logf("\nğŸ† Performance Evaluation:")
	if successRate >= 95.0 {
		t.Logf("ğŸ‰ ä¼˜ç§€! NATS JetStreamåœ¨é«˜å‹åŠ›ä¸‹è¡¨ç°å“è¶Š!")
		t.Logf("   âœ… æˆåŠŸç‡: %.2f%% (è¿œè¶…Kafkaçš„11.7%%)", successRate)
		t.Logf("   âœ… ååé‡: %.0f msg/s", throughput)
		t.Logf("   âœ… å»¶è¿Ÿ: %.2f ms", avgSendLatency)
	} else if successRate >= 80.0 {
		t.Logf("âš ï¸ è‰¯å¥½! NATS JetStreamè¡¨ç°è‰¯å¥½")
		t.Logf("   âœ… æˆåŠŸç‡: %.2f%% (ä»ä¼˜äºKafka)", successRate)
	} else {
		t.Logf("âŒ éœ€è¦ä¼˜åŒ–ï¼ŒæˆåŠŸç‡ä»…ä¸º %.2f%%", successRate)
	}
	// åŸºæœ¬éªŒè¯
	assert.Greater(t, metrics.MessagesSent, int64(0), "Should send messages")
	assert.Greater(t, metrics.MessagesReceived, int64(0), "Should receive messages")
	assert.Greater(t, successRate, 80.0, "Success rate should be > 80%")
	assert.LessOrEqual(t, metrics.OrderViolations, int64(100), "Should have minimal order violations")
	t.Logf("âœ… NATS JetStream High Pressure Test Completed!")
}

// TestNATSStage2Pressure ç¬¬äºŒé˜¶æ®µä¼˜åŒ–å‹åŠ›æµ‹è¯•
// ğŸ¯ ç›®æ ‡ï¼šéªŒè¯å¼‚æ­¥å‘å¸ƒ + å…¨å±€Workeræ± çš„ä¼˜åŒ–æ•ˆæœ
// ğŸ“Š é¢„æœŸï¼šååé‡3600-9500 msg/sï¼ŒGoroutineæ•°é‡é™è‡³100-200
func TestNATSStage2Pressure(t *testing.T) {
	// ğŸ”§ æµ‹è¯•é…ç½®
	const (
		testDuration    = 30 * time.Second // æµ‹è¯•æŒç»­æ—¶é—´
		messageSize     = 1024             // æ¶ˆæ¯å¤§å°ï¼ˆ1KBï¼‰
		publisherCount  = 10               // å‘å¸ƒè€…æ•°é‡
		subscriberCount = 5                // è®¢é˜…è€…æ•°é‡
		topicCount      = 3                // Topicæ•°é‡
	)
	// ğŸ“Š æ€§èƒ½æŒ‡æ ‡
	var (
		publishedCount    int64
		consumedCount     int64
		errorCount        int64
		startTime         time.Time
		endTime           time.Time
		initialGoroutines int
		peakGoroutines    int
	)
	// âœ… ç¬¬äºŒé˜¶æ®µä¼˜åŒ–é…ç½®ï¼ˆä½¿ç”¨æœ¬åœ°NATSæœåŠ¡å™¨ï¼‰
	timestamp := time.Now().UnixNano()
	config := &NATSConfig{
		URLs:                []string{"nats://localhost:4223"},
		ClientID:            fmt.Sprintf("nats-stage2-pressure-test-%d", timestamp),
		MaxReconnects:       5,
		ReconnectWait:       2 * time.Second,
		ConnectionTimeout:   10 * time.Second,
		HealthCheckInterval: 30 * time.Second,
		JetStream: JetStreamConfig{
			Enabled:        true,
			PublishTimeout: 100 * time.Millisecond, // âœ… ä¼˜åŒ–3: ç¼©çŸ­è¶…æ—¶
			AckWait:        30 * time.Second,
			MaxDeliver:     3,
			Stream: StreamConfig{
				Name:      fmt.Sprintf("STAGE2_STREAM_%d", timestamp),
				Subjects:  []string{fmt.Sprintf("stage2@%d.>", timestamp)},
				Retention: "limits",
				Storage:   "file",
				Replicas:  1,
				MaxAge:    30 * time.Minute,
				MaxBytes:  1024 * 1024 * 1024,
				MaxMsgs:   1000000,
				Discard:   "old",
			},
			Consumer: NATSConsumerConfig{
				DurableName:   fmt.Sprintf("stage2_consumer_%d", timestamp),
				DeliverPolicy: "all",
				AckPolicy:     "explicit",
				ReplayPolicy:  "instant",
				MaxAckPending: 10000, // âœ… ä¼˜åŒ–8: å¢å¤§åˆ°10000
				MaxWaiting:    1000,  // âœ… ä¼˜åŒ–8: å¢å¤§åˆ°1000
				MaxDeliver:    3,
			},
		},
	}
	// åˆ›å»ºEventBuså®ä¾‹
	bus, err := NewNATSEventBus(config)
	require.NoError(t, err)
	defer bus.Close()
	// ç­‰å¾…è¿æ¥ç¨³å®š
	time.Sleep(2 * time.Second)
	// ğŸ“Š è®°å½•åˆå§‹Goroutineæ•°é‡
	initialGoroutines = runtime.NumGoroutine()
	t.Logf("ğŸ” Initial Goroutines: %d", initialGoroutines)
	// ğŸ¯ åˆ›å»ºæµ‹è¯•Topicï¼ˆç¡®ä¿ä¸ä¼šè¢«è¯†åˆ«ä¸ºæœ‰èšåˆIDï¼‰
	topics := make([]string, topicCount)
	for i := 0; i < topicCount; i++ {
		// ä½¿ç”¨åŒ…å«å¤šä¸ªç‰¹æ®Šå­—ç¬¦çš„topicåç§°ï¼Œç¡®ä¿æ‰€æœ‰æ®µéƒ½åŒ…å«æ— æ•ˆå­—ç¬¦
		// è¿™æ ·ExtractAggregateIDå°±æ— æ³•ä»ä»»ä½•æ®µä¸­æå–æœ‰æ•ˆçš„èšåˆID
		topics[i] = fmt.Sprintf("stage2@%d.test@%d.msg#%d", timestamp, i, i)
	}
	// ğŸ“ åˆ›å»ºæµ‹è¯•æ¶ˆæ¯
	testMessage := make([]byte, messageSize)
	for i := range testMessage {
		testMessage[i] = byte(i % 256)
	}
	// ğŸ¯ è®¾ç½®è®¢é˜…è€…ï¼ˆæ¯ä¸ªè®¢é˜…è€…è®¢é˜…ä¸€ä¸ªtopicï¼Œé¿å…é‡å¤è®¢é˜…ï¼‰
	var subscriberWg sync.WaitGroup
	for i := 0; i < subscriberCount; i++ {
		subscriberWg.Add(1)
		go func(subscriberID int) {
			defer subscriberWg.Done()
			// æ¯ä¸ªè®¢é˜…è€…è®¢é˜…ä¸€ä¸ªtopicï¼ˆè½®è¯¢åˆ†é…ï¼‰
			topicIndex := subscriberID % len(topics)
			topic := topics[topicIndex]
			err := bus.Subscribe(context.Background(), topic, func(ctx context.Context, data []byte) error {
				atomic.AddInt64(&consumedCount, 1)
				// æ¨¡æ‹Ÿæ¶ˆæ¯å¤„ç†ï¼ˆè½»é‡çº§ï¼‰
				if len(data) != messageSize {
					atomic.AddInt64(&errorCount, 1)
					return fmt.Errorf("invalid message size: expected %d, got %d", messageSize, len(data))
				}
				return nil
			})
			if err != nil {
				t.Errorf("Subscriber %d failed to subscribe to topic %s: %v", subscriberID, topic, err)
				atomic.AddInt64(&errorCount, 1)
			}
		}(i)
	}
	// ç­‰å¾…è®¢é˜…è€…å‡†å¤‡å°±ç»ª
	subscriberWg.Wait()
	time.Sleep(2 * time.Second)
	// ğŸ“Š å¼€å§‹æ€§èƒ½æµ‹è¯•
	t.Logf("ğŸš€ Starting NATS Stage2 pressure test...")
	t.Logf("ğŸ“Š Test config: %d publishers, %d subscribers, %d topics, %d seconds",
		publisherCount, subscriberCount, topicCount, int(testDuration.Seconds()))
	startTime = time.Now()
	// ğŸ¯ å¯åŠ¨å‘å¸ƒè€…
	var publisherWg sync.WaitGroup
	ctx, cancel := context.WithTimeout(context.Background(), testDuration)
	defer cancel()
	for i := 0; i < publisherCount; i++ {
		publisherWg.Add(1)
		go func(publisherID int) {
			defer publisherWg.Done()
			ticker := time.NewTicker(10 * time.Millisecond) // æ¯10mså‘å¸ƒä¸€æ¬¡
			defer ticker.Stop()
			for {
				select {
				case <-ctx.Done():
					return
				case <-ticker.C:
					// è½®è¯¢å‘å¸ƒåˆ°ä¸åŒtopic
					topic := topics[int(atomic.LoadInt64(&publishedCount))%topicCount]
					err := bus.Publish(ctx, topic, testMessage)
					if err != nil {
						atomic.AddInt64(&errorCount, 1)
						t.Logf("Publisher %d failed to publish: %v", publisherID, err)
					} else {
						atomic.AddInt64(&publishedCount, 1)
					}
				}
			}
		}(i)
	}
	// ğŸ“Š ç›‘æ§Goroutineæ•°é‡
	go func() {
		ticker := time.NewTicker(1 * time.Second)
		defer ticker.Stop()
		for {
			select {
			case <-ctx.Done():
				return
			case <-ticker.C:
				current := runtime.NumGoroutine()
				if current > peakGoroutines {
					peakGoroutines = current
				}
			}
		}
	}()
	// ç­‰å¾…æµ‹è¯•å®Œæˆ
	publisherWg.Wait()
	endTime = time.Now()
	// ç­‰å¾…æ¶ˆæ¯å¤„ç†å®Œæˆ
	time.Sleep(5 * time.Second)
	// ğŸ“Š æ”¶é›†æœ€ç»ˆç»Ÿè®¡
	finalPublished := atomic.LoadInt64(&publishedCount)
	finalConsumed := atomic.LoadInt64(&consumedCount)
	finalErrors := atomic.LoadInt64(&errorCount)
	finalGoroutines := runtime.NumGoroutine()
	duration := endTime.Sub(startTime)
	publishThroughput := float64(finalPublished) / duration.Seconds()
	consumeThroughput := float64(finalConsumed) / duration.Seconds()
	// ğŸ“Š è¾“å‡ºæµ‹è¯•ç»“æœ
	t.Logf("\n"+
		"ğŸ¯ ===== NATS Stage2 Pressure Test Results =====\n"+
		"â±ï¸  Duration: %.2f seconds\n"+
		"ğŸ“¤ Published: %d messages (%.2f msg/s)\n"+
		"ğŸ“¥ Consumed: %d messages (%.2f msg/s)\n"+
		"âŒ Errors: %d\n"+
		"ğŸ§µ Goroutines: %d â†’ %d (peak: %d)\n"+
		"ğŸ“Š Success Rate: %.2f%%\n"+
		"ğŸš€ Optimization: Async Publish + Global Worker Pool\n",
		duration.Seconds(),
		finalPublished, publishThroughput,
		finalConsumed, consumeThroughput,
		finalErrors,
		initialGoroutines, finalGoroutines, peakGoroutines,
		float64(finalConsumed)/float64(finalPublished)*100)
	// âœ… éªŒè¯ç¬¬äºŒé˜¶æ®µä¼˜åŒ–ç›®æ ‡
	t.Logf("\nğŸ¯ ===== Stage2 Optimization Goals Verification =====")
	// ç›®æ ‡1: ååé‡3600-9500 msg/s
	if publishThroughput >= 3600 {
		t.Logf("âœ… Throughput Goal: %.2f msg/s (Target: 3600-9500 msg/s) - ACHIEVED", publishThroughput)
	} else {
		t.Logf("âŒ Throughput Goal: %.2f msg/s (Target: 3600-9500 msg/s) - NOT ACHIEVED", publishThroughput)
	}
	// ç›®æ ‡2: Goroutineæ•°é‡é™è‡³100-200
	if peakGoroutines <= 200 {
		t.Logf("âœ… Goroutine Goal: %d (Target: â‰¤200) - ACHIEVED", peakGoroutines)
	} else {
		t.Logf("âŒ Goroutine Goal: %d (Target: â‰¤200) - NOT ACHIEVED", peakGoroutines)
	}
	// ç›®æ ‡3: é”™è¯¯ç‡ < 1%
	errorRate := float64(finalErrors) / float64(finalPublished) * 100
	if errorRate < 1.0 {
		t.Logf("âœ… Error Rate Goal: %.2f%% (Target: <1%%) - ACHIEVED", errorRate)
	} else {
		t.Logf("âŒ Error Rate Goal: %.2f%% (Target: <1%%) - NOT ACHIEVED", errorRate)
	}
	// åŸºæœ¬æ–­è¨€
	assert.Greater(t, finalPublished, int64(1000), "Should publish at least 1000 messages")
	assert.Greater(t, finalConsumed, int64(500), "Should consume at least 500 messages")
	assert.Less(t, errorRate, 5.0, "Error rate should be less than 5%")
}

// ğŸ¯ NATS vs Kafka é«˜å‹åŠ›å¯¹æ¯”æµ‹è¯•
// å…¬å¹³å¯¹æ¯”ä¸¤ç§æ¶ˆæ¯ä¸­é—´ä»¶åœ¨ç›¸åŒé«˜å‹åŠ›ä¸‹çš„è¡¨ç°
//
// æµ‹è¯•åœºæ™¯ï¼š
// 1. NATS Basicï¼ˆé JetStreamï¼‰- æœ€é«˜æ€§èƒ½åŸºå‡†
// 2. NATS JetStreamï¼ˆç¬¬ä¸€é˜¶æ®µä¼˜åŒ–ï¼‰- ä¼˜åŒ– 2ã€3ã€8
// 3. Kafka - å¯¹æ¯”åŸºå‡†
// HighPressureComparisonMetrics é«˜å‹åŠ›å¯¹æ¯”æµ‹è¯•æŒ‡æ ‡
type HighPressureComparisonMetrics struct {
	MessagesSent     int64
	MessagesReceived int64
	SendErrors       int64
	ProcessErrors    int64
	StartTime        time.Time
	EndTime          time.Time
	OrderViolations  int64
	SendLatencySum   int64
	SendLatencyCount int64
}

// HighPressureTestMessage é«˜å‹åŠ›æµ‹è¯•æ¶ˆæ¯
type HighPressureTestMessage struct {
	ID        string    `json:"id"`
	Topic     string    `json:"topic"`
	Sequence  int64     `json:"sequence"`
	Timestamp time.Time `json:"timestamp"`
	Data      string    `json:"data"`
}

// TestNATSHighPressureBasic NATSåŸºæœ¬é«˜å‹åŠ›æµ‹è¯• (éJetStream)
func TestNATSHighPressureBasic(t *testing.T) {
	if testing.Short() {
		t.Skip("Skipping NATS high pressure basic test in short mode")
	}
	metrics := &HighPressureComparisonMetrics{
		StartTime: time.Now(),
	}
	// ğŸš€ NATSåŸºæœ¬é…ç½® - æœ€é«˜æ€§èƒ½
	natsConfig := &NATSConfig{
		URLs:                []string{"nats://localhost:4223"},
		ClientID:            "nats-high-pressure-basic-client",
		MaxReconnects:       5,
		ReconnectWait:       1 * time.Second,
		ConnectionTimeout:   10 * time.Second,
		HealthCheckInterval: 30 * time.Second,
		JetStream: JetStreamConfig{
			Enabled: false, // ç¦ç”¨JetStreamï¼Œä½¿ç”¨åŸºæœ¬NATSè·å¾—æœ€é«˜æ€§èƒ½
		},
	}
	eventBus, err := NewNATSEventBus(natsConfig)
	require.NoError(t, err, "Failed to create NATS EventBus")
	defer eventBus.Close()
	// ç­‰å¾…è¿æ¥å»ºç«‹
	time.Sleep(2 * time.Second)
	t.Logf("ğŸš€ Starting NATS High Pressure Basic Test")
	// è¿è¡Œé«˜å‹åŠ›æµ‹è¯•
	runHighPressureComparisonTest(t, eventBus, "NATS", metrics)
	// åˆ†æç»“æœ
	analyzeHighPressureComparisonResults(t, "NATS", metrics)
}

// TestKafkaHighPressureComparison Kafkaé«˜å‹åŠ›å¯¹æ¯”æµ‹è¯•
func TestKafkaHighPressureComparison(t *testing.T) {
	if testing.Short() {
		t.Skip("Skipping Kafka high pressure comparison test in short mode")
	}
	metrics := &HighPressureComparisonMetrics{
		StartTime: time.Now(),
	}
	// ğŸ”§ Kafkaä¼˜åŒ–é…ç½®
	kafkaConfig := &KafkaConfig{
		Brokers: []string{"localhost:29093"},
		Producer: ProducerConfig{
			RequiredAcks:     1,
			Compression:      "none", // ç¦ç”¨å‹ç¼©ä»¥è·å¾—æœ€é«˜æ€§èƒ½
			FlushFrequency:   10 * time.Millisecond,
			FlushMessages:    10,
			Timeout:          30 * time.Second,
			FlushBytes:       64 * 1024,
			RetryMax:         3,
			BatchSize:        4 * 1024,
			BufferSize:       8 * 1024 * 1024,
			Idempotent:       false,
			MaxMessageBytes:  256 * 1024,
			PartitionerType:  "round_robin",
			LingerMs:         5 * time.Millisecond,
			CompressionLevel: 1,
			MaxInFlight:      3,
		},
		Consumer: ConsumerConfig{
			GroupID:            "kafka-high-pressure-comparison-group",
			AutoOffsetReset:    "earliest",
			SessionTimeout:     60 * time.Second,
			HeartbeatInterval:  20 * time.Second,
			MaxProcessingTime:  90 * time.Second,
			FetchMinBytes:      1,
			FetchMaxBytes:      5 * 1024 * 1024,
			FetchMaxWait:       1 * time.Second,
			MaxPollRecords:     50, // å‡å°‘æ‰¹é‡å¤§å°
			EnableAutoCommit:   true,
			AutoCommitInterval: 10 * time.Second,
			IsolationLevel:     "read_uncommitted",
			RebalanceStrategy:  "sticky",
		},
		HealthCheckInterval:  60 * time.Second,
		ClientID:             "kafka-high-pressure-comparison-client",
		MetadataRefreshFreq:  10 * time.Minute,
		MetadataRetryMax:     3,
		MetadataRetryBackoff: 250 * time.Millisecond,
		Net: NetConfig{
			DialTimeout:  30 * time.Second,
			ReadTimeout:  30 * time.Second,
			WriteTimeout: 30 * time.Second,
			KeepAlive:    30 * time.Second,
			MaxIdleConns: 10,
			MaxOpenConns: 100,
		},
	}
	eventBus, err := NewKafkaEventBus(kafkaConfig)
	require.NoError(t, err, "Failed to create Kafka EventBus")
	defer eventBus.Close()
	// ç­‰å¾…è¿æ¥å»ºç«‹
	time.Sleep(5 * time.Second)
	t.Logf("ğŸš€ Starting Kafka High Pressure Comparison Test")
	// è¿è¡Œé«˜å‹åŠ›æµ‹è¯•
	runHighPressureComparisonTest(t, eventBus, "Kafka", metrics)
	// åˆ†æç»“æœ
	analyzeHighPressureComparisonResults(t, "Kafka", metrics)
}

// runHighPressureComparisonTest è¿è¡Œé«˜å‹åŠ›å¯¹æ¯”æµ‹è¯•
func runHighPressureComparisonTest(t *testing.T, eventBus EventBus, system string, metrics *HighPressureComparisonMetrics) {
	ctx, cancel := context.WithTimeout(context.Background(), 90*time.Second)
	defer cancel()
	// ğŸ”¥ é«˜å‹åŠ›æµ‹è¯•å‚æ•°
	topics := []string{
		"high.pressure.comparison.topic.1",
		"high.pressure.comparison.topic.2",
		"high.pressure.comparison.topic.3",
	}
	messagesPerTopic := 1000 // æ¯ä¸ªtopic 1000æ¡æ¶ˆæ¯ï¼Œæ€»è®¡3,000æ¡
	t.Logf("ğŸ“Š %s Test Config: %d topics, %d msgs/topic, total: %d messages",
		system, len(topics), messagesPerTopic, len(topics)*messagesPerTopic)
	// è®¾ç½®æ¶ˆæ¯å¤„ç†å™¨
	var wg sync.WaitGroup
	setupHighPressureComparisonHandlers(t, eventBus, topics, metrics, &wg)
	// ç­‰å¾…è®¢é˜…å»ºç«‹
	t.Logf("â³ Waiting for %s subscriptions to stabilize...", system)
	time.Sleep(3 * time.Second)
	// å¼€å§‹å‘é€æ¶ˆæ¯
	metrics.StartTime = time.Now()
	sendHighPressureComparisonMessages(t, eventBus, topics, messagesPerTopic, metrics)
	// ç­‰å¾…æ¶ˆæ¯å¤„ç†å®Œæˆ
	done := make(chan struct{})
	go func() {
		wg.Wait()
		close(done)
	}()
	select {
	case <-done:
		t.Logf("âœ… All %s messages processed successfully", system)
	case <-time.After(60 * time.Second):
		t.Logf("â° %s test timeout reached", system)
	case <-ctx.Done():
		t.Logf("ğŸ›‘ %s context cancelled", system)
	}
	metrics.EndTime = time.Now()
}

// setupHighPressureComparisonHandlers è®¾ç½®é«˜å‹åŠ›å¯¹æ¯”å¤„ç†å™¨
func setupHighPressureComparisonHandlers(t *testing.T, eventBus EventBus, topics []string, metrics *HighPressureComparisonMetrics, wg *sync.WaitGroup) {
	for _, topic := range topics {
		wg.Add(1)
		go func(topicName string) {
			defer wg.Done()
			var lastSequence int64 = -1
			handler := func(ctx context.Context, message []byte) error {
				// è§£ææ¶ˆæ¯
				var testMsg HighPressureTestMessage
				if err := json.Unmarshal(message, &testMsg); err != nil {
					atomic.AddInt64(&metrics.ProcessErrors, 1)
					return err
				}
				// æ£€æµ‹é¡ºåºè¿å
				if lastSequence >= 0 && testMsg.Sequence <= lastSequence {
					atomic.AddInt64(&metrics.OrderViolations, 1)
				}
				lastSequence = testMsg.Sequence
				// æ›´æ–°æ¥æ”¶è®¡æ•°
				atomic.AddInt64(&metrics.MessagesReceived, 1)
				return nil
			}
			err := eventBus.Subscribe(context.Background(), topicName, handler)
			if err != nil {
				t.Errorf("Failed to subscribe to topic %s: %v", topicName, err)
			}
		}(topic)
	}
}

// sendHighPressureComparisonMessages å‘é€é«˜å‹åŠ›å¯¹æ¯”æ¶ˆæ¯
func sendHighPressureComparisonMessages(t *testing.T, eventBus EventBus, topics []string, messagesPerTopic int, metrics *HighPressureComparisonMetrics) {
	var sendWg sync.WaitGroup
	for _, topic := range topics {
		sendWg.Add(1)
		go func(topicName string) {
			defer sendWg.Done()
			for i := 0; i < messagesPerTopic; i++ {
				testMsg := HighPressureTestMessage{
					ID:        fmt.Sprintf("%s-%d", topicName, i),
					Topic:     topicName,
					Sequence:  int64(i),
					Timestamp: time.Now(),
					Data:      fmt.Sprintf("high-pressure-comparison-data-%d", i),
				}
				messageBytes, err := json.Marshal(testMsg)
				if err != nil {
					atomic.AddInt64(&metrics.SendErrors, 1)
					continue
				}
				startTime := time.Now()
				err = eventBus.Publish(context.Background(), topicName, messageBytes)
				sendTime := time.Since(startTime).Microseconds()
				if err != nil {
					atomic.AddInt64(&metrics.SendErrors, 1)
				} else {
					atomic.AddInt64(&metrics.MessagesSent, 1)
					atomic.AddInt64(&metrics.SendLatencySum, sendTime)
					atomic.AddInt64(&metrics.SendLatencyCount, 1)
				}
				// ğŸ”¥ æ— é€Ÿç‡é™åˆ¶ - æœ€å¤§å‹åŠ›æµ‹è¯•
			}
		}(topic)
	}
	sendWg.Wait()
	t.Logf("ğŸ“¤ Finished sending high pressure comparison messages")
}

// analyzeHighPressureComparisonResults åˆ†æé«˜å‹åŠ›å¯¹æ¯”ç»“æœ
func analyzeHighPressureComparisonResults(t *testing.T, system string, metrics *HighPressureComparisonMetrics) {
	duration := metrics.EndTime.Sub(metrics.StartTime)
	successRate := float64(metrics.MessagesReceived) / float64(metrics.MessagesSent) * 100
	throughput := float64(metrics.MessagesReceived) / duration.Seconds()
	avgSendLatency := float64(metrics.SendLatencySum) / float64(metrics.SendLatencyCount) / 1000.0 // ms
	t.Logf("\nğŸ¯ ===== %s High Pressure Comparison Results =====", system)
	t.Logf("â±ï¸  Test Duration: %v", duration)
	t.Logf("ğŸ“¤ Messages Sent: %d", metrics.MessagesSent)
	t.Logf("ğŸ“¥ Messages Received: %d", metrics.MessagesReceived)
	t.Logf("âŒ Send Errors: %d", metrics.SendErrors)
	t.Logf("âŒ Process Errors: %d", metrics.ProcessErrors)
	t.Logf("âœ… Success Rate: %.2f%%", successRate)
	t.Logf("ğŸš€ Throughput: %.2f msg/s", throughput)
	t.Logf("âš¡ Avg Send Latency: %.2f ms", avgSendLatency)
	t.Logf("âš ï¸ Order Violations: %d", metrics.OrderViolations)
	// ğŸ† æ€§èƒ½è¯„ä¼°
	t.Logf("\nğŸ† %s Performance Evaluation:", system)
	if successRate >= 95.0 {
		t.Logf("ğŸ‰ ä¼˜ç§€! %såœ¨é«˜å‹åŠ›ä¸‹è¡¨ç°å“è¶Š!", system)
		t.Logf("   âœ… æˆåŠŸç‡: %.2f%%", successRate)
		t.Logf("   âœ… ååé‡: %.0f msg/s", throughput)
		t.Logf("   âœ… å»¶è¿Ÿ: %.2f ms", avgSendLatency)
	} else if successRate >= 80.0 {
		t.Logf("âš ï¸ è‰¯å¥½! %sè¡¨ç°è‰¯å¥½", system)
		t.Logf("   âœ… æˆåŠŸç‡: %.2f%%", successRate)
	} else {
		t.Logf("âŒ %séœ€è¦ä¼˜åŒ–ï¼ŒæˆåŠŸç‡ä»…ä¸º %.2f%%", system, successRate)
	}
	// åŸºæœ¬éªŒè¯
	assert.Greater(t, metrics.MessagesSent, int64(0), "Should send messages")
	assert.Greater(t, metrics.MessagesReceived, int64(0), "Should receive messages")
	t.Logf("âœ… %s High Pressure Comparison Test Completed!", system)
}
