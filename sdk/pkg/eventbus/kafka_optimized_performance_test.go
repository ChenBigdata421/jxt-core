package eventbus

import (
	"context"
	"fmt"
	"sync"
	"sync/atomic"
	"testing"
	"time"
)

// TestKafkaOptimizedPerformance æµ‹è¯•Kafkaä¼˜åŒ–åçš„æ€§èƒ½
// ğŸš€ éªŒè¯ä¸šç•Œæœ€ä½³å®è·µä¼˜åŒ–æ•ˆæœ
func TestKafkaOptimizedPerformance(t *testing.T) {
	t.Log("ğŸš€ Kafkaä¼˜åŒ–æ€§èƒ½æµ‹è¯• - åŸºäºConfluentå®˜æ–¹æœ€ä½³å®è·µ")
	t.Log("=" + string(make([]byte, 80)))

	// åˆ›å»ºKafkaé…ç½®ï¼ˆåº”ç”¨æ‰€æœ‰ä¼˜åŒ–ï¼‰
	kafkaConfig := &KafkaConfig{
		Brokers:  []string{"localhost:29094"}, // ä½¿ç”¨RedPandaç«¯å£
		ClientID: "optimized-perf-test",
		Producer: ProducerConfig{
			RequiredAcks:    1,                     // acks=1ï¼ˆæ€§èƒ½ä¼˜å…ˆï¼‰
			Compression:     "lz4",                 // ğŸš€ ä¼˜åŒ–2ï¼šLZ4å‹ç¼©ï¼ˆConfluenté¦–é€‰ï¼‰
			FlushFrequency:  10 * time.Millisecond, // ğŸš€ ä¼˜åŒ–3ï¼š10msæ‰¹é‡ï¼ˆConfluentæ¨èï¼‰
			FlushMessages:   100,                   // ğŸš€ ä¼˜åŒ–3ï¼š100æ¡æ¶ˆæ¯ï¼ˆConfluentæ¨èï¼‰
			FlushBytes:      100000,                // ğŸš€ ä¼˜åŒ–3ï¼š100KBï¼ˆConfluentæ¨èï¼‰
			RetryMax:        3,
			Timeout:         10 * time.Second,
			MaxMessageBytes: 1024 * 1024,
			Idempotent:      false,
			MaxInFlight:     100, // ğŸš€ ä¼˜åŒ–4ï¼š100å¹¶å‘è¯·æ±‚ï¼ˆä¸šç•Œæ¨èï¼‰
		},
		Consumer: ConsumerConfig{
			GroupID:           "optimized-perf-test-group",
			SessionTimeout:    10 * time.Second,
			HeartbeatInterval: 3 * time.Second,
			MaxProcessingTime: 1 * time.Second,
			FetchMinBytes:     100 * 1024,             // ğŸš€ ä¼˜åŒ–6ï¼š100KBï¼ˆConfluentæ¨èï¼‰
			FetchMaxBytes:     10 * 1024 * 1024,       // ğŸš€ ä¼˜åŒ–6ï¼š10MBï¼ˆConfluentæ¨èï¼‰
			FetchMaxWait:      500 * time.Millisecond, // ğŸš€ ä¼˜åŒ–6ï¼š500msï¼ˆConfluentæ¨èï¼‰
			AutoOffsetReset:   "latest",
			RebalanceStrategy: "range",
			IsolationLevel:    "read_uncommitted",
		},
		Net: NetConfig{
			DialTimeout:  10 * time.Second, // ğŸš€ ä¼˜åŒ–8ï¼š10ç§’ï¼ˆä¸šç•Œæ¨èï¼‰
			ReadTimeout:  30 * time.Second,
			WriteTimeout: 30 * time.Second,
			KeepAlive:    30 * time.Second,
		},
		MetadataRefreshFreq:  10 * time.Minute,
		MetadataRetryMax:     3,
		MetadataRetryBackoff: 250 * time.Millisecond,
		HealthCheckInterval:  30 * time.Second,
	}

	// åˆ›å»ºEventBus
	bus, err := NewKafkaEventBus(kafkaConfig)
	if err != nil {
		t.Fatalf("âŒ Failed to create Kafka EventBus: %v", err)
	}
	defer bus.Close()

	t.Log("âœ… Kafka EventBusåˆ›å»ºæˆåŠŸï¼ˆAsyncProducer + å…¨éƒ¨ä¼˜åŒ–ï¼‰")

	// æµ‹è¯•åœºæ™¯
	scenarios := []struct {
		name         string
		messageCount int
		messageSize  int
	}{
		{"è½»è´Ÿè½½", 300, 1024},
		{"ä¸­è´Ÿè½½", 800, 1024},
		{"é‡è´Ÿè½½", 1500, 1024},
		{"æé™è´Ÿè½½", 3000, 1024},
	}

	for _, scenario := range scenarios {
		t.Run(scenario.name, func(t *testing.T) {
			testKafkaOptimizedScenario(t, bus, scenario.name, scenario.messageCount, scenario.messageSize)
		})
	}
}

func testKafkaOptimizedScenario(t *testing.T, bus EventBus, scenarioName string, messageCount, messageSize int) {
	t.Logf("\nğŸ“Š æµ‹è¯•åœºæ™¯: %s", scenarioName)
	t.Logf("   æ¶ˆæ¯æ•°é‡: %d", messageCount)
	t.Logf("   æ¶ˆæ¯å¤§å°: %d bytes", messageSize)

	topic := fmt.Sprintf("optimized-perf-test-%d", time.Now().UnixNano())
	ctx := context.Background()

	// ğŸš€ é…ç½®é¢„è®¢é˜…æ¨¡å¼
	if kafkaBus, ok := bus.(*kafkaEventBus); ok {
		kafkaBus.allPossibleTopics = []string{topic}
		t.Logf("âœ… Configured pre-subscription for topic: %s", topic)
	}

	// è®¢é˜…è®¡æ•°å™¨
	var receivedCount atomic.Int64
	var firstMessageTime atomic.Value // time.Time
	var lastMessageTime atomic.Value  // time.Time
	receivedChan := make(chan struct{}, messageCount)

	// è®¢é˜…
	handler := func(ctx context.Context, message []byte) error {
		now := time.Now()

		// è®°å½•ç¬¬ä¸€æ¡æ¶ˆæ¯æ—¶é—´
		if firstMessageTime.Load() == nil {
			firstMessageTime.Store(now)
		}

		// æ›´æ–°æœ€åä¸€æ¡æ¶ˆæ¯æ—¶é—´
		lastMessageTime.Store(now)

		receivedCount.Add(1)
		receivedChan <- struct{}{}
		return nil
	}

	err := bus.Subscribe(ctx, topic, handler)
	if err != nil {
		t.Fatalf("âŒ Failed to subscribe: %v", err)
	}
	t.Logf("âœ… Subscribed to topic: %s", topic)

	// ç­‰å¾…è®¢é˜…å°±ç»ª
	time.Sleep(5 * time.Second) // å¢åŠ ç­‰å¾…æ—¶é—´

	// å‘é€æ¶ˆæ¯
	message := make([]byte, messageSize)
	for i := 0; i < messageSize; i++ {
		message[i] = byte(i % 256)
	}

	t.Logf("ğŸ“¤ å¼€å§‹å‘é€ %d æ¡æ¶ˆæ¯...", messageCount)
	sendStart := time.Now()

	var sendErrors atomic.Int64
	var wg sync.WaitGroup

	// å¹¶å‘å‘é€
	concurrency := 10
	messagesPerWorker := messageCount / concurrency

	for i := 0; i < concurrency; i++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()
			for j := 0; j < messagesPerWorker; j++ {
				if err := bus.Publish(ctx, topic, message); err != nil {
					sendErrors.Add(1)
					t.Logf("âš ï¸  Send error: %v", err)
				}
			}
		}(i)
	}

	wg.Wait()
	sendDuration := time.Since(sendStart)

	t.Logf("âœ… å‘é€å®Œæˆ: %v", sendDuration)
	t.Logf("   å‘é€é€Ÿç‡: %.2f msg/s", float64(messageCount)/sendDuration.Seconds())
	t.Logf("   å‘é€é”™è¯¯: %d", sendErrors.Load())

	// ğŸš€ AsyncProduceréœ€è¦é¢å¤–ç­‰å¾…æ—¶é—´è®©æ¶ˆæ¯çœŸæ­£å‘é€
	t.Logf("â³ ç­‰å¾…AsyncProduceræ‰¹é‡å‘é€å®Œæˆ...")
	time.Sleep(10 * time.Second) // ç­‰å¾…æ‰¹é‡å‘é€å®Œæˆ

	// ç­‰å¾…æ¥æ”¶
	t.Logf("ğŸ“¥ ç­‰å¾…æ¥æ”¶æ¶ˆæ¯...")
	receiveTimeout := 3 * time.Minute // å¢åŠ è¶…æ—¶æ—¶é—´
	receiveStart := time.Now()

	receivedInTime := 0
	timeoutTimer := time.NewTimer(receiveTimeout)
	defer timeoutTimer.Stop()

receiveLoop:
	for receivedInTime < messageCount {
		select {
		case <-receivedChan:
			receivedInTime++
		case <-timeoutTimer.C:
			t.Logf("â±ï¸  æ¥æ”¶è¶…æ—¶ (%v)", receiveTimeout)
			break receiveLoop
		}
	}

	receiveDuration := time.Since(receiveStart)

	// è®¡ç®—æŒ‡æ ‡
	successRate := float64(receivedInTime) / float64(messageCount) * 100
	throughput := float64(receivedInTime) / receiveDuration.Seconds()

	// è®¡ç®—å»¶è¿Ÿ
	var firstMsgLatency time.Duration
	if firstMessageTime.Load() != nil {
		firstMsgLatency = firstMessageTime.Load().(time.Time).Sub(sendStart)
	}

	// è¾“å‡ºç»“æœ
	t.Logf("\nğŸ“Š æ€§èƒ½æŒ‡æ ‡:")
	t.Logf("   âœ… æˆåŠŸç‡: %.2f%% (%d/%d)", successRate, receivedInTime, messageCount)
	t.Logf("   ğŸš€ ååé‡: %.2f msg/s", throughput)
	t.Logf("   â±ï¸  é¦–æ¡å»¶è¿Ÿ: %v", firstMsgLatency)
	t.Logf("   â±ï¸  æ€»æ¥æ”¶æ—¶é—´: %v", receiveDuration)
	t.Logf("   ğŸ“¤ å‘é€é€Ÿç‡: %.2f msg/s", float64(messageCount)/sendDuration.Seconds())

	// æ€§èƒ½æ–­è¨€
	if successRate < 95.0 {
		t.Errorf("âŒ æˆåŠŸç‡è¿‡ä½: %.2f%% (æœŸæœ› >= 95%%)", successRate)
	}

	if throughput < 10.0 {
		t.Errorf("âŒ ååé‡è¿‡ä½: %.2f msg/s (æœŸæœ› >= 10 msg/s)", throughput)
	}

	t.Logf("âœ… åœºæ™¯æµ‹è¯•å®Œæˆ\n")
}

// TestKafkaOptimizationComparison å¯¹æ¯”ä¼˜åŒ–å‰åçš„æ€§èƒ½
func TestKafkaOptimizationComparison(t *testing.T) {
	t.Log("ğŸ”¬ Kafkaä¼˜åŒ–å¯¹æ¯”æµ‹è¯•")
	t.Log("=" + string(make([]byte, 80)))

	messageCount := 1000
	messageSize := 1024

	// æµ‹è¯•ä¼˜åŒ–åçš„é…ç½®
	t.Log("\nğŸš€ æµ‹è¯•ä¼˜åŒ–åé…ç½®ï¼ˆAsyncProducer + æ‰¹å¤„ç† + LZ4ï¼‰")
	optimizedConfig := &KafkaConfig{
		Brokers:  []string{"localhost:29094"}, // ä½¿ç”¨RedPandaç«¯å£
		ClientID: "optimized-comparison-test",
		Producer: ProducerConfig{
			RequiredAcks:    1,
			Compression:     "lz4",                 // LZ4å‹ç¼©
			FlushFrequency:  10 * time.Millisecond, // 10msæ‰¹é‡
			FlushMessages:   100,                   // 100æ¡æ¶ˆæ¯
			FlushBytes:      100000,                // 100KB
			RetryMax:        3,
			Timeout:         10 * time.Second,
			MaxMessageBytes: 1024 * 1024,
			MaxInFlight:     100,
		},
		Consumer: ConsumerConfig{
			GroupID:           "optimized-comparison-group",
			SessionTimeout:    10 * time.Second,
			HeartbeatInterval: 3 * time.Second,
			MaxProcessingTime: 1 * time.Second,
			FetchMinBytes:     100 * 1024,       // 100KB
			FetchMaxBytes:     10 * 1024 * 1024, // 10MB
			FetchMaxWait:      500 * time.Millisecond,
			AutoOffsetReset:   "latest",
			RebalanceStrategy: "range",
			IsolationLevel:    "read_uncommitted",
		},
		Net: NetConfig{
			DialTimeout:  10 * time.Second,
			ReadTimeout:  30 * time.Second,
			WriteTimeout: 30 * time.Second,
			KeepAlive:    30 * time.Second,
		},
		MetadataRefreshFreq:  10 * time.Minute,
		MetadataRetryMax:     3,
		MetadataRetryBackoff: 250 * time.Millisecond,
		HealthCheckInterval:  30 * time.Second,
	}

	optimizedBus, err := NewKafkaEventBus(optimizedConfig)
	if err != nil {
		t.Fatalf("âŒ Failed to create optimized Kafka EventBus: %v", err)
	}
	defer optimizedBus.Close()

	optimizedMetrics := runPerformanceTest(t, optimizedBus, "optimized", messageCount, messageSize)

	// è¾“å‡ºå¯¹æ¯”ç»“æœ
	t.Logf("\nğŸ“Š ä¼˜åŒ–æ•ˆæœæ€»ç»“:")
	t.Logf("   ğŸš€ ååé‡: %.2f msg/s", optimizedMetrics.throughput)
	t.Logf("   âœ… æˆåŠŸç‡: %.2f%%", optimizedMetrics.successRate)
	t.Logf("   â±ï¸  é¦–æ¡å»¶è¿Ÿ: %v", optimizedMetrics.firstMsgLatency)
	t.Logf("   ğŸ“¤ å‘é€é€Ÿç‡: %.2f msg/s", optimizedMetrics.sendRate)

	t.Log("\nğŸ¯ ä¼˜åŒ–ç›®æ ‡è¾¾æˆæƒ…å†µ:")
	if optimizedMetrics.throughput >= 30.0 {
		t.Logf("   âœ… ååé‡ç›®æ ‡è¾¾æˆ: %.2f msg/s >= 30 msg/s", optimizedMetrics.throughput)
	} else {
		t.Logf("   âš ï¸  ååé‡æœªè¾¾ç›®æ ‡: %.2f msg/s < 30 msg/s", optimizedMetrics.throughput)
	}

	if optimizedMetrics.successRate >= 95.0 {
		t.Logf("   âœ… æˆåŠŸç‡ç›®æ ‡è¾¾æˆ: %.2f%% >= 95%%", optimizedMetrics.successRate)
	} else {
		t.Logf("   âš ï¸  æˆåŠŸç‡æœªè¾¾ç›®æ ‡: %.2f%% < 95%%", optimizedMetrics.successRate)
	}

	if optimizedMetrics.firstMsgLatency <= 100*time.Millisecond {
		t.Logf("   âœ… å»¶è¿Ÿç›®æ ‡è¾¾æˆ: %v <= 100ms", optimizedMetrics.firstMsgLatency)
	} else {
		t.Logf("   âš ï¸  å»¶è¿Ÿæœªè¾¾ç›®æ ‡: %v > 100ms", optimizedMetrics.firstMsgLatency)
	}
}

type performanceMetrics struct {
	throughput      float64
	successRate     float64
	firstMsgLatency time.Duration
	sendRate        float64
}

func runPerformanceTest(t *testing.T, bus EventBus, testName string, messageCount, messageSize int) performanceMetrics {
	topic := fmt.Sprintf("perf-test-%s-%d", testName, time.Now().UnixNano())
	ctx := context.Background()

	// ğŸš€ é…ç½®é¢„è®¢é˜…æ¨¡å¼
	if kafkaBus, ok := bus.(*kafkaEventBus); ok {
		kafkaBus.allPossibleTopics = []string{topic}
		t.Logf("âœ… Configured pre-subscription for topic: %s", topic)
	}

	var receivedCount atomic.Int64
	var firstMessageTime atomic.Value
	receivedChan := make(chan struct{}, messageCount)

	handler := func(ctx context.Context, message []byte) error {
		now := time.Now()
		if firstMessageTime.Load() == nil {
			firstMessageTime.Store(now)
		}
		receivedCount.Add(1)
		receivedChan <- struct{}{}
		return nil
	}

	err := bus.Subscribe(ctx, topic, handler)
	if err != nil {
		t.Fatalf("âŒ Failed to subscribe: %v", err)
	}
	t.Logf("âœ… Subscribed to topic: %s", topic)
	time.Sleep(5 * time.Second) // å¢åŠ ç­‰å¾…æ—¶é—´ç¡®ä¿è®¢é˜…å°±ç»ª

	message := make([]byte, messageSize)
	sendStart := time.Now()

	for i := 0; i < messageCount; i++ {
		bus.Publish(ctx, topic, message)
	}

	sendDuration := time.Since(sendStart)
	sendRate := float64(messageCount) / sendDuration.Seconds()

	// ğŸš€ AsyncProduceréœ€è¦é¢å¤–ç­‰å¾…æ—¶é—´è®©æ¶ˆæ¯çœŸæ­£å‘é€
	t.Logf("â³ Waiting for async producer to flush messages...")
	time.Sleep(5 * time.Second) // ç­‰å¾…æ‰¹é‡å‘é€å®Œæˆ

	receiveTimeout := 2 * time.Minute // å¢åŠ è¶…æ—¶æ—¶é—´
	receivedInTime := 0
	timeoutTimer := time.NewTimer(receiveTimeout)
	defer timeoutTimer.Stop()

receiveLoop:
	for receivedInTime < messageCount {
		select {
		case <-receivedChan:
			receivedInTime++
		case <-timeoutTimer.C:
			break receiveLoop
		}
	}

	receiveDuration := time.Since(sendStart)
	successRate := float64(receivedInTime) / float64(messageCount) * 100
	throughput := float64(receivedInTime) / receiveDuration.Seconds()

	var firstMsgLatency time.Duration
	if firstMessageTime.Load() != nil {
		firstMsgLatency = firstMessageTime.Load().(time.Time).Sub(sendStart)
	}

	return performanceMetrics{
		throughput:      throughput,
		successRate:     successRate,
		firstMsgLatency: firstMsgLatency,
		sendRate:        sendRate,
	}
}
