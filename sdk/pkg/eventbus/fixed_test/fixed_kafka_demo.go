package main

import (
	"context"
	"fmt"
	"sync"
	"time"

	"github.com/ChenBigdata421/jxt-core/sdk/pkg/eventbus"
	"github.com/ChenBigdata421/jxt-core/sdk/pkg/logger"
	"go.uber.org/zap"
)

func main() {
	fmt.Println("ğŸš€ Kafka EventBus ä¿®å¤åå®Œæ•´æµ‹è¯•")
	fmt.Println("=================================")

	// åˆå§‹åŒ–logger
	zapLogger, _ := zap.NewDevelopment()
	defer zapLogger.Sync()
	logger.Logger = zapLogger
	logger.DefaultLogger = zapLogger.Sugar()

	// ä½¿ç”¨æ­£ç¡®çš„å¤–éƒ¨ç«¯å£å’Œä¿®å¤çš„é…ç½®
	fmt.Println("ğŸ“¡ è¿æ¥åˆ° Kafka æœåŠ¡å™¨...")
	config := &eventbus.EventBusConfig{
		Type: "kafka",
		Kafka: eventbus.KafkaConfig{
			Brokers: []string{"localhost:29092"}, // ä½¿ç”¨å¤–éƒ¨ç«¯å£
			Producer: eventbus.ProducerConfig{
				RequiredAcks:   1,
				Timeout:        5 * time.Second,
				RetryMax:       2,
				Compression:    "none",
				FlushFrequency: 100 * time.Millisecond,
				BatchSize:      1024,
			},
			Consumer: eventbus.ConsumerConfig{
				GroupID:           "kafka-fixed-test",
				SessionTimeout:    15 * time.Second,
				HeartbeatInterval: 3 * time.Second,
				MaxProcessingTime: 2 * time.Minute,
				AutoOffsetReset:   "earliest", // ä¿®å¤ï¼šä»æœ€æ—©æ¶ˆæ¯å¼€å§‹è¯»å–
				FetchMinBytes:     1,
				FetchMaxBytes:     1024 * 1024,
				FetchMaxWait:      500 * time.Millisecond,
			},
		},
	}

	bus, err := eventbus.NewEventBus(config)
	if err != nil {
		fmt.Printf("âŒ è¿æ¥ Kafka å¤±è´¥: %v\n", err)
		return
	}
	defer bus.Close()

	fmt.Println("âœ… æˆåŠŸè¿æ¥åˆ° Kafka æœåŠ¡å™¨")

	ctx := context.Background()

	// æµ‹è¯•1: ä¸»é¢˜æŒä¹…åŒ–é…ç½®
	fmt.Println("\nğŸ“‹ æµ‹è¯•1: ä¸»é¢˜æŒä¹…åŒ–é…ç½®")
	testKafkaTopicConfiguration(ctx, bus)

	// æµ‹è¯•2: ä¿®å¤åçš„å‘å¸ƒè®¢é˜…æµ‹è¯•
	fmt.Println("\nğŸ”„ æµ‹è¯•2: ä¿®å¤åçš„å‘å¸ƒè®¢é˜…æµ‹è¯•")
	testKafkaPublishSubscribe(ctx, bus)

	// æµ‹è¯•3: åŠ¨æ€é…ç½®ç®¡ç†
	fmt.Println("\nâš™ï¸ æµ‹è¯•3: åŠ¨æ€é…ç½®ç®¡ç†")
	testKafkaDynamicConfiguration(ctx, bus)

	// æµ‹è¯•4: æ€§èƒ½æµ‹è¯•
	fmt.Println("\nâš¡ æµ‹è¯•4: æ€§èƒ½æµ‹è¯•")
	testKafkaPerformance(ctx, bus)

	fmt.Println("\nâœ… Kafka ä¿®å¤åå®Œæ•´æµ‹è¯•å®Œæˆï¼")
}

func testKafkaTopicConfiguration(ctx context.Context, bus eventbus.EventBus) {
	// é…ç½®ä¸åŒæŒä¹…åŒ–ç­–ç•¥çš„ä¸»é¢˜
	topics := []struct {
		name    string
		options eventbus.TopicOptions
	}{
		{
			name: "kafka.fixed.orders",
			options: eventbus.TopicOptions{
				PersistenceMode: eventbus.TopicPersistent,
				RetentionTime:   2 * time.Hour,
				MaxSize:         20 * 1024 * 1024,
				Description:     "ä¿®å¤æµ‹è¯•-æŒä¹…åŒ–è®¢å•",
			},
		},
		{
			name: "kafka.fixed.events",
			options: eventbus.TopicOptions{
				PersistenceMode: eventbus.TopicEphemeral,
				RetentionTime:   30 * time.Minute,
				Description:     "ä¿®å¤æµ‹è¯•-ä¸´æ—¶äº‹ä»¶",
			},
		},
		{
			name: "kafka.fixed.metrics",
			options: eventbus.TopicOptions{
				PersistenceMode: eventbus.TopicAuto,
				Description:     "ä¿®å¤æµ‹è¯•-è‡ªåŠ¨é€‰æ‹©",
			},
		},
	}

	successCount := 0
	for _, topic := range topics {
		err := bus.ConfigureTopic(ctx, topic.name, topic.options)
		if err != nil {
			fmt.Printf("âŒ é…ç½®ä¸»é¢˜ %s å¤±è´¥: %v\n", topic.name, err)
		} else {
			fmt.Printf("âœ… æˆåŠŸé…ç½®ä¸»é¢˜: %s (%s)\n", topic.name, topic.options.PersistenceMode)
			successCount++
		}
	}

	// éªŒè¯é…ç½®
	configuredTopics := bus.ListConfiguredTopics()
	fmt.Printf("ğŸ“‹ é…ç½®ç»“æœ: %d/%d æˆåŠŸ, æ€»è®¡ %d ä¸ªä¸»é¢˜\n", 
		successCount, len(topics), len(configuredTopics))

	for _, topic := range configuredTopics {
		if len(topic) > 12 && topic[:12] == "kafka.fixed." {
			config, _ := bus.GetTopicConfig(topic)
			fmt.Printf("   - %s: %s (ä¿ç•™: %v)\n", 
				topic, config.PersistenceMode, config.RetentionTime)
		}
	}
}

func testKafkaPublishSubscribe(ctx context.Context, bus eventbus.EventBus) {
	// è®¾ç½®æ¶ˆæ¯æ¥æ”¶è®¡æ•°å™¨
	var mu sync.Mutex
	messageCount := make(map[string]int)
	receivedMessages := make(map[string][]string)

	// è®¢é˜…æµ‹è¯•ä¸»é¢˜
	topics := []string{
		"kafka.fixed.orders",
		"kafka.fixed.events", 
		"kafka.fixed.metrics",
	}

	fmt.Println("ğŸ“¨ è®¾ç½®æ¶ˆæ¯è®¢é˜…...")
	for _, topic := range topics {
		topicName := topic // é¿å…é—­åŒ…é—®é¢˜
		err := bus.Subscribe(ctx, topicName, func(ctx context.Context, message []byte) error {
			mu.Lock()
			messageCount[topicName]++
			count := messageCount[topicName]
			receivedMessages[topicName] = append(receivedMessages[topicName], string(message))
			mu.Unlock()

			fmt.Printf("ğŸ“¨ [%s] æ”¶åˆ°æ¶ˆæ¯ #%d: %s\n", topicName, count, string(message))
			return nil
		})
		if err != nil {
			fmt.Printf("âŒ è®¢é˜…ä¸»é¢˜ %s å¤±è´¥: %v\n", topicName, err)
		} else {
			fmt.Printf("âœ… æˆåŠŸè®¢é˜…ä¸»é¢˜: %s\n", topicName)
		}
	}

	// ç­‰å¾…è®¢é˜…å»ºç«‹
	fmt.Println("â³ ç­‰å¾… Kafka æ¶ˆè´¹è€…ç»„å»ºç«‹...")
	time.Sleep(5 * time.Second)

	// å‘å¸ƒæµ‹è¯•æ¶ˆæ¯
	fmt.Println("ğŸ“¤ å¼€å§‹å‘å¸ƒæµ‹è¯•æ¶ˆæ¯...")
	messages := []struct {
		topic   string
		content string
	}{
		{
			"kafka.fixed.orders",
			`{"order_id": "kafka-fixed-001", "amount": 199.99, "customer": "test-user-1", "timestamp": "2024-01-01T12:00:00Z"}`,
		},
		{
			"kafka.fixed.events",
			`{"event_type": "user_login", "user_id": "user-123", "ip": "192.168.1.100", "timestamp": "2024-01-01T12:01:00Z"}`,
		},
		{
			"kafka.fixed.metrics",
			`{"cpu_usage": 65.4, "memory_usage": 78.2, "disk_usage": 45.1, "timestamp": "2024-01-01T12:02:00Z"}`,
		},
		{
			"kafka.fixed.orders",
			`{"order_id": "kafka-fixed-002", "amount": 299.99, "customer": "test-user-2", "timestamp": "2024-01-01T12:03:00Z"}`,
		},
	}

	publishedCount := 0
	for i, msg := range messages {
		err := bus.Publish(ctx, msg.topic, []byte(msg.content))
		if err != nil {
			fmt.Printf("âŒ å‘å¸ƒæ¶ˆæ¯ #%d åˆ° %s å¤±è´¥: %v\n", i+1, msg.topic, err)
		} else {
			fmt.Printf("âœ… æˆåŠŸå‘å¸ƒæ¶ˆæ¯ #%d åˆ° %s\n", i+1, msg.topic)
			publishedCount++
		}
		time.Sleep(1 * time.Second) // ç»™æ¶ˆæ¯å¤„ç†æ—¶é—´
	}

	// ç­‰å¾…æ¶ˆæ¯å¤„ç†
	fmt.Println("â³ ç­‰å¾…æ¶ˆæ¯å¤„ç†...")
	time.Sleep(8 * time.Second)

	// ç»Ÿè®¡ç»“æœ
	fmt.Printf("ğŸ“Š å‘å¸ƒè®¢é˜…æµ‹è¯•ç»“æœ:\n")
	fmt.Printf("   - å‘å¸ƒæˆåŠŸ: %d/%d æ¶ˆæ¯\n", publishedCount, len(messages))

	mu.Lock()
	totalReceived := 0
	for topic, count := range messageCount {
		fmt.Printf("   - %s: æ”¶åˆ° %d æ¡æ¶ˆæ¯\n", topic, count)
		totalReceived += count
	}
	mu.Unlock()

	fmt.Printf("   - æ€»è®¡æ”¶åˆ°: %d æ¡æ¶ˆæ¯\n", totalReceived)

	if totalReceived >= publishedCount {
		fmt.Println("âœ… å‘å¸ƒè®¢é˜…æµ‹è¯•æˆåŠŸï¼")
	} else {
		fmt.Printf("âš ï¸ å‘å¸ƒè®¢é˜…æµ‹è¯•éƒ¨åˆ†æˆåŠŸ (æ”¶åˆ° %d/%d)\n", totalReceived, publishedCount)
	}
}

func testKafkaDynamicConfiguration(ctx context.Context, bus eventbus.EventBus) {
	// åŠ¨æ€é…ç½®æµ‹è¯•
	dynamicTopic := "kafka.fixed.dynamic.test"

	// 1. åˆ›å»ºåŠ¨æ€ä¸»é¢˜
	err := bus.SetTopicPersistence(ctx, dynamicTopic, true)
	if err != nil {
		fmt.Printf("âŒ åŠ¨æ€åˆ›å»ºä¸»é¢˜å¤±è´¥: %v\n", err)
	} else {
		fmt.Printf("âœ… åŠ¨æ€åˆ›å»ºä¸»é¢˜: %s (æŒä¹…åŒ–)\n", dynamicTopic)
	}

	// 2. éªŒè¯é…ç½®
	config, err := bus.GetTopicConfig(dynamicTopic)
	if err != nil {
		fmt.Printf("âŒ è·å–åŠ¨æ€ä¸»é¢˜é…ç½®å¤±è´¥: %v\n", err)
	} else {
		fmt.Printf("âœ… åŠ¨æ€ä¸»é¢˜é…ç½®: %s\n", config.PersistenceMode)
	}

	// 3. ä¿®æ”¹é…ç½®
	err = bus.SetTopicPersistence(ctx, dynamicTopic, false)
	if err != nil {
		fmt.Printf("âŒ ä¿®æ”¹åŠ¨æ€ä¸»é¢˜é…ç½®å¤±è´¥: %v\n", err)
	} else {
		fmt.Printf("âœ… æˆåŠŸä¿®æ”¹ä¸»é¢˜ %s ä¸ºéæŒä¹…åŒ–\n", dynamicTopic)
	}

	// 4. éªŒè¯ä¿®æ”¹
	updatedConfig, err := bus.GetTopicConfig(dynamicTopic)
	if err != nil {
		fmt.Printf("âŒ éªŒè¯é…ç½®ä¿®æ”¹å¤±è´¥: %v\n", err)
	} else {
		if updatedConfig.PersistenceMode == eventbus.TopicEphemeral {
			fmt.Println("âœ… é…ç½®ä¿®æ”¹éªŒè¯æˆåŠŸ (å·²æ”¹ä¸ºéæŒä¹…åŒ–)")
		} else {
			fmt.Printf("âš ï¸ é…ç½®ä¿®æ”¹å¯èƒ½æœ‰é—®é¢˜ (å½“å‰: %s)\n", updatedConfig.PersistenceMode)
		}
	}

	// 5. æ¸…ç†
	err = bus.RemoveTopicConfig(dynamicTopic)
	if err != nil {
		fmt.Printf("âŒ æ¸…ç†åŠ¨æ€ä¸»é¢˜å¤±è´¥: %v\n", err)
	} else {
		fmt.Println("âœ… æˆåŠŸæ¸…ç†åŠ¨æ€ä¸»é¢˜é…ç½®")
	}

	fmt.Println("ğŸ”„ åŠ¨æ€é…ç½®ç®¡ç†æµ‹è¯•å®Œæˆ")
}

func testKafkaPerformance(ctx context.Context, bus eventbus.EventBus) {
	// æ€§èƒ½æµ‹è¯•ä¸»é¢˜
	perfTopic := "kafka.fixed.performance.test"
	
	err := bus.SetTopicPersistence(ctx, perfTopic, true)
	if err != nil {
		fmt.Printf("âŒ æ€§èƒ½æµ‹è¯•ä¸»é¢˜é…ç½®å¤±è´¥: %v\n", err)
		return
	}

	// æ‰¹é‡å‘å¸ƒæµ‹è¯•
	batchSize := 20
	fmt.Printf("âš¡ å¼€å§‹æ€§èƒ½æµ‹è¯• (%d æ¡æ¶ˆæ¯)...\n", batchSize)

	start := time.Now()
	successCount := 0
	var publishTimes []time.Duration

	for i := 0; i < batchSize; i++ {
		message := fmt.Sprintf(`{"batch_id": %d, "message": "Kafkaæ€§èƒ½æµ‹è¯•æ¶ˆæ¯ #%d", "data": "test_data_%d", "timestamp": "%s"}`,
			i, i+1, i, time.Now().Format(time.RFC3339))

		msgStart := time.Now()
		err = bus.Publish(ctx, perfTopic, []byte(message))
		msgDuration := time.Since(msgStart)

		if err != nil {
			fmt.Printf("âŒ æ‰¹é‡å‘å¸ƒå¤±è´¥ #%d: %v\n", i+1, err)
		} else {
			successCount++
			publishTimes = append(publishTimes, msgDuration)
		}
	}

	totalDuration := time.Since(start)
	throughput := float64(successCount) / totalDuration.Seconds()

	// è®¡ç®—å¹³å‡å»¶è¿Ÿ
	var totalLatency time.Duration
	for _, latency := range publishTimes {
		totalLatency += latency
	}
	avgLatency := totalLatency / time.Duration(len(publishTimes))

	fmt.Printf("âš¡ æ€§èƒ½æµ‹è¯•ç»“æœ:\n")
	fmt.Printf("   - æˆåŠŸå‘å¸ƒ: %d/%d æ¶ˆæ¯\n", successCount, batchSize)
	fmt.Printf("   - æ€»è€—æ—¶: %v\n", totalDuration)
	fmt.Printf("   - ååé‡: %.2f æ¶ˆæ¯/ç§’\n", throughput)
	fmt.Printf("   - å¹³å‡å»¶è¿Ÿ: %v\n", avgLatency)
	fmt.Printf("   - æˆåŠŸç‡: %.1f%%\n", float64(successCount)/float64(batchSize)*100)

	// æ€§èƒ½è¯„ä¼°
	if throughput > 10 {
		fmt.Println("âœ… æ€§èƒ½æµ‹è¯•ä¼˜ç§€ï¼")
	} else if throughput > 5 {
		fmt.Println("âœ… æ€§èƒ½æµ‹è¯•è‰¯å¥½")
	} else {
		fmt.Println("âš ï¸ æ€§èƒ½æµ‹è¯•ä¸€èˆ¬")
	}
}
