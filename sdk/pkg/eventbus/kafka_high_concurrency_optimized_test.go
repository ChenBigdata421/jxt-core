package eventbus

import (
	"context"
	"encoding/json"
	"fmt"
	"sync"
	"sync/atomic"
	"testing"
	"time"

	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
)

// ğŸ¯ Kafkaé«˜å¹¶å‘ä¼˜åŒ–æµ‹è¯•
// ä¸“é—¨è§£å†³é«˜å‹åŠ›ä¸‹çš„å†å¹³è¡¡é—®é¢˜

// HighConcurrencyConfig é«˜å¹¶å‘æµ‹è¯•é…ç½®
type HighConcurrencyConfig struct {
	TopicCount       int           // topicæ•°é‡
	MessagesPerTopic int           // æ¯ä¸ªtopicçš„æ¶ˆæ¯æ•°é‡
	TestDuration     time.Duration // æµ‹è¯•æŒç»­æ—¶é—´
	BatchSize        int           // æ‰¹é‡å‘é€å¤§å°
	SendRateLimit    time.Duration // å‘é€é€Ÿç‡é™åˆ¶
}

// OptimizedHighConcurrencyConfig ä¼˜åŒ–çš„é«˜å¹¶å‘é…ç½®
func OptimizedHighConcurrencyConfig() HighConcurrencyConfig {
	return HighConcurrencyConfig{
		TopicCount:       5,   // å‡å°‘topicæ•°é‡
		MessagesPerTopic: 1000, // ä¿æŒæ¶ˆæ¯æ•°é‡
		TestDuration:     120 * time.Second, // å¢åŠ æµ‹è¯•æ—¶é—´
		BatchSize:        20,  // å‡å°‘æ‰¹é‡å¤§å°
		SendRateLimit:    10 * time.Millisecond, // æ§åˆ¶å‘é€é€Ÿç‡
	}
}

// HighConcurrencyMetrics é«˜å¹¶å‘æµ‹è¯•æŒ‡æ ‡
type HighConcurrencyMetrics struct {
	// å‘é€æŒ‡æ ‡
	MessagesSent     int64 // å‘é€æ¶ˆæ¯æ€»æ•°
	SendErrors       int64 // å‘é€é”™è¯¯æ•°
	SendLatencySum   int64 // å‘é€å»¶è¿Ÿæ€»å’Œ(å¾®ç§’)
	SendLatencyCount int64 // å‘é€å»¶è¿Ÿè®¡æ•°
	
	// æ¥æ”¶æŒ‡æ ‡
	MessagesReceived int64 // æ¥æ”¶æ¶ˆæ¯æ€»æ•°
	ProcessErrors    int64 // å¤„ç†é”™è¯¯æ•°
	ProcessLatencySum int64 // å¤„ç†å»¶è¿Ÿæ€»å’Œ(å¾®ç§’)
	ProcessLatencyCount int64 // å¤„ç†å»¶è¿Ÿè®¡æ•°
	
	// å†å¹³è¡¡æ£€æµ‹
	ProcessingGaps     int64         // å¤„ç†é—´éš™æ¬¡æ•°
	SuspectedRebalances int64        // ç–‘ä¼¼å†å¹³è¡¡æ¬¡æ•°
	MaxGapDuration     time.Duration // æœ€å¤§å¤„ç†é—´éš™
	OrderViolations    int64         // é¡ºåºè¿åæ¬¡æ•°
	
	// æ€§èƒ½æŒ‡æ ‡
	StartTime        time.Time // å¼€å§‹æ—¶é—´
	EndTime          time.Time // ç»“æŸæ—¶é—´
}

// HighConcurrencyTestMessage é«˜å¹¶å‘æµ‹è¯•æ¶ˆæ¯
type HighConcurrencyTestMessage struct {
	ID        string    `json:"id"`
	Topic     string    `json:"topic"`
	Sequence  int64     `json:"sequence"`
	Timestamp time.Time `json:"timestamp"`
	Data      string    `json:"data"`
}

// TestKafkaHighConcurrencyOptimized Kafkaé«˜å¹¶å‘ä¼˜åŒ–æµ‹è¯•
func TestKafkaHighConcurrencyOptimized(t *testing.T) {
	if testing.Short() {
		t.Skip("Skipping Kafka high concurrency optimized test in short mode")
	}

	config := OptimizedHighConcurrencyConfig()
	metrics := &HighConcurrencyMetrics{
		StartTime: time.Now(),
	}

	// åˆ›å»ºé«˜å¹¶å‘ä¼˜åŒ–çš„Kafka EventBusé…ç½®
	kafkaConfig := &KafkaConfig{
		Brokers: []string{"localhost:29093"},
		Producer: ProducerConfig{
			RequiredAcks:     1, // é™ä½ä¸€è‡´æ€§è¦æ±‚ä»¥æé«˜æ€§èƒ½
			Compression:      "lz4", // ä½¿ç”¨æ›´å¿«çš„å‹ç¼©ç®—æ³•
			FlushFrequency:   50 * time.Millisecond, // å¢åŠ åˆ·æ–°é¢‘ç‡
			FlushMessages:    20, // å‡å°‘æ‰¹é‡å¤§å°
			Timeout:          60 * time.Second, // å¢åŠ è¶…æ—¶æ—¶é—´
			// é«˜å¹¶å‘ä¼˜åŒ–å‚æ•°
			FlushBytes:       512 * 1024, // å‡å°‘åˆ·æ–°å­—èŠ‚æ•°
			RetryMax:         5, // å¢åŠ é‡è¯•æ¬¡æ•°
			BatchSize:        8 * 1024, // å‡å°‘æ‰¹é‡å¤§å°
			BufferSize:       16 * 1024 * 1024, // å‡å°‘ç¼“å†²åŒº
			Idempotent:       false, // ç¦ç”¨å¹‚ç­‰æ€§ä»¥æé«˜æ€§èƒ½
			MaxMessageBytes:  512 * 1024, // å‡å°‘æœ€å¤§æ¶ˆæ¯å¤§å°
			PartitionerType:  "round_robin", // ä½¿ç”¨è½®è¯¢åˆ†åŒºå™¨
			LingerMs:         10 * time.Millisecond, // å¢åŠ å»¶è¿Ÿå‘é€æ—¶é—´
			CompressionLevel: 1, // é™ä½å‹ç¼©çº§åˆ«
			MaxInFlight:      3, // é€‚ä¸­çš„é£è¡Œè¯·æ±‚æ•°
		},
		Consumer: ConsumerConfig{
			GroupID:           "high-concurrency-optimized-group",
			AutoOffsetReset:   "earliest",
			SessionTimeout:    120 * time.Second, // å¤§å¹…å¢åŠ ä¼šè¯è¶…æ—¶
			HeartbeatInterval: 30 * time.Second,  // å¤§å¹…å¢åŠ å¿ƒè·³é—´éš”
			// é«˜å¹¶å‘ä¼˜åŒ–å‚æ•°
			MaxProcessingTime:  180 * time.Second, // å¤§å¹…å¢åŠ å¤„ç†æ—¶é—´
			FetchMinBytes:      1, // æœ€å°è·å–å­—èŠ‚æ•°
			FetchMaxBytes:      10 * 1024 * 1024, // å‡å°‘æœ€å¤§è·å–å­—èŠ‚æ•°
			FetchMaxWait:       2 * time.Second, // å¢åŠ æœ€å¤§ç­‰å¾…æ—¶é—´
			MaxPollRecords:     20, // å¤§å¹…å‡å°‘è½®è¯¢è®°å½•æ•°
			EnableAutoCommit:   true, // å¯ç”¨è‡ªåŠ¨æäº¤ä»¥å‡å°‘å¤æ‚æ€§
			AutoCommitInterval: 10 * time.Second, // å¢åŠ è‡ªåŠ¨æäº¤é—´éš”
			IsolationLevel:     "read_uncommitted", // é™ä½éš”ç¦»çº§åˆ«
			RebalanceStrategy:  "cooperative_sticky", // ä½¿ç”¨åä½œç²˜æ€§ç­–ç•¥
		},
		HealthCheckInterval:  60 * time.Second, // å¢åŠ å¥åº·æ£€æŸ¥é—´éš”
		ClientID:             "high-concurrency-optimized-client",
		MetadataRefreshFreq:  30 * time.Minute, // å¢åŠ å…ƒæ•°æ®åˆ·æ–°é¢‘ç‡
		MetadataRetryMax:     5,
		MetadataRetryBackoff: 500 * time.Millisecond,
		Net: NetConfig{
			DialTimeout:  60 * time.Second, // å¢åŠ è¿æ¥è¶…æ—¶
			ReadTimeout:  60 * time.Second, // å¢åŠ è¯»å–è¶…æ—¶
			WriteTimeout: 60 * time.Second, // å¢åŠ å†™å…¥è¶…æ—¶
			KeepAlive:    60 * time.Second, // å¢åŠ ä¿æ´»æ—¶é—´
			MaxIdleConns: 20, // å¢åŠ æœ€å¤§ç©ºé—²è¿æ¥æ•°
			MaxOpenConns: 200, // å¢åŠ æœ€å¤§æ‰“å¼€è¿æ¥æ•°
		},
	}

	eventBus, err := NewKafkaEventBus(kafkaConfig)
	require.NoError(t, err, "Failed to create optimized Kafka EventBus")
	defer eventBus.Close()

	// ç­‰å¾…è¿æ¥å»ºç«‹å’Œåˆ†åŒºåˆ†é…ç¨³å®š
	t.Logf("â³ Waiting for Kafka to stabilize...")
	time.Sleep(10 * time.Second)

	t.Logf("ğŸš€ Starting Kafka High Concurrency Optimized Test")
	t.Logf("ğŸ“Š Config: %d topics, %d msgs/topic, total: %d messages",
		config.TopicCount, config.MessagesPerTopic, config.TopicCount*config.MessagesPerTopic)

	// è¿è¡Œé«˜å¹¶å‘ä¼˜åŒ–æµ‹è¯•
	runHighConcurrencyOptimizedTest(t, eventBus, config, metrics)

	// åˆ†æç»“æœ
	analyzeHighConcurrencyResults(t, config, metrics)
}

// runHighConcurrencyOptimizedTest è¿è¡Œé«˜å¹¶å‘ä¼˜åŒ–æµ‹è¯•
func runHighConcurrencyOptimizedTest(t *testing.T, eventBus EventBus, config HighConcurrencyConfig, metrics *HighConcurrencyMetrics) {
	ctx, cancel := context.WithTimeout(context.Background(), config.TestDuration+30*time.Second)
	defer cancel()

	// åˆ›å»ºtopicåˆ—è¡¨
	topics := make([]string, config.TopicCount)
	for i := 0; i < config.TopicCount; i++ {
		topics[i] = fmt.Sprintf("high.concurrency.optimized.topic.%d", i)
	}

	// è®¾ç½®æ¶ˆæ¯å¤„ç†å™¨
	var wg sync.WaitGroup
	setupHighConcurrencyHandlers(t, eventBus, topics, metrics, &wg)

	// ç­‰å¾…è®¢é˜…å»ºç«‹å’Œåˆ†åŒºåˆ†é…ç¨³å®š
	t.Logf("â³ Waiting for subscriptions to stabilize...")
	time.Sleep(5 * time.Second)

	// å¼€å§‹å‘é€æ¶ˆæ¯
	metrics.StartTime = time.Now()
	sendHighConcurrencyMessages(t, eventBus, topics, config, metrics)

	// ç­‰å¾…æ¶ˆæ¯å¤„ç†å®Œæˆ
	done := make(chan struct{})
	go func() {
		wg.Wait()
		close(done)
	}()

	select {
	case <-done:
		t.Logf("âœ… All messages processed successfully")
	case <-time.After(config.TestDuration):
		t.Logf("â° Test timeout reached")
	case <-ctx.Done():
		t.Logf("ğŸ›‘ Context cancelled")
	}

	metrics.EndTime = time.Now()
}

// setupHighConcurrencyHandlers è®¾ç½®é«˜å¹¶å‘æ¶ˆæ¯å¤„ç†å™¨
func setupHighConcurrencyHandlers(t *testing.T, eventBus EventBus, topics []string, metrics *HighConcurrencyMetrics, wg *sync.WaitGroup) {
	for _, topic := range topics {
		wg.Add(1)
		go func(topicName string) {
			defer wg.Done()
			
			var lastSequence int64 = -1
			var lastProcessTime time.Time = time.Now()
			
			handler := func(ctx context.Context, message []byte) error {
				currentTime := time.Now()
				
				// æ£€æµ‹å¤„ç†é—´éš™
				if !lastProcessTime.IsZero() {
					gap := currentTime.Sub(lastProcessTime)
					if gap > 10*time.Second { // è¶…è¿‡10ç§’è®¤ä¸ºæ˜¯å¼‚å¸¸é—´éš™
						atomic.AddInt64(&metrics.ProcessingGaps, 1)
						if gap > 30*time.Second { // è¶…è¿‡30ç§’è®¤ä¸ºæ˜¯å†å¹³è¡¡
							atomic.AddInt64(&metrics.SuspectedRebalances, 1)
							t.Logf("ğŸš¨ Suspected rebalance: %v gap in topic %s", gap, topicName)
						}
						
						if gap > metrics.MaxGapDuration {
							metrics.MaxGapDuration = gap
						}
					}
				}
				lastProcessTime = currentTime
				
				// è§£ææ¶ˆæ¯
				var testMsg HighConcurrencyTestMessage
				if err := json.Unmarshal(message, &testMsg); err != nil {
					atomic.AddInt64(&metrics.ProcessErrors, 1)
					return err
				}
				
				// æ£€æµ‹é¡ºåºè¿å
				if lastSequence >= 0 && testMsg.Sequence <= lastSequence {
					atomic.AddInt64(&metrics.OrderViolations, 1)
				}
				lastSequence = testMsg.Sequence
				
				// æ›´æ–°æ¥æ”¶è®¡æ•°
				atomic.AddInt64(&metrics.MessagesReceived, 1)
				
				// è®°å½•å¤„ç†å»¶è¿Ÿ
				processingTime := time.Since(testMsg.Timestamp).Microseconds()
				atomic.AddInt64(&metrics.ProcessLatencySum, processingTime)
				atomic.AddInt64(&metrics.ProcessLatencyCount, 1)
				
				return nil
			}
			
			err := eventBus.Subscribe(context.Background(), topicName, handler)
			if err != nil {
				t.Errorf("Failed to subscribe to topic %s: %v", topicName, err)
			}
		}(topic)
	}
}

// sendHighConcurrencyMessages å‘é€é«˜å¹¶å‘æ¶ˆæ¯
func sendHighConcurrencyMessages(t *testing.T, eventBus EventBus, topics []string, config HighConcurrencyConfig, metrics *HighConcurrencyMetrics) {
	var sendWg sync.WaitGroup
	
	for _, topic := range topics {
		sendWg.Add(1)
		go func(topicName string) {
			defer sendWg.Done()
			
			for i := 0; i < config.MessagesPerTopic; i++ {
				testMsg := HighConcurrencyTestMessage{
					ID:        fmt.Sprintf("%s-%d", topicName, i),
					Topic:     topicName,
					Sequence:  int64(i),
					Timestamp: time.Now(),
					Data:      fmt.Sprintf("high-concurrency-data-%d", i),
				}
				
				messageBytes, err := json.Marshal(testMsg)
				if err != nil {
					atomic.AddInt64(&metrics.SendErrors, 1)
					continue
				}
				
				startTime := time.Now()
				err = eventBus.Publish(context.Background(), topicName, messageBytes)
				sendTime := time.Since(startTime).Microseconds()
				
				if err != nil {
					atomic.AddInt64(&metrics.SendErrors, 1)
				} else {
					atomic.AddInt64(&metrics.MessagesSent, 1)
					atomic.AddInt64(&metrics.SendLatencySum, sendTime)
					atomic.AddInt64(&metrics.SendLatencyCount, 1)
				}
				
				// æ§åˆ¶å‘é€é€Ÿç‡
				if config.SendRateLimit > 0 {
					time.Sleep(config.SendRateLimit)
				}
			}
		}(topic)
	}
	
	sendWg.Wait()
	t.Logf("ğŸ“¤ Finished sending high concurrency messages")
}

// analyzeHighConcurrencyResults åˆ†æé«˜å¹¶å‘ç»“æœ
func analyzeHighConcurrencyResults(t *testing.T, config HighConcurrencyConfig, metrics *HighConcurrencyMetrics) {
	duration := metrics.EndTime.Sub(metrics.StartTime)
	successRate := float64(metrics.MessagesReceived) / float64(metrics.MessagesSent) * 100
	throughput := float64(metrics.MessagesReceived) / duration.Seconds()
	
	avgSendLatency := float64(metrics.SendLatencySum) / float64(metrics.SendLatencyCount) / 1000.0 // ms
	avgProcessLatency := float64(metrics.ProcessLatencySum) / float64(metrics.ProcessLatencyCount) / 1000.0 // ms
	
	t.Logf("\nğŸ¯ ===== Kafka High Concurrency Optimized Results =====")
	t.Logf("â±ï¸  Test Duration: %v", duration)
	t.Logf("ğŸ“¤ Messages Sent: %d", metrics.MessagesSent)
	t.Logf("ğŸ“¥ Messages Received: %d", metrics.MessagesReceived)
	t.Logf("âœ… Success Rate: %.2f%%", successRate)
	t.Logf("ğŸš€ Throughput: %.2f msg/s", throughput)
	t.Logf("âš¡ Avg Send Latency: %.2f ms", avgSendLatency)
	t.Logf("âš¡ Avg Process Latency: %.2f ms", avgProcessLatency)
	
	t.Logf("\nğŸš¨ Rebalance Analysis:")
	t.Logf("   Processing Gaps (>10s): %d", metrics.ProcessingGaps)
	t.Logf("   Suspected Rebalances (>30s): %d", metrics.SuspectedRebalances)
	t.Logf("   Max Gap Duration: %v", metrics.MaxGapDuration)
	t.Logf("   Order Violations: %d", metrics.OrderViolations)
	
	// è¯„ä¼°ä¼˜åŒ–æ•ˆæœ
	if successRate >= 95.0 {
		t.Logf("\nğŸ‰ ä¼˜ç§€! é«˜å¹¶å‘ä¼˜åŒ–æˆåŠŸï¼ŒæˆåŠŸç‡è¾¾åˆ° %.2f%%", successRate)
	} else if successRate >= 80.0 {
		t.Logf("\nâš ï¸ è‰¯å¥½! é«˜å¹¶å‘ä¼˜åŒ–æœ‰æ•ˆï¼ŒæˆåŠŸç‡è¾¾åˆ° %.2f%%", successRate)
	} else {
		t.Logf("\nâŒ éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ï¼ŒæˆåŠŸç‡ä»…ä¸º %.2f%%", successRate)
	}
	
	if metrics.SuspectedRebalances == 0 {
		t.Logf("âœ… å†å¹³è¡¡é—®é¢˜å·²è§£å†³!")
	} else {
		t.Logf("âš ï¸ ä»æœ‰ %d æ¬¡ç–‘ä¼¼å†å¹³è¡¡", metrics.SuspectedRebalances)
	}
	
	// åŸºæœ¬éªŒè¯
	assert.Greater(t, metrics.MessagesSent, int64(0), "Should send messages")
	assert.Greater(t, metrics.MessagesReceived, int64(0), "Should receive messages")
	assert.Greater(t, successRate, 80.0, "Success rate should be > 80%")
	assert.LessOrEqual(t, metrics.SuspectedRebalances, int64(2), "Should have minimal rebalances")
	
	t.Logf("âœ… Kafka High Concurrency Optimized Test Completed!")
}
