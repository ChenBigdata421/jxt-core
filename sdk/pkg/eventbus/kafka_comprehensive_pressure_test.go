package eventbus

import (
	"context"
	"fmt"
	"runtime"
	"sync/atomic"
	"testing"
	"time"
)

// PressureLevel å‹åŠ›çº§åˆ«
type PressureLevel struct {
	Name         string
	MessageCount int
	Concurrency  int
	MessageSize  int
	Timeout      time.Duration
}

// ComprehensivePressureMetrics Kafkaå…¨é¢å‹åŠ›æµ‹è¯•æŒ‡æ ‡
type ComprehensivePressureMetrics struct {
	PressureLevel     string
	MessageCount      int
	Concurrency       int
	MessageSize       int
	SentCount         int64
	ReceivedCount     int64
	ErrorCount        int64
	SuccessRate       float64
	SendRate          float64
	Throughput        float64
	FirstMsgLatency   time.Duration
	AverageLatency    time.Duration
	P95Latency        time.Duration
	P99Latency        time.Duration
	MaxLatency        time.Duration
	MinLatency        time.Duration
	TotalDuration     time.Duration
	SendDuration      time.Duration
	InitialMemoryMB   float64
	PeakMemoryMB      float64
	MemoryDeltaMB     float64
	InitialGoroutines int
	PeakGoroutines    int
	GoroutineDelta    int
}

// TestKafkaComprehensivePressure EventBus+Kafkaå…¨é¢å‹åŠ›æµ‹è¯•
func TestKafkaComprehensivePressure(t *testing.T) {
	t.Log("ğŸš€ EVENTBUS + KAFKA å…¨é¢å‹åŠ›æµ‹è¯•")
	t.Log("=" + string(make([]byte, 100)))
	t.Log("ğŸ“Š æµ‹è¯•ä¼˜åŒ–åçš„AsyncProducer + æ‰¹å¤„ç† + LZ4å‹ç¼©é…ç½®")
	t.Log("")

	// å®šä¹‰å‹åŠ›çº§åˆ«
	pressureLevels := []PressureLevel{
		{
			Name:         "ä½å‹",
			MessageCount: 500,
			Concurrency:  5,
			MessageSize:  1024,
			Timeout:      2 * time.Minute,
		},
		{
			Name:         "ä¸­å‹",
			MessageCount: 2000,
			Concurrency:  10,
			MessageSize:  2048,
			Timeout:      3 * time.Minute,
		},
		{
			Name:         "é«˜å‹",
			MessageCount: 5000,
			Concurrency:  20,
			MessageSize:  4096,
			Timeout:      5 * time.Minute,
		},
		{
			Name:         "æé™",
			MessageCount: 10000,
			Concurrency:  50,
			MessageSize:  8192,
			Timeout:      10 * time.Minute,
		},
	}

	allResults := make([]*ComprehensivePressureMetrics, 0)

	for _, level := range pressureLevels {
		separator := string(make([]byte, 100))
		t.Logf("\n%s", separator)
		t.Logf("ğŸ¯ å¼€å§‹æµ‹è¯•: %s", level.Name)
		t.Logf("   æ¶ˆæ¯æ•°é‡: %d", level.MessageCount)
		t.Logf("   å¹¶å‘æ•°: %d", level.Concurrency)
		t.Logf("   æ¶ˆæ¯å¤§å°: %d bytes", level.MessageSize)
		t.Logf("   è¶…æ—¶æ—¶é—´: %v", level.Timeout)

		metrics := runKafkaFullPressureTest(t, level)
		allResults = append(allResults, metrics)

		// è¾“å‡ºæœ¬è½®ç»“æœ
		printFullPressureMetrics(t, metrics)

		// æ¸…ç†é—´éš”
		t.Logf("â³ æ¸…ç†èµ„æºï¼Œç­‰å¾…5ç§’...")
		time.Sleep(5 * time.Second)
		runtime.GC()
	}

	// ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
	generateFinalPressureReport(t, allResults)
}

// runKafkaFullPressureTest è¿è¡Œå•ä¸ªå‹åŠ›çº§åˆ«æµ‹è¯•
func runKafkaFullPressureTest(t *testing.T, level PressureLevel) *ComprehensivePressureMetrics {
	// ğŸ”§ å…³é”®ä¿®å¤ï¼šClientIDå’Œtopicä¸èƒ½åŒ…å«ä¸­æ–‡å­—ç¬¦
	levelNameMap := map[string]string{
		"ä½å‹": "low",
		"ä¸­å‹": "medium",
		"é«˜å‹": "high",
		"æé™": "extreme",
	}
	levelNameEn := levelNameMap[level.Name]
	if levelNameEn == "" {
		levelNameEn = level.Name // fallback
	}

	// å…ˆç”Ÿæˆtopicåç§°
	topic := fmt.Sprintf("pressure-test-%s-%d", levelNameEn, time.Now().UnixNano())

	// åˆ›å»ºä¼˜åŒ–åçš„Kafkaé…ç½®
	config := &KafkaConfig{
		Brokers:  []string{"localhost:29094"},
		ClientID: fmt.Sprintf("pressure-test-%s-%d", levelNameEn, time.Now().UnixNano()),
		Producer: ProducerConfig{
			RequiredAcks:    1,
			Compression:     "lz4",                 // LZ4å‹ç¼©
			FlushFrequency:  10 * time.Millisecond, // 10msæ‰¹é‡
			FlushMessages:   100,                   // 100æ¡æ¶ˆæ¯
			FlushBytes:      100000,                // 100KB
			RetryMax:        3,
			Timeout:         10 * time.Second,
			MaxMessageBytes: 10 * 1024 * 1024, // 10MB
			MaxInFlight:     100,              // 100å¹¶å‘è¯·æ±‚
		},
		Consumer: ConsumerConfig{
			GroupID:           fmt.Sprintf("pressure-group-%d", time.Now().UnixNano()), // æ¯æ¬¡ä½¿ç”¨æ–°çš„Consumer Group ID
			SessionTimeout:    10 * time.Second,
			HeartbeatInterval: 3 * time.Second,
			MaxProcessingTime: 1 * time.Second,        // å’ŒæˆåŠŸçš„æµ‹è¯•ä¸€è‡´
			FetchMinBytes:     1,                      // è®¾ç½®ä¸º1ï¼Œç¡®ä¿èƒ½ç«‹å³è¯»å–
			FetchMaxBytes:     10 * 1024 * 1024,       // 10MB
			FetchMaxWait:      500 * time.Millisecond, // 500ms
			AutoOffsetReset:   "earliest",             // ä½¿ç”¨earliestç¡®ä¿èƒ½è¯»å–æ‰€æœ‰æ¶ˆæ¯
			RebalanceStrategy: "range",
			IsolationLevel:    "read_uncommitted",
		},
		Net: NetConfig{
			DialTimeout:  10 * time.Second,
			ReadTimeout:  30 * time.Second,
			WriteTimeout: 30 * time.Second,
			KeepAlive:    30 * time.Second,
		},
		MetadataRefreshFreq:  10 * time.Minute,
		MetadataRetryMax:     3,
		MetadataRetryBackoff: 250 * time.Millisecond,
		HealthCheckInterval:  30 * time.Second,
	}

	// åˆ›å»ºEventBus
	bus, err := NewKafkaEventBus(config)
	if err != nil {
		t.Fatalf("âŒ Failed to create Kafka EventBus: %v", err)
	}
	defer bus.Close()

	// åˆå§‹åŒ–æŒ‡æ ‡
	metrics := &ComprehensivePressureMetrics{
		PressureLevel: level.Name,
		MessageCount:  level.MessageCount,
		Concurrency:   level.Concurrency,
		MessageSize:   level.MessageSize,
		MinLatency:    time.Hour, // åˆå§‹åŒ–ä¸ºå¾ˆå¤§çš„å€¼
	}

	// è®°å½•åˆå§‹èµ„æºçŠ¶æ€
	metrics.InitialGoroutines = runtime.NumGoroutine()
	var m runtime.MemStats
	runtime.ReadMemStats(&m)
	metrics.InitialMemoryMB = float64(m.Alloc) / 1024 / 1024

	// topicå·²ç»åœ¨å‡½æ•°å¼€å¤´åˆ›å»º
	ctx := context.Background()

	// ğŸš€ é…ç½®é¢„è®¢é˜…æ¨¡å¼ï¼ˆåœ¨Subscribeä¹‹å‰è®¾ç½®ï¼‰
	if kafkaBus, ok := bus.(*kafkaEventBus); ok {
		kafkaBus.allPossibleTopics = []string{topic}
		t.Logf("âœ… é…ç½®é¢„è®¢é˜…: %s", topic)
	}

	// æ¥æ”¶è®¡æ•°å™¨
	var receivedCount atomic.Int64
	var firstMsgTime atomic.Value // time.Time
	receivedChan := make(chan struct{}, level.MessageCount)

	// è®¢é˜…ï¼ˆç®€åŒ–handlerï¼‰
	handler := func(ctx context.Context, message []byte) error {
		now := time.Now()

		// è®°å½•ç¬¬ä¸€æ¡æ¶ˆæ¯æ—¶é—´
		if firstMsgTime.Load() == nil {
			firstMsgTime.Store(now)
		}

		receivedCount.Add(1)
		receivedChan <- struct{}{} // é€šçŸ¥æ¥æ”¶åˆ°æ¶ˆæ¯
		return nil
	}

	err = bus.Subscribe(ctx, topic, handler)
	if err != nil {
		t.Fatalf("âŒ Failed to subscribe: %v", err)
	}
	t.Logf("âœ… è®¢é˜…æˆåŠŸ: %s", topic)

	// ç­‰å¾…è®¢é˜…å°±ç»ª
	time.Sleep(5 * time.Second)

	// å¼€å§‹å‘é€ï¼ˆæ”¹ä¸ºå•çº¿ç¨‹å‘é€ï¼Œç®€åŒ–è°ƒè¯•ï¼‰
	t.Logf("ğŸ“¤ å¼€å§‹å‘é€ %d æ¡æ¶ˆæ¯...", level.MessageCount)
	sendStart := time.Now()

	var sentCount atomic.Int64
	var sendErrors atomic.Int64

	// å•çº¿ç¨‹å‘é€
	for i := 0; i < level.MessageCount; i++ {
		// åˆ›å»ºç®€å•æ¶ˆæ¯ï¼ˆä¸ä½¿ç”¨JSONï¼Œç®€åŒ–è°ƒè¯•ï¼‰
		message := []byte(fmt.Sprintf("Message #%d", i))

		err := bus.Publish(ctx, topic, message)
		if err != nil {
			sendErrors.Add(1)
			t.Logf("âŒ å‘é€å¤±è´¥ #%d: %v", i, err)
		} else {
			sentCount.Add(1)
		}
	}

	metrics.SendDuration = time.Since(sendStart)
	metrics.SentCount = sentCount.Load()
	metrics.ErrorCount = sendErrors.Load()
	metrics.SendRate = float64(metrics.SentCount) / metrics.SendDuration.Seconds()

	t.Logf("âœ… å‘é€å®Œæˆ: %v", metrics.SendDuration)
	t.Logf("   å‘é€æˆåŠŸ: %d/%d", metrics.SentCount, level.MessageCount)
	t.Logf("   å‘é€é€Ÿç‡: %.2f msg/s", metrics.SendRate)
	t.Logf("   å‘é€é”™è¯¯: %d", metrics.ErrorCount)

	// ç­‰å¾…AsyncProduceræ‰¹é‡å‘é€å®Œæˆ
	t.Logf("â³ ç­‰å¾…AsyncProduceræ‰¹é‡å‘é€å®Œæˆ...")
	time.Sleep(10 * time.Second)

	// ç­‰å¾…æ¥æ”¶
	t.Logf("ğŸ“¥ ç­‰å¾…æ¥æ”¶æ¶ˆæ¯ï¼ˆè¶…æ—¶: %vï¼‰...", level.Timeout)
	timeoutTimer := time.NewTimer(level.Timeout)
	defer timeoutTimer.Stop()

	receivedInTime := 0
	ticker := time.NewTicker(5 * time.Second)
	defer ticker.Stop()

receiveLoop:
	for receivedInTime < level.MessageCount {
		select {
		case <-receivedChan:
			receivedInTime++
		case <-ticker.C:
			progress := float64(receivedInTime) / float64(level.MessageCount) * 100
			t.Logf("   è¿›åº¦: %d/%d (%.1f%%)", receivedInTime, level.MessageCount, progress)
		case <-timeoutTimer.C:
			t.Logf("â±ï¸  æ¥æ”¶è¶…æ—¶")
			break receiveLoop
		}
	}

	metrics.TotalDuration = time.Since(sendStart)
	metrics.ReceivedCount = receivedCount.Load()
	metrics.SuccessRate = float64(metrics.ReceivedCount) / float64(level.MessageCount) * 100
	metrics.Throughput = float64(metrics.ReceivedCount) / metrics.TotalDuration.Seconds()

	// è®¡ç®—å»¶è¿ŸæŒ‡æ ‡ï¼ˆç®€åŒ–ç‰ˆï¼‰
	if firstMsgTime.Load() != nil {
		metrics.FirstMsgLatency = firstMsgTime.Load().(time.Time).Sub(sendStart)
	}

	// è®°å½•å³°å€¼èµ„æºä½¿ç”¨
	metrics.PeakGoroutines = runtime.NumGoroutine()
	metrics.GoroutineDelta = metrics.PeakGoroutines - metrics.InitialGoroutines

	runtime.ReadMemStats(&m)
	metrics.PeakMemoryMB = float64(m.Alloc) / 1024 / 1024
	metrics.MemoryDeltaMB = metrics.PeakMemoryMB - metrics.InitialMemoryMB

	return metrics
}

// sortLatencies ç®€å•çš„å†’æ³¡æ’åº
func sortLatencies(latencies []time.Duration) {
	n := len(latencies)
	for i := 0; i < n; i++ {
		for j := i + 1; j < n; j++ {
			if latencies[i] > latencies[j] {
				latencies[i], latencies[j] = latencies[j], latencies[i]
			}
		}
	}
}

// printFullPressureMetrics æ‰“å°å‹åŠ›æµ‹è¯•æŒ‡æ ‡
func printFullPressureMetrics(t *testing.T, m *ComprehensivePressureMetrics) {
	t.Logf("\nğŸ“Š ===== %s æµ‹è¯•ç»“æœ =====", m.PressureLevel)
	t.Logf("âœ… æˆåŠŸç‡: %.2f%% (%d/%d)", m.SuccessRate, m.ReceivedCount, m.MessageCount)
	t.Logf("ğŸš€ ååé‡: %.2f msg/s", m.Throughput)
	t.Logf("ğŸ“¤ å‘é€é€Ÿç‡: %.2f msg/s", m.SendRate)
	t.Logf("â±ï¸  å»¶è¿ŸæŒ‡æ ‡:")
	t.Logf("   é¦–æ¡å»¶è¿Ÿ: %v", m.FirstMsgLatency)
	t.Logf("   å¹³å‡å»¶è¿Ÿ: %v", m.AverageLatency)
	t.Logf("   P95å»¶è¿Ÿ: %v", m.P95Latency)
	t.Logf("   P99å»¶è¿Ÿ: %v", m.P99Latency)
	t.Logf("   æœ€å°å»¶è¿Ÿ: %v", m.MinLatency)
	t.Logf("   æœ€å¤§å»¶è¿Ÿ: %v", m.MaxLatency)
	t.Logf("â° æ—¶é—´æŒ‡æ ‡:")
	t.Logf("   å‘é€è€—æ—¶: %v", m.SendDuration)
	t.Logf("   æ€»è€—æ—¶: %v", m.TotalDuration)
	t.Logf("ğŸ’¾ èµ„æºä½¿ç”¨:")
	t.Logf("   å†…å­˜å¢é‡: %.2f MB (%.2f â†’ %.2f)", m.MemoryDeltaMB, m.InitialMemoryMB, m.PeakMemoryMB)
	t.Logf("   Goroutineå¢é‡: %d (%d â†’ %d)", m.GoroutineDelta, m.InitialGoroutines, m.PeakGoroutines)
}

// generateFinalPressureReport ç”Ÿæˆæœ€ç»ˆå‹åŠ›æµ‹è¯•æŠ¥å‘Š
func generateFinalPressureReport(t *testing.T, results []*ComprehensivePressureMetrics) {
	separator1 := string(make([]byte, 100))
	t.Logf("\n%s", separator1)
	t.Logf("ğŸ“Š ===== EVENTBUS + KAFKA å…¨é¢å‹åŠ›æµ‹è¯•æ€»ç»“ =====")
	t.Logf("")

	// è¡¨æ ¼å¤´
	t.Logf("%-10s | %8s | %8s | %10s | %10s | %10s | %10s | %10s",
		"å‹åŠ›çº§åˆ«", "æ¶ˆæ¯æ•°", "å¹¶å‘æ•°", "æˆåŠŸç‡", "ååé‡", "å¹³å‡å»¶è¿Ÿ", "P95å»¶è¿Ÿ", "å†…å­˜å¢é‡")
	separator2 := string(make([]byte, 110))
	t.Logf("%s", separator2)

	// è¡¨æ ¼æ•°æ®
	for _, m := range results {
		t.Logf("%-10s | %8d | %8d | %9.2f%% | %8.2f/s | %10v | %10v | %8.2fMB",
			m.PressureLevel,
			m.MessageCount,
			m.Concurrency,
			m.SuccessRate,
			m.Throughput,
			m.AverageLatency,
			m.P95Latency,
			m.MemoryDeltaMB)
	}

	t.Logf("")
	t.Logf("ğŸ¯ æ€§èƒ½åˆ†æ:")

	// æ‰¾å‡ºæœ€ä½³å’Œæœ€å·®æ€§èƒ½
	var bestThroughput, worstThroughput *ComprehensivePressureMetrics
	var bestLatency, worstLatency *ComprehensivePressureMetrics
	var bestSuccessRate, worstSuccessRate *ComprehensivePressureMetrics

	for i, m := range results {
		if i == 0 {
			bestThroughput = m
			worstThroughput = m
			bestLatency = m
			worstLatency = m
			bestSuccessRate = m
			worstSuccessRate = m
			continue
		}

		if m.Throughput > bestThroughput.Throughput {
			bestThroughput = m
		}
		if m.Throughput < worstThroughput.Throughput {
			worstThroughput = m
		}

		if m.AverageLatency < bestLatency.AverageLatency {
			bestLatency = m
		}
		if m.AverageLatency > worstLatency.AverageLatency {
			worstLatency = m
		}

		if m.SuccessRate > bestSuccessRate.SuccessRate {
			bestSuccessRate = m
		}
		if m.SuccessRate < worstSuccessRate.SuccessRate {
			worstSuccessRate = m
		}
	}

	t.Logf("   ğŸ† æœ€é«˜ååé‡: %s (%.2f msg/s)", bestThroughput.PressureLevel, bestThroughput.Throughput)
	t.Logf("   âš¡ æœ€ä½å»¶è¿Ÿ: %s (%v)", bestLatency.PressureLevel, bestLatency.AverageLatency)
	t.Logf("   âœ… æœ€é«˜æˆåŠŸç‡: %s (%.2f%%)", bestSuccessRate.PressureLevel, bestSuccessRate.SuccessRate)

	t.Logf("")
	t.Logf("ğŸ“ˆ æ€§èƒ½è¶‹åŠ¿:")

	// è®¡ç®—æ€§èƒ½è¶‹åŠ¿
	if len(results) >= 2 {
		firstResult := results[0]
		lastResult := results[len(results)-1]

		throughputChange := (lastResult.Throughput - firstResult.Throughput) / firstResult.Throughput * 100
		latencyChange := float64(lastResult.AverageLatency-firstResult.AverageLatency) / float64(firstResult.AverageLatency) * 100
		successRateChange := lastResult.SuccessRate - firstResult.SuccessRate

		t.Logf("   ååé‡å˜åŒ–: %.2f%% (%s â†’ %s)", throughputChange, firstResult.PressureLevel, lastResult.PressureLevel)
		t.Logf("   å»¶è¿Ÿå˜åŒ–: %.2f%% (%s â†’ %s)", latencyChange, firstResult.PressureLevel, lastResult.PressureLevel)
		t.Logf("   æˆåŠŸç‡å˜åŒ–: %.2f%% (%s â†’ %s)", successRateChange, firstResult.PressureLevel, lastResult.PressureLevel)
	}

	t.Logf("")
	t.Logf("ğŸ“ ç»“è®º:")

	// è¯„ä¼°æ•´ä½“æ€§èƒ½
	allPassed := true
	for _, m := range results {
		if m.SuccessRate < 95.0 {
			allPassed = false
			t.Logf("   âš ï¸  %s: æˆåŠŸç‡ %.2f%% < 95%%", m.PressureLevel, m.SuccessRate)
		}
	}

	if allPassed {
		t.Logf("   âœ… æ‰€æœ‰å‹åŠ›çº§åˆ«æµ‹è¯•é€šè¿‡ï¼")
		t.Logf("   âœ… EventBus + Kafka (AsyncProducerä¼˜åŒ–ç‰ˆ) æ€§èƒ½ä¼˜ç§€ï¼")
	} else {
		t.Logf("   âš ï¸  éƒ¨åˆ†å‹åŠ›çº§åˆ«æœªè¾¾æ ‡ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
	}

	t.Logf("")
	t.Logf("ğŸš€ ä¼˜åŒ–é…ç½®:")
	t.Logf("   âœ… AsyncProducer (éé˜»å¡å¼‚æ­¥å‘é€)")
	t.Logf("   âœ… LZ4å‹ç¼© (Confluentå®˜æ–¹é¦–é€‰)")
	t.Logf("   âœ… æ‰¹å¤„ç†: 10ms / 100æ¡ / 100KB")
	t.Logf("   âœ… Consumer Fetch: 100KB-10MB / 500ms")
	t.Logf("   âœ… å¹¶å‘è¯·æ±‚: 100")

	t.Logf("")
	separator3 := string(make([]byte, 100))
	t.Logf("=%s", separator3)
	t.Logf("æµ‹è¯•å®Œæˆæ—¶é—´: %s", time.Now().Format("2006-01-02 15:04:05"))
}
