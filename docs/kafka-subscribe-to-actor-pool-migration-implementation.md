# Kafka EventBus Subscribe() è¿ç§»åˆ° Hollywood Actor Pool - å®æ–½è®¡åˆ’æ–‡æ¡£

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¥æœŸ**: 2025-10-30  
**çŠ¶æ€**: å¾…è¯„å®¡  
**ä½œè€…**: AI Assistant  

---

## ğŸ“‹ ç›®å½•

1. [å®æ–½æ¦‚è§ˆ](#å®æ–½æ¦‚è§ˆ)
2. [ä»£ç ä¿®æ”¹æ¸…å•](#ä»£ç ä¿®æ”¹æ¸…å•)
3. [è¯¦ç»†å®æ–½æ­¥éª¤](#è¯¦ç»†å®æ–½æ­¥éª¤)
4. [æµ‹è¯•éªŒè¯è®¡åˆ’](#æµ‹è¯•éªŒè¯è®¡åˆ’)
5. [å›æ»šæ–¹æ¡ˆ](#å›æ»šæ–¹æ¡ˆ)

---

## å®æ–½æ¦‚è§ˆ

### ğŸ¯ **å®æ–½ç›®æ ‡**

1. ä¿®æ”¹ `processMessageWithKeyedPool` æ–¹æ³•ï¼Œç»Ÿä¸€ä½¿ç”¨ Hollywood Actor Pool
2. åˆ é™¤å…¨å±€ Worker Pool ç›¸å…³ä»£ç ï¼ˆçº¦ 200+ è¡Œï¼Œä»¥ç¬¦å·åä¸ºå‡†ï¼‰
3. æ›´æ–°è·¯ç”±é€»è¾‘ï¼Œæ”¯æŒ Round-Robin è½®è¯¢è·¯ç”±
4. æ·»åŠ è½®è¯¢è®¡æ•°å™¨å­—æ®µåˆ° `kafkaEventBus` ç»“æ„
5. æ›´æ–°æµ‹è¯•ç”¨ä¾‹ï¼ŒéªŒè¯æ–°å®ç°
6. æ›´æ–°æ–‡æ¡£ï¼Œè¯´æ˜æ¶æ„å˜åŒ–

### ğŸ“Š **å·¥ä½œé‡ä¼°ç®—**

| ä»»åŠ¡ | æ–‡ä»¶æ•° | ä»£ç è¡Œæ•° | é¢„è®¡æ—¶é—´ |
|------|-------|---------|---------|
| **ä»£ç ä¿®æ”¹** | 1 | ~50 è¡Œä¿®æ”¹ + 200+ è¡Œåˆ é™¤ | 2 å°æ—¶ |
| **æµ‹è¯•ä¿®æ”¹** | 0 | 0 è¡Œï¼ˆç°æœ‰æµ‹è¯•æ— éœ€ä¿®æ”¹ï¼‰ | 0 å°æ—¶ |
| **æ–‡æ¡£æ›´æ–°** | 2 | ~100 è¡Œ | 1 å°æ—¶ |
| **æµ‹è¯•éªŒè¯** | - | - | 2.5 å°æ—¶ |
| **æ€»è®¡** | 3 | ~350 è¡Œ | 5.5 å°æ—¶ |

### ğŸ”„ **å®æ–½é˜¶æ®µ**

```
é˜¶æ®µ 1: ä»£ç ä¿®æ”¹ï¼ˆ2 å°æ—¶ï¼‰
  â”œâ”€ æ­¥éª¤ 1: ä¿®æ”¹è·¯ç”±é€»è¾‘ï¼ˆ30 åˆ†é’Ÿï¼‰
  â”œâ”€ æ­¥éª¤ 2: åˆ é™¤ Worker Pool ä»£ç ï¼ˆ30 åˆ†é’Ÿï¼‰
  â”œâ”€ æ­¥éª¤ 3: æ¸…ç†åˆå§‹åŒ–å’Œå…³é—­é€»è¾‘ï¼ˆ30 åˆ†é’Ÿï¼‰
  â””â”€ æ­¥éª¤ 4: ä»£ç å®¡æŸ¥å’Œä¼˜åŒ–ï¼ˆ30 åˆ†é’Ÿï¼‰

é˜¶æ®µ 2: æµ‹è¯•éªŒè¯ï¼ˆ2 å°æ—¶ï¼‰
  â”œâ”€ æ­¥éª¤ 5: è¿è¡Œç°æœ‰æµ‹è¯•ï¼ˆ30 åˆ†é’Ÿï¼‰
  â”œâ”€ æ­¥éª¤ 6: æ€§èƒ½æµ‹è¯•ï¼ˆ1 å°æ—¶ï¼‰
  â””â”€ æ­¥éª¤ 7: å¯é æ€§æµ‹è¯•ï¼ˆ30 åˆ†é’Ÿï¼‰

é˜¶æ®µ 3: æ–‡æ¡£æ›´æ–°ï¼ˆ1 å°æ—¶ï¼‰
  â”œâ”€ æ­¥éª¤ 8: æ›´æ–° READMEï¼ˆ30 åˆ†é’Ÿï¼‰
  â””â”€ æ­¥éª¤ 9: æ›´æ–°æ¶æ„æ–‡æ¡£ï¼ˆ30 åˆ†é’Ÿï¼‰
```

---

## ä»£ç ä¿®æ”¹æ¸…å•

### ğŸ“ **æ–‡ä»¶ä¿®æ”¹æ¸…å•**

#### 1. `jxt-core/sdk/pkg/eventbus/kafka.go`

**ä¿®æ”¹ç±»å‹**: é‡æ„ + åˆ é™¤

**ä¿®æ”¹å†…å®¹**ï¼ˆä»¥ç¬¦å·åä¸ºå‡†ï¼Œè¡Œå·ä»…ä¾›å‚è€ƒï¼‰:

| ç¬¦å·/æ–¹æ³•å | ä¿®æ”¹ç±»å‹ | è¯´æ˜ |
|-----------|---------|------|
| `WorkItem` ç»“æ„ä½“ | âŒ åˆ é™¤ | åˆ é™¤å…¨å±€ Worker Pool å·¥ä½œé¡¹å®šä¹‰ |
| `GlobalWorkerPool` ç»“æ„ä½“ | âŒ åˆ é™¤ | åˆ é™¤å…¨å±€ Worker Pool åŠæ‰€æœ‰æ–¹æ³• |
| `Worker` ç»“æ„ä½“ | âŒ åˆ é™¤ | åˆ é™¤ Worker åŠæ‰€æœ‰æ–¹æ³• |
| `NewGlobalWorkerPool()` | âŒ åˆ é™¤ | åˆ é™¤å…¨å±€ Worker Pool æ„é€ å‡½æ•° |
| `SubmitWork()` | âŒ åˆ é™¤ | åˆ é™¤å·¥ä½œæäº¤æ–¹æ³• |
| `processMessageDirectly()` | âŒ åˆ é™¤ | åˆ é™¤ç›´æ¥å¤„ç†æ¶ˆæ¯çš„åå¤‡æ–¹æ¡ˆ |
| `globalWorkerPool` å­—æ®µ | âŒ åˆ é™¤ | åˆ é™¤ kafkaEventBus ä¸­çš„å­—æ®µ |
| `globalWorkerPool` åˆå§‹åŒ– | âŒ åˆ é™¤ | åˆ é™¤ NewKafkaEventBus ä¸­çš„åˆå§‹åŒ–ä»£ç  |
| `globalWorkerPool.Close()` | âŒ åˆ é™¤ | åˆ é™¤ Close() ä¸­çš„æ¸…ç†ä»£ç  |
| `processMessageWithKeyedPool()` | âœï¸ ä¿®æ”¹ | ä¿®æ”¹è·¯ç”±é€»è¾‘ï¼Œç»Ÿä¸€ä½¿ç”¨ Hollywood Actor Pool |

**é¢„è®¡ä¿®æ”¹è¡Œæ•°**: ~50 è¡Œä¿®æ”¹ + 200+ è¡Œåˆ é™¤

**åˆ é™¤çš„æ ¸å¿ƒç¬¦å·**:
- `WorkItem` ç»“æ„ä½“ï¼ˆ~10 è¡Œï¼‰
- `GlobalWorkerPool` ç»“æ„ä½“åŠæ–¹æ³•ï¼ˆ~160 è¡Œï¼‰
- `Worker` ç»“æ„ä½“åŠæ–¹æ³•ï¼ˆ~45 è¡Œï¼‰
- `processMessageDirectly` æ–¹æ³•ï¼ˆ~20 è¡Œï¼‰
- åˆå§‹åŒ–å’Œæ¸…ç†ä»£ç ï¼ˆ~10 è¡Œï¼‰

---

#### 2. `jxt-core/sdk/pkg/eventbus/README.md`

**ä¿®æ”¹ç±»å‹**: æ›´æ–°

**ä¿®æ”¹å†…å®¹**:

| ç« èŠ‚ | ä¿®æ”¹ç±»å‹ | è¯´æ˜ |
|------|---------|------|
| æ¶æ„å›¾ | âœï¸ ä¿®æ”¹ | æ›´æ–°æ¶æ„å›¾ï¼Œç§»é™¤ Worker Pool |
| Subscribe() è¯´æ˜ | âœï¸ ä¿®æ”¹ | æ›´æ–°è¯´æ˜ï¼Œè¯´æ˜ç°åœ¨ä¹Ÿä½¿ç”¨ Actor Pool |
| æ€§èƒ½å¯¹æ¯” | âœï¸ ä¿®æ”¹ | æ›´æ–°æ€§èƒ½æ•°æ® |

**é¢„è®¡ä¿®æ”¹è¡Œæ•°**: ~50 è¡Œ

---

#### 3. `jxt-core/docs/kafka-subscribe-to-actor-pool-migration-summary.md`

**ä¿®æ”¹ç±»å‹**: æ–°å¢

**ä¿®æ”¹å†…å®¹**: åˆ›å»ºè¿ç§»æ€»ç»“æ–‡æ¡£

**é¢„è®¡è¡Œæ•°**: ~50 è¡Œ

---

### ğŸ” **ç»“æ„ä½“å­—æ®µå˜æ›´**

#### `kafkaEventBus` ç»“æ„ä½“

**åˆ é™¤å­—æ®µ**:
```go
type kafkaEventBus struct {
    // ... å…¶ä»–å­—æ®µ ...
    
    // âŒ åˆ é™¤ï¼šå…¨å±€ Worker Pool
    globalWorkerPool *GlobalWorkerPool
    
    // ... å…¶ä»–å­—æ®µ ...
}
```

**ä¿ç•™å­—æ®µ**:
```go
type kafkaEventBus struct {
    // ... å…¶ä»–å­—æ®µ ...

    // âœ… ä¿ç•™ï¼šå…¨å±€ Hollywood Actor Pool
    globalActorPool *HollywoodActorPool

    // ... å…¶ä»–å­—æ®µ ...
}
```

**æ–°å¢å­—æ®µ**:
```go
type kafkaEventBus struct {
    // ... å…¶ä»–å­—æ®µ ...

    // âœ… æ–°å¢ï¼šè½®è¯¢è®¡æ•°å™¨ï¼ˆç”¨äºæ— èšåˆIDæ¶ˆæ¯çš„è´Ÿè½½å‡è¡¡ï¼‰
    roundRobinCounter atomic.Uint64

    // ... å…¶ä»–å­—æ®µ ...
}
```

---

## è¯¦ç»†å®æ–½æ­¥éª¤

### æ­¥éª¤ 1: ä¿®æ”¹è·¯ç”±é€»è¾‘

**æ–‡ä»¶**: `jxt-core/sdk/pkg/eventbus/kafka.go`

**ä½ç½®**: Line 1154-1224ï¼ˆ`processMessageWithKeyedPool` æ–¹æ³•ï¼‰

**å½“å‰ä»£ç **:
```go
func (h *preSubscriptionConsumerHandler) processMessageWithKeyedPool(
    ctx context.Context,
    message *sarama.ConsumerMessage,
    handler MessageHandler,
    session sarama.ConsumerGroupSession,
) error {
    // è½¬æ¢ Headers ä¸º map
    headersMap := make(map[string]string, len(message.Headers))
    for _, header := range message.Headers {
        headersMap[string(header.Key)] = string(header.Value)
    }

    // å°è¯•æå–èšåˆIDï¼ˆä¼˜å…ˆçº§ï¼šEnvelope > Header > Kafka Keyï¼‰
    aggregateID, _ := ExtractAggregateID(message.Value, headersMap, message.Key, "")

    if aggregateID != "" {
        // æœ‰èšåˆIDï¼šä½¿ç”¨ Hollywood Actor Pool è¿›è¡Œé¡ºåºå¤„ç†
        pool := h.eventBus.globalActorPool
        if pool != nil {
            aggMsg := &AggregateMessage{
                Topic:       message.Topic,
                Partition:   message.Partition,
                Offset:      message.Offset,
                Key:         message.Key,
                Value:       message.Value,
                Headers:     make(map[string][]byte),
                Timestamp:   message.Timestamp,
                AggregateID: aggregateID,
                Context:     ctx,
                Done:        make(chan error, 1),
                Handler:     handler,
            }
            for _, header := range message.Headers {
                aggMsg.Headers[string(header.Key)] = header.Value
            }

            if err := pool.ProcessMessage(ctx, aggMsg); err != nil {
                return err
            }

            select {
            case err := <-aggMsg.Done:
                session.MarkMessage(message, "")
                return err
            case <-ctx.Done():
                return ctx.Err()
            }
        }
    }

    // æ— èšåˆIDï¼šä½¿ç”¨å…¨å±€Workeræ± å¤„ç†ï¼ˆè¿ç§»åå°†æ”¹ä¸ºä½¿ç”¨ Hollywood Actor Poolï¼‰
    workItem := WorkItem{
        Topic:   message.Topic,
        Message: message,
        Handler: handler,
        Session: session,
    }

    // æäº¤åˆ°å…¨å±€Workeræ± 
    if !h.eventBus.globalWorkerPool.SubmitWork(workItem) {
        h.eventBus.logger.Warn("Failed to submit work to global worker pool, using direct processing",
            zap.String("topic", message.Topic),
            zap.Int64("offset", message.Offset))
        // å¦‚æœWorkeræ± æ»¡äº†ï¼Œç›´æ¥åœ¨å½“å‰goroutineå¤„ç†
        h.processMessageDirectly(ctx, message, handler, session)
    }

    return nil
}
```

**ä¿®æ”¹åä»£ç **:
```go
func (h *preSubscriptionConsumerHandler) processMessageWithKeyedPool(
    ctx context.Context,
    message *sarama.ConsumerMessage,
    handler MessageHandler,
    session sarama.ConsumerGroupSession,
) error {
    // è½¬æ¢ Headers ä¸º map
    headersMap := make(map[string]string, len(message.Headers))
    for _, header := range message.Headers {
        headersMap[string(header.Key)] = string(header.Value)
    }

    // å°è¯•æå–èšåˆIDï¼ˆä¼˜å…ˆçº§ï¼šEnvelope > Header > Kafka Keyï¼‰
    aggregateID, _ := ExtractAggregateID(message.Value, headersMap, message.Key, "")

    // â­ æ ¸å¿ƒå˜æ›´ï¼šç»Ÿä¸€ä½¿ç”¨ Hollywood Actor Pool
    // è·¯ç”±ç­–ç•¥ï¼š
    // - æœ‰èšåˆIDï¼šä½¿ç”¨ aggregateID ä½œä¸ºè·¯ç”±é”®ï¼ˆä¿æŒæœ‰åºï¼‰
    // - æ— èšåˆIDï¼šä½¿ç”¨ Round-Robin è½®è¯¢ï¼ˆä¿æŒå¹¶å‘ï¼‰
    routingKey := aggregateID
    if routingKey == "" {
        // ä½¿ç”¨è½®è¯¢è®¡æ•°å™¨ç”Ÿæˆè·¯ç”±é”®
        index := h.eventBus.roundRobinCounter.Add(1)
        routingKey = fmt.Sprintf("rr-%d", index)
    }

    pool := h.eventBus.globalActorPool
    if pool == nil {
        return fmt.Errorf("hollywood actor pool not initialized")
    }

    aggMsg := &AggregateMessage{
        Topic:       message.Topic,
        Partition:   message.Partition,
        Offset:      message.Offset,
        Key:         message.Key,
        Value:       message.Value,
        Headers:     make(map[string][]byte),
        Timestamp:   message.Timestamp,
        AggregateID: routingKey,  // â­ ä½¿ç”¨ routingKeyï¼ˆå¯èƒ½æ˜¯ aggregateID æˆ– topicï¼‰
        Context:     ctx,
        Done:        make(chan error, 1),
        Handler:     handler,
    }
    for _, header := range message.Headers {
        aggMsg.Headers[string(header.Key)] = header.Value
    }

    if err := pool.ProcessMessage(ctx, aggMsg); err != nil {
        return err
    }

    select {
    case err := <-aggMsg.Done:
        session.MarkMessage(message, "")
        return err
    case <-ctx.Done():
        return ctx.Err()
    }
}
```

**å…³é”®å˜æ›´**:
1. âœ… åˆ é™¤ `if aggregateID != ""` åˆ†æ”¯åˆ¤æ–­
2. âœ… æ·»åŠ  `routingKey` é€»è¾‘ï¼šæœ‰èšåˆIDç”¨èšåˆIDï¼Œæ— èšåˆIDç”¨ topic
3. âœ… ç»Ÿä¸€ä½¿ç”¨ `globalActorPool.ProcessMessage()`
4. âœ… åˆ é™¤å…¨å±€ Worker Pool ç›¸å…³ä»£ç 

**é¢„è®¡ä¿®æ”¹è¡Œæ•°**: ~30 è¡Œï¼ˆåˆ é™¤ ~40 è¡Œï¼Œæ–°å¢ ~10 è¡Œï¼‰

---

### æ­¥éª¤ 2: åˆ é™¤ Worker Pool ä»£ç 

**æ–‡ä»¶**: `jxt-core/sdk/pkg/eventbus/kafka.go`

**ä½ç½®**: Line 33-218

**åˆ é™¤å†…å®¹**:

1. **GlobalWorkerPool ç»“æ„ä½“**ï¼ˆLine 33-44ï¼‰
2. **Worker ç»“æ„ä½“**ï¼ˆLine 46-52ï¼‰
3. **NewGlobalWorkerPool å‡½æ•°**ï¼ˆLine 54-76ï¼‰
4. **start æ–¹æ³•**ï¼ˆLine 78-102ï¼‰
5. **dispatcher æ–¹æ³•**ï¼ˆLine 104-134ï¼‰
6. **SubmitWork æ–¹æ³•**ï¼ˆLine 136-150ï¼‰
7. **Worker.start æ–¹æ³•**ï¼ˆLine 152-166ï¼‰
8. **Worker.processWork æ–¹æ³•**ï¼ˆLine 168-192ï¼‰
9. **GlobalWorkerPool.Close æ–¹æ³•**ï¼ˆLine 194-218ï¼‰

**é¢„è®¡åˆ é™¤è¡Œæ•°**: ~185 è¡Œ

---

### æ­¥éª¤ 3: åˆ é™¤ WorkItem ç»“æ„ä½“å’Œ processMessageDirectly æ–¹æ³•

**æ–‡ä»¶**: `jxt-core/sdk/pkg/eventbus/kafka.go`

**åˆ é™¤å†…å®¹**:

1. **WorkItem ç»“æ„ä½“**ï¼ˆæœç´¢ `type WorkItem struct`ï¼‰
   ```go
   // âŒ åˆ é™¤
   type WorkItem struct {
       Topic   string
       Message *sarama.ConsumerMessage
       Handler MessageHandler
       Session sarama.ConsumerGroupSession
   }
   ```

2. **processMessageDirectly æ–¹æ³•**ï¼ˆLine 1225-1245ï¼‰
   ```go
   // âŒ åˆ é™¤
   func (h *preSubscriptionConsumerHandler) processMessageDirectly(
       ctx context.Context,
       message *sarama.ConsumerMessage,
       handler MessageHandler,
       session sarama.ConsumerGroupSession,
   ) {
       // ... å®ç°ä»£ç  ...
   }
   ```

**é¢„è®¡åˆ é™¤è¡Œæ•°**: ~30 è¡Œ

---

### æ­¥éª¤ 4: æ¸…ç†åˆå§‹åŒ–å’Œå…³é—­é€»è¾‘

**æ–‡ä»¶**: `jxt-core/sdk/pkg/eventbus/kafka.go`

#### 4.1 åˆ é™¤åˆå§‹åŒ–ä»£ç 

**ä½ç½®**: Line 577-578

**å½“å‰ä»£ç **:
```go
// åˆ›å»ºå…¨å±€Workeræ± 
globalWorkerPool := NewGlobalWorkerPool(0, zap.NewNop()) // 0è¡¨ç¤ºä½¿ç”¨é»˜è®¤workeræ•°é‡
```

**ä¿®æ”¹**: âŒ åˆ é™¤è¿™ä¸¤è¡Œ

---

**ä½ç½®**: Line 592

**å½“å‰ä»£ç **:
```go
bus := &kafkaEventBus{
    config: cfg,
    logger: zap.NewNop(),
    
    // ...
    
    globalWorkerPool:       globalWorkerPool,  // âŒ åˆ é™¤è¿™ä¸€è¡Œ
    
    // ...
}
```

**ä¿®æ”¹**: âŒ åˆ é™¤ `globalWorkerPool` å­—æ®µèµ‹å€¼

---

#### 4.2 åˆ é™¤å…³é—­ä»£ç 

**ä½ç½®**: Line 1959-1961

**å½“å‰ä»£ç **:
```go
// åœæ­¢å…¨å±€Workeræ± 
if k.globalWorkerPool != nil {
    k.globalWorkerPool.Close()
}
```

**ä¿®æ”¹**: âŒ åˆ é™¤è¿™ä¸‰è¡Œ

---

**é¢„è®¡åˆ é™¤è¡Œæ•°**: ~10 è¡Œ

---

### æ­¥éª¤ 5: ä»£ç å®¡æŸ¥å’Œä¼˜åŒ–

**æ£€æŸ¥æ¸…å•**:

1. âœ… ç¡®è®¤æ‰€æœ‰ `globalWorkerPool` å¼•ç”¨å·²åˆ é™¤
2. âœ… ç¡®è®¤æ‰€æœ‰ `WorkItem` å¼•ç”¨å·²åˆ é™¤
3. âœ… ç¡®è®¤ `processMessageDirectly` å¼•ç”¨å·²åˆ é™¤
4. âœ… ç¡®è®¤è·¯ç”±é€»è¾‘æ­£ç¡®ï¼ˆæœ‰/æ— èšåˆIDï¼‰
5. âœ… ç¡®è®¤é”™è¯¯å¤„ç†å®Œæ•´
6. âœ… ç¡®è®¤æ—¥å¿—è®°å½•å®Œæ•´
7. âœ… è¿è¡Œ `go build` ç¡®è®¤ç¼–è¯‘é€šè¿‡
8. âœ… è¿è¡Œ `go vet` ç¡®è®¤æ— è­¦å‘Š
9. âœ… è¿è¡Œ `golangci-lint` ç¡®è®¤ä»£ç è´¨é‡

**å·¥å…·å‘½ä»¤**:
```bash
# ç¼–è¯‘æ£€æŸ¥
cd jxt-core/sdk/pkg/eventbus
go build

# é™æ€åˆ†æ
go vet ./...

# ä»£ç è´¨é‡æ£€æŸ¥ï¼ˆå¦‚æœå®‰è£…äº† golangci-lintï¼‰
golangci-lint run
```

---

## æµ‹è¯•éªŒè¯è®¡åˆ’

### ğŸ§ª **æµ‹è¯•é˜¶æ®µ**

#### é˜¶æ®µ 1: å•å…ƒæµ‹è¯•ï¼ˆ30 åˆ†é’Ÿï¼‰

**ç›®æ ‡**: éªŒè¯åŸºæœ¬åŠŸèƒ½æ­£å¸¸

**æµ‹è¯•ç”¨ä¾‹**:
1. âœ… `TestKafkaBasicPublishSubscribe` - åŸºæœ¬å‘å¸ƒè®¢é˜…
2. âœ… `TestKafkaMultipleMessages` - å¤šæ¶ˆæ¯æµ‹è¯•
3. âœ… `TestKafkaEnvelopePublishSubscribe` - Envelope å‘å¸ƒè®¢é˜…

**æ‰§è¡Œå‘½ä»¤**:
```bash
cd jxt-core/tests/eventbus/function_regression_tests
go test -v -run "TestKafka" -timeout 300s
```

**æˆåŠŸæ ‡å‡†**:
- âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡
- âœ… æ—  panic æˆ–é”™è¯¯
- âœ… æ¶ˆæ¯æ­£ç¡®æ¥æ”¶å’Œå¤„ç†

---

#### é˜¶æ®µ 2: æ€§èƒ½æµ‹è¯•ï¼ˆ1 å°æ—¶ï¼‰

**ç›®æ ‡**: éªŒè¯æ€§èƒ½ä¸ä½äºå½“å‰å®ç°

**æµ‹è¯•ç”¨ä¾‹**:
1. âœ… `TestMemoryVsPersistenceComparison` - å†…å­˜æŒä¹…åŒ–æ€§èƒ½å¯¹æ¯”
2. âœ… `TestKafkaVsNATSPerformanceComparison` - Kafka vs NATS æ€§èƒ½å¯¹æ¯”

**æ‰§è¡Œå‘½ä»¤**:
```bash
cd jxt-core/tests/eventbus/performance_regression_tests
go test -v -run "TestMemoryVsPersistenceComparison" -timeout 600s
go test -v -run "TestKafkaVsNATSPerformanceComparison" -timeout 600s
```

**æˆåŠŸæ ‡å‡†**:
- âœ… ååé‡ â‰¥ 5000 msg/sï¼ˆå• topicï¼‰
- âœ… ååé‡ â‰¥ 6000 msg/sï¼ˆå¤š topicï¼‰
- âœ… P50 å»¶è¿Ÿ â‰¤ 200 ms
- âœ… P99 å»¶è¿Ÿ â‰¤ 500 ms
- âœ… å†…å­˜å ç”¨ â‰¤ å½“å‰å®ç°çš„ 120%

---

#### é˜¶æ®µ 3: å¯é æ€§æµ‹è¯•ï¼ˆ30 åˆ†é’Ÿï¼‰

**ç›®æ ‡**: éªŒè¯æ•…éšœæ¢å¤æœºåˆ¶

**æµ‹è¯•ç”¨ä¾‹**:
1. âœ… Handler panic æ¢å¤æµ‹è¯•
2. âœ… Actor é‡å¯æµ‹è¯•
3. âœ… Inbox æ»¡è½½æµ‹è¯•

**æµ‹è¯•ä»£ç **ï¼ˆæ–°å¢ï¼‰:
```go
// TestKafkaActorPoolReliability æµ‹è¯• Actor Pool å¯é æ€§
func TestKafkaActorPoolReliability(t *testing.T) {
    helper := NewTestHelper(t)
    defer helper.Cleanup()
    
    topic := fmt.Sprintf("test.kafka.reliability.%d", helper.GetTimestamp())
    helper.CreateKafkaTopics([]string{topic}, 3)
    
    bus := helper.CreateKafkaEventBus(fmt.Sprintf("kafka-reliability-%d", helper.GetTimestamp()))
    defer helper.CloseEventBus(bus)
    
    ctx := context.Background()
    
    var received int64
    var panicCount int64
    
    // Handler ä¼šåœ¨å‰ 3 æ¬¡è°ƒç”¨æ—¶ panic
    err := bus.Subscribe(ctx, topic, func(ctx context.Context, message []byte) error {
        count := atomic.AddInt64(&received, 1)
        if count <= 3 {
            atomic.AddInt64(&panicCount, 1)
            panic("simulated panic")
        }
        return nil
    })
    helper.AssertNoError(err, "Subscribe should not return error")
    
    time.Sleep(2 * time.Second)
    
    // å‘é€ 10 æ¡æ¶ˆæ¯
    for i := 0; i < 10; i++ {
        err = bus.Publish(ctx, topic, []byte(fmt.Sprintf("message-%d", i)))
        helper.AssertNoError(err, "Publish should not return error")
    }
    
    time.Sleep(5 * time.Second)
    
    // éªŒè¯ï¼šå‰ 3 æ¬¡ panicï¼Œå 7 æ¬¡æˆåŠŸ
    helper.AssertEqual(int64(10), atomic.LoadInt64(&received), "Should receive all 10 messages")
    helper.AssertEqual(int64(3), atomic.LoadInt64(&panicCount), "Should panic 3 times")
    
    t.Logf("âœ… Actor Pool reliability test passed")
}
```

**æˆåŠŸæ ‡å‡†**:
- âœ… Handler panic å Actor è‡ªåŠ¨é‡å¯
- âœ… Actor é‡å¯åç»§ç»­å¤„ç†æ¶ˆæ¯
- âœ… é‡å¯æ¬¡æ•°ä¸è¶…è¿‡ maxRestartsï¼ˆ3æ¬¡ï¼‰
- âœ… Inbox æ»¡è½½æ—¶æ¶ˆæ¯é˜»å¡ï¼Œä¸ä¸¢å¤±

---

## å›æ»šæ–¹æ¡ˆ

### ğŸ”„ **å›æ»šè¯´æ˜**

**é¡¹ç›®æœªä¸Šç”Ÿäº§ç¯å¢ƒï¼Œå›æ»šé£é™©è¾ƒä½**

å¦‚éœ€å›æ»šï¼Œä½¿ç”¨ Git å›æ»šå³å¯ï¼š

```bash
# æŸ¥çœ‹æäº¤å†å²
git log --oneline

# å›æ»šåˆ°è¿ç§»å‰çš„æäº¤
git revert <commit-hash>

# æˆ–è€…ç¡¬å›æ»šï¼ˆè°¨æ…ä½¿ç”¨ï¼‰
git reset --hard <commit-hash>

# éªŒè¯å›æ»š
cd jxt-core/tests/eventbus/function_regression_tests
go test -v -run "TestKafka" -timeout 300s
```

**è¯´æ˜**: ç”±äºé¡¹ç›®æœªä¸Šç”Ÿäº§ç¯å¢ƒï¼Œæ— éœ€å¤æ‚çš„å›æ»šæµç¨‹ã€‚å¦‚æœè¿ç§»åå‘ç°é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨ Git å›æ»šå³å¯

---

## é™„å½•

### A. ä»£ç ä¿®æ”¹ Diff é¢„è§ˆ

```diff
--- a/jxt-core/sdk/pkg/eventbus/kafka.go
+++ b/jxt-core/sdk/pkg/eventbus/kafka.go
@@ -30,188 +30,0 @@
-// GlobalWorkerPool å…¨å±€Workeræ± 
-type GlobalWorkerPool struct {
-    workers     []*Worker
-    workQueue   chan WorkItem
-    workerCount int
-    queueSize   int
-    ctx         context.Context
-    cancel      context.CancelFunc
-    wg          sync.WaitGroup
-    logger      *zap.Logger
-    closed      atomic.Bool
-}
-
-// Worker å…¨å±€Worker
-type Worker struct {
-    id       int
-    pool     *GlobalWorkerPool
-    workChan chan WorkItem
-    quit     chan bool
-}
-
-// ... (åˆ é™¤æ‰€æœ‰ Worker Pool ç›¸å…³ä»£ç )
-
@@ -575,3 +387,0 @@
-    // åˆ›å»ºå…¨å±€Workeræ± 
-    globalWorkerPool := NewGlobalWorkerPool(0, zap.NewNop())
-
@@ -589,1 +388,0 @@
-        globalWorkerPool:       globalWorkerPool,
@@ -1151,74 +1149,45 @@
 func (h *preSubscriptionConsumerHandler) processMessageWithKeyedPool(
     ctx context.Context,
     message *sarama.ConsumerMessage,
     handler MessageHandler,
     session sarama.ConsumerGroupSession,
 ) error {
     // è½¬æ¢ Headers ä¸º map
     headersMap := make(map[string]string, len(message.Headers))
     for _, header := range message.Headers {
         headersMap[string(header.Key)] = string(header.Value)
     }
 
     // å°è¯•æå–èšåˆIDï¼ˆä¼˜å…ˆçº§ï¼šEnvelope > Header > Kafka Keyï¼‰
     aggregateID, _ := ExtractAggregateID(message.Value, headersMap, message.Key, "")
 
-    if aggregateID != "" {
-        // æœ‰èšåˆIDï¼šä½¿ç”¨ Hollywood Actor Pool è¿›è¡Œé¡ºåºå¤„ç†
-        pool := h.eventBus.globalActorPool
-        if pool != nil {
-            aggMsg := &AggregateMessage{
-                // ... (çœç•¥å­—æ®µ)
-            }
-            // ... (çœç•¥å¤„ç†é€»è¾‘)
-        }
+    // â­ æ ¸å¿ƒå˜æ›´ï¼šç»Ÿä¸€ä½¿ç”¨ Hollywood Actor Pool
+    routingKey := aggregateID
+    if routingKey == "" {
+        routingKey = message.Topic
     }
 
-    // æ— èšåˆIDï¼šä½¿ç”¨å…¨å±€Workeræ± å¤„ç†
-    workItem := WorkItem{
-        Topic:   message.Topic,
-        Message: message,
-        Handler: handler,
-        Session: session,
+    pool := h.eventBus.globalActorPool
+    if pool == nil {
+        return fmt.Errorf("hollywood actor pool not initialized")
     }
 
-    if !h.eventBus.globalWorkerPool.SubmitWork(workItem) {
-        h.eventBus.logger.Warn("Failed to submit work to global worker pool")
-        h.processMessageDirectly(ctx, message, handler, session)
+    aggMsg := &AggregateMessage{
+        Topic:       message.Topic,
+        Partition:   message.Partition,
+        Offset:      message.Offset,
+        Key:         message.Key,
+        Value:       message.Value,
+        Headers:     make(map[string][]byte),
+        Timestamp:   message.Timestamp,
+        AggregateID: routingKey,  // â­ ä½¿ç”¨ routingKey
+        Context:     ctx,
+        Done:        make(chan error, 1),
+        Handler:     handler,
     }
+    for _, header := range message.Headers {
+        aggMsg.Headers[string(header.Key)] = header.Value
+    }
+
+    if err := pool.ProcessMessage(ctx, aggMsg); err != nil {
+        return err
+    }
+
+    select {
+    case err := <-aggMsg.Done:
+        session.MarkMessage(message, "")
+        return err
+    case <-ctx.Done():
+        return ctx.Err()
+    }
-
-    return nil
 }
@@ -1956,4 +1925,0 @@
-    // åœæ­¢å…¨å±€Workeræ± 
-    if k.globalWorkerPool != nil {
-        k.globalWorkerPool.Close()
-    }
```

---

**æ–‡æ¡£çŠ¶æ€**: å¾…è¯„å®¡  
**ä¸‹ä¸€æ­¥**: ç­‰å¾…è¯„å®¡æ‰¹å‡†åï¼Œå¼€å§‹ä»£ç å®æ–½

