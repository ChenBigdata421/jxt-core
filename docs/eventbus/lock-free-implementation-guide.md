# EventBus å…é”ä¼˜åŒ–å®æ–½æŒ‡å—

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¥æœŸ**: 2025-09-30  
**çŠ¶æ€**: å®æ–½å‚è€ƒ

---

## ğŸ“‹ ç›®å½•

1. [å®æ–½å‰å‡†å¤‡](#1-å®æ–½å‰å‡†å¤‡)
2. [è¯¦ç»†ä»£ç æ”¹åŠ¨](#2-è¯¦ç»†ä»£ç æ”¹åŠ¨)
3. [è¿ç§»æ­¥éª¤](#3-è¿ç§»æ­¥éª¤)
4. [æµ‹è¯•éªŒè¯](#4-æµ‹è¯•éªŒè¯)
5. [æ€§èƒ½åŸºå‡†æµ‹è¯•](#5-æ€§èƒ½åŸºå‡†æµ‹è¯•)
6. [å¸¸è§é—®é¢˜](#6-å¸¸è§é—®é¢˜)

---

## 1. å®æ–½å‰å‡†å¤‡

### 1.1 ä¾èµ–æ£€æŸ¥

```bash
# ç¡®ä¿ Go ç‰ˆæœ¬ >= 1.19ï¼ˆæ”¯æŒ atomic åŒ…çš„æ³›å‹ï¼‰
go version

# å®‰è£… LRU ç¼“å­˜åº“
go get github.com/hashicorp/golang-lru/v2

# å®‰è£…é™æµå™¨
go get golang.org/x/time/rate
```

### 1.2 å¤‡ä»½å½“å‰ä»£ç 

```bash
# åˆ›å»ºåˆ†æ”¯
git checkout -b feature/lock-free-optimization

# å¤‡ä»½å…³é”®æ–‡ä»¶
cp jxt-core/sdk/pkg/eventbus/kafka.go jxt-core/sdk/pkg/eventbus/kafka.go.backup
cp jxt-core/sdk/pkg/eventbus/nats.go jxt-core/sdk/pkg/eventbus/nats.go.backup
```

---

## 2. è¯¦ç»†ä»£ç æ”¹åŠ¨

### 2.1 ä¼˜åŒ–åŸåˆ™ â­

**æ ¸å¿ƒåŸåˆ™**: **åªä¼˜åŒ–é«˜é¢‘è·¯å¾„ï¼Œä½é¢‘è·¯å¾„ä¿ç•™é”**

#### ğŸ”¥ é«˜é¢‘è·¯å¾„ï¼ˆéœ€è¦ä¼˜åŒ–ï¼‰
- `Publish` / `PublishEnvelope` - æ¯ç§’æ•°åƒ-æ•°ä¸‡æ¬¡
- `ConsumeClaim` (handleræŸ¥æ‰¾) - æ¯æ¡æ¶ˆæ¯
- `GetTopicConfig` - æ¯æ¬¡å‘å¸ƒ/è®¢é˜…

#### âœ… ä½é¢‘è·¯å¾„ï¼ˆä¿ç•™é”ï¼‰
- `Subscribe` / `SubscribeEnvelope` - å¯åŠ¨æ—¶ä¸€æ¬¡
- `Close` - å…³é—­æ—¶ä¸€æ¬¡
- `ConfigureTopic` - åˆå§‹åŒ–æ—¶

### 2.2 Kafka EventBus ç»“æ„ä½“æ”¹åŠ¨

#### æ”¹åŠ¨ 1: é«˜é¢‘è·¯å¾„ - è®¢é˜…æ˜ å°„æŸ¥æ‰¾

**æ–‡ä»¶**: `jxt-core/sdk/pkg/eventbus/kafka.go`

**å½“å‰ä»£ç ** (çº¦ L50-L60):
```go
type kafkaEventBus struct {
    config *config.KafkaConfig

    // ğŸ”´ ä½é¢‘è·¯å¾„ï¼šä¿ç•™ muï¼ˆç”¨äº Subscribeã€Close ç­‰ä½é¢‘æ“ä½œï¼‰
    mu            sync.Mutex

    producer      sarama.SyncProducer
    consumerGroup sarama.ConsumerGroup
    admin         sarama.ClusterAdmin
    client        sarama.Client

    // ğŸ”¥ é«˜é¢‘è·¯å¾„ï¼šéœ€è¦ä¼˜åŒ–
    subscriptionsMu sync.Mutex
    subscriptions   map[string]MessageHandler

    topicConfigMu sync.RWMutex
    topicConfigs  map[string]TopicOptions

    // ...
}
```

**ä¿®æ”¹ä¸º**:
```go
type kafkaEventBus struct {
    config *config.KafkaConfig

    // âœ… ä½é¢‘è·¯å¾„ï¼šä¿ç•™ muï¼ˆç”¨äº Subscribeã€Close ç­‰ä½é¢‘æ“ä½œï¼‰
    mu     sync.Mutex
    closed atomic.Bool // ğŸ”¥ P0ä¿®å¤ï¼šæ”¹ä¸º atomic.Boolï¼Œçƒ­è·¯å¾„æ— é”è¯»å–

    // ğŸ”¥ é«˜é¢‘è·¯å¾„ï¼šæ”¹ä¸º atomic.Valueï¼ˆå‘å¸ƒæ—¶æ— é”è¯»å–ï¼‰
    asyncProducer        atomic.Value // stores sarama.AsyncProducer
    consumer             atomic.Value // stores sarama.Consumer
    client               atomic.Value // stores sarama.Client
    admin                atomic.Value // stores sarama.ClusterAdmin
    unifiedConsumerGroup atomic.Value // stores sarama.ConsumerGroup

    // ğŸ”¥ é«˜é¢‘è·¯å¾„ï¼šæ”¹ä¸º sync.Mapï¼ˆæ¶ˆæ¯å¤„ç†æ—¶æ— é”æŸ¥æ‰¾ï¼‰
    subscriptions sync.Map // key: string (topic), value: MessageHandler

    // ğŸ”¥ é«˜é¢‘è·¯å¾„ï¼šæ”¹ä¸º sync.Mapï¼ˆå‘å¸ƒæ—¶æ— é”è¯»å–é…ç½®ï¼‰
    topicConfigs sync.Map // key: string (topic), value: TopicOptions

    // ğŸ”¥ P0ä¿®å¤ï¼šé¢„è®¢é˜…æ¨¡å¼ - ä½¿ç”¨ atomic.Value å­˜å‚¨ä¸å¯å˜åˆ‡ç‰‡å¿«ç…§
    allPossibleTopicsMu sync.Mutex   // ä¿æŠ¤å†™å…¥
    allPossibleTopics   []string     // ä¸»å‰¯æœ¬ï¼ˆä»…åœ¨æŒæœ‰é”æ—¶ä¿®æ”¹ï¼‰
    topicsSnapshot      atomic.Value // åªè¯»å¿«ç…§ï¼ˆ[]stringï¼‰ï¼Œæ¶ˆè´¹goroutineæ— é”è¯»å–

    // ğŸ”¥ é«˜é¢‘è·¯å¾„ï¼šæ”¹ä¸º sync.Mapï¼ˆæ¶ˆæ¯è·¯ç”±æ—¶æ— é”æŸ¥æ‰¾ï¼‰
    activeTopicHandlers sync.Map // key: string (topic), value: MessageHandler

    // âœ… å·²ä¼˜åŒ–ï¼šåŸå­æ“ä½œ
    isConnected  atomic.Bool
    publishCount atomic.Int64
    consumeCount atomic.Int64
    errorCount   atomic.Int64

    globalWorkerPool *GlobalWorkerPool
    ctx              context.Context
    cancel           context.CancelFunc
    wg               sync.WaitGroup
}
```

**å…³é”®å˜åŒ–**:
- ğŸ”¥ **P0ä¿®å¤1**: `closed` æ”¹ä¸º `atomic.Bool`ï¼Œçƒ­è·¯å¾„ï¼ˆPublish/PublishEnvelopeï¼‰æ— é”è¯»å–
- ğŸ”¥ **P0ä¿®å¤2**: `allPossibleTopics` ä½¿ç”¨ `atomic.Value` å­˜å‚¨ä¸å¯å˜å¿«ç…§ï¼Œæ¶ˆè´¹goroutineæ— é”è¯»å–ï¼Œæ¶ˆé™¤æ•°æ®ç«æ€
- ğŸ”¥ **P0ä¿®å¤3**: `activeTopicHandlers` æ”¹ä¸º `sync.Map`ï¼Œæ¶ˆæ¯è·¯ç”±æ—¶æ— é”æŸ¥æ‰¾
- ğŸ”¥ **é«˜é¢‘è·¯å¾„**: `subscriptions`ã€`topicConfigs`ã€`asyncProducer` ç­‰æ”¹ä¸ºæ— é”æ•°æ®ç»“æ„
- âœ… **ä½é¢‘è·¯å¾„**: `mu` ä¿ç•™ï¼Œç”¨äº `Subscribe`ã€`Close` ç­‰ä½é¢‘æ“ä½œ
- âœ… **ä»£ç æ¸…æ™°**: ä½é¢‘æ“ä½œä»ä½¿ç”¨é”ï¼Œä¸šåŠ¡é€»è¾‘æ¸…æ™°æ˜“æ‡‚

---

### 2.3 åˆå§‹åŒ–å‡½æ•°æ”¹åŠ¨

**æ–‡ä»¶**: `jxt-core/sdk/pkg/eventbus/kafka.go`

**å½“å‰ä»£ç ** (çº¦ L150-L200):
```go
func NewKafkaEventBus(cfg *config.KafkaConfig) (EventBus, error) {
    // ...

    bus := &kafkaEventBus{
        config:        cfg,
        subscriptions: make(map[string]MessageHandler),
        keyedPools:    make(map[string]*KeyedWorkerPool),
        topicConfigs:  make(map[string]TopicOptions),
    }

    // åˆå§‹åŒ–ç”Ÿäº§è€…
    bus.producer = producer
    bus.consumerGroup = consumerGroup
    bus.admin = admin
    bus.client = client

    // ...
}
```

**ä¿®æ”¹ä¸º**:
```go
func NewKafkaEventBus(cfg *config.KafkaConfig) (EventBus, error) {
    // ...

    bus := &kafkaEventBus{
        config: cfg,
        // subscriptions, topicConfigs, activeTopicHandlers ä¸éœ€è¦åˆå§‹åŒ–ï¼ˆsync.Map é›¶å€¼å¯ç”¨ï¼‰

        // ğŸ”¥ P0ä¿®å¤ï¼šåˆå§‹åŒ–é¢„è®¢é˜…å¿«ç…§
        allPossibleTopics: make([]string, 0),
    }

    // ğŸ”¥ P0ä¿®å¤ï¼šåˆå§‹åŒ– closed çŠ¶æ€
    bus.closed.Store(false)

    // ğŸ”¥ P0ä¿®å¤ï¼šåˆå§‹åŒ– topicsSnapshot
    bus.topicsSnapshot.Store([]string{})

    // âœ… ä½¿ç”¨ atomic.Value å­˜å‚¨
    bus.asyncProducer.Store(asyncProducer)
    bus.consumer.Store(consumer)
    bus.admin.Store(admin)
    bus.client.Store(client)
    bus.unifiedConsumerGroup.Store(unifiedConsumerGroup)

    // ...
}
```

### 2.4 è®¢é˜…å‡½æ•°æ”¹åŠ¨ï¼ˆâœ… ä½é¢‘è·¯å¾„ - ä¿ç•™é”ï¼‰

**å½“å‰ä»£ç ** (çº¦ L450-L480):
```go
func (k *kafkaEventBus) Subscribe(ctx context.Context, topic string, handler MessageHandler) error {
    k.subscriptionsMu.Lock()
    defer k.subscriptionsMu.Unlock()

    if _, exists := k.subscriptions[topic]; exists {
        return fmt.Errorf("already subscribed to topic: %s", topic)
    }

    k.subscriptions[topic] = handler

    // ...
}
```

**ä¿®æ”¹ä¸º**:
```go
func (k *kafkaEventBus) Subscribe(ctx context.Context, topic string, handler MessageHandler) error {
    k.mu.Lock() // âœ… ä¿ç•™é” - è®¢é˜…æ˜¯ä½é¢‘æ“ä½œ
    defer k.mu.Unlock()

    // ğŸ”¥ P0ä¿®å¤ï¼šä½¿ç”¨ atomic.Bool è¯»å–å…³é—­çŠ¶æ€
    if k.closed.Load() {
        return fmt.Errorf("eventbus is closed")
    }

    // âœ… ä½¿ç”¨ LoadOrStore åŸå­æ€§æ£€æŸ¥å¹¶å­˜å‚¨
    if _, loaded := k.subscriptions.LoadOrStore(topic, handler); loaded {
        return fmt.Errorf("already subscribed to topic: %s", topic)
    }

    // ğŸ”¥ P0ä¿®å¤ï¼šæ›´æ–°é¢„è®¢é˜…å¿«ç…§ï¼ˆå¦‚æœä½¿ç”¨é¢„è®¢é˜…æ¨¡å¼ï¼‰
    k.addTopicToPreSubscription(topic)

    // ... å…¶ä»–è®¢é˜…é€»è¾‘ï¼ˆä¿æŒä¸å˜ï¼‰
}

// ğŸ”¥ P0ä¿®å¤ï¼šæ·»åŠ topicåˆ°é¢„è®¢é˜…åˆ—è¡¨ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰
func (k *kafkaEventBus) addTopicToPreSubscription(topic string) {
    k.allPossibleTopicsMu.Lock()
    defer k.allPossibleTopicsMu.Unlock()

    // æ£€æŸ¥é‡å¤
    for _, existingTopic := range k.allPossibleTopics {
        if existingTopic == topic {
            return
        }
    }

    // åˆ›å»ºæ–°çš„ä¸å¯å˜å‰¯æœ¬
    newTopics := make([]string, len(k.allPossibleTopics)+1)
    copy(newTopics, k.allPossibleTopics)
    newTopics[len(k.allPossibleTopics)] = topic

    // æ›´æ–°ä¸»å‰¯æœ¬å’Œå¿«ç…§
    k.allPossibleTopics = newTopics
    k.topicsSnapshot.Store(newTopics)
}
```

### 2.5 å‘å¸ƒå‡½æ•°æ”¹åŠ¨ï¼ˆğŸ”¥ é«˜é¢‘è·¯å¾„ - å…é”ï¼‰

**å½“å‰ä»£ç ** (çº¦ L400-L450):
```go
func (k *kafkaEventBus) Publish(ctx context.Context, topic string, data []byte) error {
    k.mu.Lock()
    defer k.mu.Unlock()
    
    if k.isClosed.Load() {
        return fmt.Errorf("kafka eventbus is closed")
    }
    
    if k.producer == nil {
        return fmt.Errorf("kafka producer not initialized")
    }
    
    // ...
    _, _, err := k.producer.SendMessage(msg)
    // ...
}
```

**ä¿®æ”¹ä¸º**:
```go
func (k *kafkaEventBus) Publish(ctx context.Context, topic string, data []byte) error {
    // ğŸ”¥ P0ä¿®å¤ï¼šæ— é”æ£€æŸ¥å…³é—­çŠ¶æ€
    if k.closed.Load() {
        return fmt.Errorf("kafka eventbus is closed")
    }

    // âœ… æ— é”è¯»å–ç”Ÿäº§è€…ï¼ˆä½¿ç”¨ helper æ–¹æ³•ï¼‰
    producer, err := k.getAsyncProducer()
    if err != nil {
        return fmt.Errorf("failed to get async producer: %w", err)
    }

    // ...
    // å‘é€åˆ° AsyncProducer çš„ Input channel
    select {
    case producer.Input() <- msg:
        return nil
    case <-time.After(100 * time.Millisecond):
        // åº”ç”¨èƒŒå‹
        producer.Input() <- msg
        return nil
    }
}

// Helper æ–¹æ³•ï¼šæ— é”è¯»å– AsyncProducer
func (k *kafkaEventBus) getAsyncProducer() (sarama.AsyncProducer, error) {
    producerAny := k.asyncProducer.Load()
    if producerAny == nil {
        return nil, fmt.Errorf("async producer not initialized")
    }
    producer, ok := producerAny.(sarama.AsyncProducer)
    if !ok {
        return nil, fmt.Errorf("invalid async producer type")
    }
    return producer, nil
}
```

### 2.5 æ¶ˆè´¹å‡½æ•°æ”¹åŠ¨

**å½“å‰ä»£ç ** (çº¦ L550-L600):
```go
func (k *kafkaEventBus) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error {
    for message := range claim.Messages() {
        k.subscriptionsMu.Lock()
        handler, exists := k.subscriptions[message.Topic]
        k.subscriptionsMu.Unlock()
        
        if !exists {
            session.MarkMessage(message, "")
            continue
        }
        
        // å¤„ç†æ¶ˆæ¯
        if err := handler(session.Context(), message.Value); err != nil {
            logger.Error("Failed to handle message", zap.Error(err))
        }
        
        session.MarkMessage(message, "")
    }
    return nil
}
```

**ä¿®æ”¹ä¸º**:
```go
// ğŸ”¥ é¢„è®¢é˜…æ¨¡å¼çš„æ¶ˆè´¹å¤„ç†å™¨
type preSubscriptionConsumerHandler struct {
    eventBus *kafkaEventBus
}

func (h *preSubscriptionConsumerHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error {
    for {
        select {
        case message := <-claim.Messages():
            if message == nil {
                return nil
            }

            // ğŸ”¥ P0ä¿®å¤ï¼šæ— é”è¯»å– handlerï¼ˆä½¿ç”¨ sync.Mapï¼‰
            handlerAny, exists := h.eventBus.activeTopicHandlers.Load(message.Topic)
            if !exists {
                // æœªæ¿€æ´»çš„ topicï¼Œè·³è¿‡
                session.MarkMessage(message, "")
                continue
            }
            handler := handlerAny.(MessageHandler)

            // å¤„ç†æ¶ˆæ¯
            if err := h.eventBus.processMessage(session.Context(), message, handler); err != nil {
                h.eventBus.logger.Error("Failed to process message",
                    zap.String("topic", message.Topic),
                    zap.Error(err))
            } else {
                h.eventBus.consumedMessages.Add(1)
                session.MarkMessage(message, "")
            }

        case <-session.Context().Done():
            return nil
        }
    }
}
```

// ğŸ”¥ P0ä¿®å¤ï¼šé¢„è®¢é˜…æ¶ˆè´¹è€…å¯åŠ¨ï¼ˆæ— é”è¯»å– topicsSnapshotï¼‰
func (k *kafkaEventBus) startPreSubscriptionConsumer(ctx context.Context) error {
    k.consumerMu.Lock()
    defer k.consumerMu.Unlock()

    if k.consumerStarted {
        return nil
    }

    consumerGroup, err := k.getUnifiedConsumerGroup()
    if err != nil {
        return fmt.Errorf("failed to get unified consumer group: %w", err)
    }

    handler := &preSubscriptionConsumerHandler{eventBus: k}

    go func() {
        defer close(k.consumerDone)

        for {
            if k.consumerCtx.Err() != nil {
                return
            }

            // ğŸ”¥ P0ä¿®å¤ï¼šæ— é”è¯»å– topicsSnapshot
            topics := k.topicsSnapshot.Load().([]string)

            if len(topics) == 0 {
                <-k.consumerCtx.Done()
                return
            }

            // âœ… å®‰å…¨ï¼štopics æ˜¯ä¸å¯å˜å‰¯æœ¬ï¼Œä¸ä¼šè¢«ä¿®æ”¹
            err = consumerGroup.Consume(k.consumerCtx, topics, handler)
            if err != nil {
                if k.consumerCtx.Err() != nil {
                    return
                }
                k.logger.Error("Pre-subscription consumer error, will retry", zap.Error(err))
                time.Sleep(2 * time.Second)
                continue
            }

            k.logger.Info("Pre-subscription consumer session ended, restarting...")
        }
    }()

    k.consumerStarted = true
    return nil
}
    }
    
    select {
    case processor.messages <- aggMsg:
        // Message sent successfully
    case <-time.After(5 * time.Second):
        logger.Warn("Timeout sending message to processor", zap.String("aggregateID", aggregateID))
    case <-ctx.Done():
        logger.Warn("Context cancelled", zap.String("aggregateID", aggregateID))
    }
}
```

### 2.6 æ¢å¤æ¨¡å¼ç›¸å…³å‡½æ•°

**æ–°å¢å‡½æ•°**:
```go
// SetRecoveryMode è®¾ç½®æ¢å¤æ¨¡å¼
func (k *kafkaEventBus) SetRecoveryMode(isRecovery bool) {
    k.isRecoveryMode.Store(isRecovery)
    if isRecovery {
        logger.Info("Entering recovery mode: messages will be processed in order by aggregate ID")
    } else {
        logger.Info("Exiting recovery mode: gradually transitioning to normal processing")
    }
}

// IsInRecoveryMode æ£€æŸ¥æ˜¯å¦åœ¨æ¢å¤æ¨¡å¼
func (k *kafkaEventBus) IsInRecoveryMode() bool {
    return k.isRecoveryMode.Load()
}

// getOrCreateAggregateProcessor è·å–æˆ–åˆ›å»ºèšåˆå¤„ç†å™¨
func (k *kafkaEventBus) getOrCreateAggregateProcessor(ctx context.Context, aggregateID string, handler MessageHandler) (*aggregateProcessor, error) {
    // ä»ç¼“å­˜ä¸­è·å–
    if proc, exists := k.aggregateProcessors.Get(aggregateID); exists {
        return proc, nil
    }
    
    // åªåœ¨æ¢å¤æ¨¡å¼ä¸‹åˆ›å»ºæ–°çš„å¤„ç†å™¨
    if !k.IsInRecoveryMode() {
        return nil, fmt.Errorf("not in recovery mode, cannot create new processor")
    }
    
    // åˆ›å»ºæ–°çš„å¤„ç†å™¨
    proc := &aggregateProcessor{
        aggregateID: aggregateID,
        messages:    make(chan *AggregateMessage, 100),
        done:        make(chan struct{}),
    }
    proc.lastActivity.Store(time.Now())
    
    // æ·»åŠ åˆ°ç¼“å­˜
    k.aggregateProcessors.Add(aggregateID, proc)
    
    // å¯åŠ¨å¤„ç†å™¨
    k.wg.Add(1)
    go k.runAggregateProcessor(ctx, proc, handler)
    
    return proc, nil
}

// runAggregateProcessor è¿è¡Œèšåˆå¤„ç†å™¨
func (k *kafkaEventBus) runAggregateProcessor(ctx context.Context, proc *aggregateProcessor, handler MessageHandler) {
    defer k.wg.Done()
    defer k.releaseAggregateProcessor(proc)
    
    idleTimeout := 5 * time.Minute
    
    for {
        select {
        case msg, ok := <-proc.messages:
            if !ok {
                return
            }
            
            // å¤„ç†æ¶ˆæ¯
            if err := handler(msg.Context, msg.Value); err != nil {
                logger.Error("Failed to handle message in processor", 
                    zap.String("aggregateID", proc.aggregateID),
                    zap.Error(err))
                k.errorCount.Add(1)
            } else {
                k.consumeCount.Add(1)
            }
            
            proc.lastActivity.Store(time.Now())
            
        case <-time.After(idleTimeout):
            lastActivity := proc.lastActivity.Load().(time.Time)
            if time.Since(lastActivity) > idleTimeout {
                logger.Info("Processor idle, shutting down", 
                    zap.String("aggregateID", proc.aggregateID))
                return
            }
            
        case <-proc.done:
            return
            
        case <-ctx.Done():
            return
        }
    }
}

// releaseAggregateProcessor é‡Šæ”¾èšåˆå¤„ç†å™¨
func (k *kafkaEventBus) releaseAggregateProcessor(proc *aggregateProcessor) {
    k.aggregateProcessors.Remove(proc.aggregateID)
    close(proc.messages)
    close(proc.done)
}

// extractAggregateID ä»æ¶ˆæ¯ä¸­æå–èšåˆID
func extractAggregateID(msg *sarama.ConsumerMessage) string {
    // ä»æ¶ˆæ¯å¤´ä¸­æå–
    for _, header := range msg.Headers {
        if string(header.Key) == "aggregateID" {
            return string(header.Value)
        }
    }
    
    // æˆ–è€…ä»æ¶ˆæ¯é”®ä¸­æå–
    if len(msg.Key) > 0 {
        return string(msg.Key)
    }
    
    return ""
}
```

---

## 3. è¿ç§»æ­¥éª¤

### æ­¥éª¤ 1: æ›´æ–°ç»“æ„ä½“å®šä¹‰

1. ä¿®æ”¹ `kafkaEventBus` ç»“æ„ä½“
2. æ·»åŠ  `aggregateProcessor` ç»“æ„ä½“
3. æ·»åŠ  `AggregateMessage` ç»“æ„ä½“

### æ­¥éª¤ 2: æ›´æ–°åˆå§‹åŒ–å‡½æ•°

1. ä¿®æ”¹ `NewKafkaEventBus` å‡½æ•°
2. ä½¿ç”¨ `atomic.Value.Store()` åˆå§‹åŒ–å¯¹è±¡
3. åˆå§‹åŒ– LRU ç¼“å­˜å’Œé™æµå™¨

### æ­¥éª¤ 3: æ›´æ–°è®¢é˜…/å‘å¸ƒå‡½æ•°

1. ä¿®æ”¹ `Subscribe` å‡½æ•°ä½¿ç”¨ `sync.Map`
2. ä¿®æ”¹ `Publish` å‡½æ•°ä½¿ç”¨ `atomic.Value`
3. ä¿®æ”¹ `ConsumeClaim` å‡½æ•°ä½¿ç”¨ `sync.Map`

### æ­¥éª¤ 4: æ·»åŠ æ¢å¤æ¨¡å¼æ”¯æŒ

1. æ·»åŠ  `SetRecoveryMode` å‡½æ•°
2. æ·»åŠ  `IsInRecoveryMode` å‡½æ•°
3. æ·»åŠ  `processMessage` å‡½æ•°
4. æ·»åŠ èšåˆå¤„ç†å™¨ç›¸å…³å‡½æ•°

### æ­¥éª¤ 5: æ›´æ–°å…¶ä»–å‡½æ•°

1. ä¿®æ”¹ `Close` å‡½æ•°
2. ä¿®æ”¹ `GetTopicConfig` å‡½æ•°
3. ä¿®æ”¹ `ConfigureTopic` å‡½æ•°

---

## 4. æµ‹è¯•éªŒè¯

### 4.1 å•å…ƒæµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
cd jxt-core/sdk/pkg/eventbus
go test -v -timeout=2m

# è¿è¡Œå¹¶å‘æµ‹è¯•
go test -v -race -timeout=2m

# è¿è¡Œç‰¹å®šæµ‹è¯•
go test -v -run="TestKafka.*" -timeout=2m
```

### 4.2 é›†æˆæµ‹è¯•

```bash
# è¿è¡Œé›†æˆæµ‹è¯•
go test -v -run=".*Integration" -timeout=5m

# è¿è¡Œ Kafka é›†æˆæµ‹è¯•
go test -v -run="TestKafka.*Integration" -timeout=5m
```

### 4.3 å¹¶å‘å®‰å…¨æµ‹è¯•

```bash
# ä½¿ç”¨ race detector
go test -race -v -timeout=5m

# å‹åŠ›æµ‹è¯•
go test -v -run="TestKafka.*Concurrent" -timeout=10m
```

---

## 5. æ€§èƒ½åŸºå‡†æµ‹è¯•

### 5.1 åŸºå‡†æµ‹è¯•ä»£ç 

åˆ›å»ºæ–‡ä»¶ `jxt-core/sdk/pkg/eventbus/kafka_benchmark_test.go`:

```go
package eventbus

import (
    "context"
    "testing"
)

func BenchmarkSubscriptionLookup(b *testing.B) {
    bus := setupKafkaBus(b)
    defer bus.Close()
    
    topic := "test-topic"
    handler := func(ctx context.Context, data []byte) error {
        return nil
    }
    
    bus.Subscribe(context.Background(), topic, handler)
    
    b.ResetTimer()
    b.RunParallel(func(pb *testing.PB) {
        for pb.Next() {
            // æ¨¡æ‹Ÿè®¢é˜…æŸ¥æ‰¾
            handlerAny, _ := bus.(*kafkaEventBus).subscriptions.Load(topic)
            _ = handlerAny.(MessageHandler)
        }
    })
}

func BenchmarkPublish(b *testing.B) {
    bus := setupKafkaBus(b)
    defer bus.Close()
    
    topic := "test-topic"
    data := []byte("test message")
    ctx := context.Background()
    
    b.ResetTimer()
    b.RunParallel(func(pb *testing.PB) {
        for pb.Next() {
            bus.Publish(ctx, topic, data)
        }
    })
}
```

### 5.2 è¿è¡ŒåŸºå‡†æµ‹è¯•

```bash
# è¿è¡ŒåŸºå‡†æµ‹è¯•
go test -bench=. -benchmem -benchtime=10s

# å¯¹æ¯”ä¼˜åŒ–å‰å
go test -bench=BenchmarkSubscriptionLookup -benchmem -count=5 > old.txt
# åº”ç”¨ä¼˜åŒ–
go test -bench=BenchmarkSubscriptionLookup -benchmem -count=5 > new.txt
benchstat old.txt new.txt
```

---

## 6. å¸¸è§é—®é¢˜

### Q1: sync.Map ä»€ä¹ˆæ—¶å€™æ€§èƒ½ä¼šé€€åŒ–ï¼Ÿ

**A**: å½“å†™æ“ä½œé¢‘ç¹æ—¶ï¼Œ`sync.Map` æ€§èƒ½å¯èƒ½ä¸å¦‚ `RWMutex + map`ã€‚å»ºè®®ï¼š
- è¯»å¤šå†™å°‘åœºæ™¯ä½¿ç”¨ `sync.Map`
- å†™å¤šåœºæ™¯å›é€€åˆ° `RWMutex + map`

### Q2: atomic.Value ç±»å‹æ–­è¨€å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

**A**: æ·»åŠ ç±»å‹æ£€æŸ¥å’Œ panic recoveryï¼š

```go
func (k *kafkaEventBus) getProducer() (sarama.SyncProducer, error) {
    producerAny := k.producer.Load()
    if producerAny == nil {
        return nil, fmt.Errorf("producer not initialized")
    }
    
    producer, ok := producerAny.(sarama.SyncProducer)
    if !ok {
        return nil, fmt.Errorf("invalid producer type")
    }
    
    return producer, nil
}
```

### Q3: å¦‚ä½•ç›‘æ§é”ç«äº‰ï¼Ÿ

**A**: ä½¿ç”¨ pprofï¼š

```bash
# å¯ç”¨ mutex profiling
go test -mutexprofile=mutex.out

# æŸ¥çœ‹é”ç«äº‰
go tool pprof mutex.out
```

### Q4: æ¢å¤æ¨¡å¼ä½•æ—¶åˆ‡æ¢ï¼Ÿ

**A**: å»ºè®®ç­–ç•¥ï¼š
- å¯åŠ¨æ—¶è¿›å…¥æ¢å¤æ¨¡å¼
- æ£€æµ‹åˆ°æ— ç§¯å‹ååˆ‡æ¢åˆ°æ™®é€šæ¨¡å¼
- å¯é…ç½®åˆ‡æ¢é˜ˆå€¼

---

## 5. NATS EventBus å…é”ä¼˜åŒ–å®æ–½æŒ‡å—

### 5.1 å®æ–½æ¦‚è§ˆ

NATS EventBus çš„å…é”ä¼˜åŒ–éµå¾ªä¸ Kafka ç›¸åŒçš„åŸåˆ™å’Œæ¨¡å¼ï¼Œä¸»è¦ä¼˜åŒ–ç‚¹åŒ…æ‹¬ï¼š

- **P0 ä¼˜åŒ–**: `closed`ã€`topicHandlers`ã€`conn/js`
- **P1 ä¼˜åŒ–**: `topicConfigs`ã€`createdStreams` + å•é£æŠ‘åˆ¶

### 5.2 P0 ä¼˜åŒ–å®æ–½æ­¥éª¤

#### æ­¥éª¤ 1: ä¿®æ”¹ç»“æ„ä½“å®šä¹‰

**æ–‡ä»¶**: `jxt-core/sdk/pkg/eventbus/nats.go`

**ä¿®æ”¹å‰** (Line 204-220):
```go
type natsEventBus struct {
    conn               *nats.Conn
    js                 nats.JetStreamContext
    config             *NATSConfig
    subscriptions      map[string]*nats.Subscription
    logger             *zap.Logger
    mu                 sync.RWMutex
    closed             bool
    reconnectCallbacks []func(ctx context.Context) error

    unifiedConsumer    nats.ConsumerInfo
    topicHandlers      map[string]MessageHandler
    topicHandlersMu    sync.RWMutex
    // ...
}
```

**ä¿®æ”¹å**:
```go
type natsEventBus struct {
    // ğŸ”¥ P0ä¿®å¤ï¼šæ”¹ä¸º atomic.Valueï¼ˆå‘å¸ƒæ—¶æ— é”è¯»å–ï¼‰
    conn atomic.Value // stores *nats.Conn
    js   atomic.Value // stores nats.JetStreamContext

    config        *NATSConfig
    subscriptions map[string]*nats.Subscription
    logger        *zap.Logger

    // âœ… ä½é¢‘è·¯å¾„ï¼šä¿ç•™ muï¼ˆç”¨äº Subscribeã€Close ç­‰ä½é¢‘æ“ä½œï¼‰
    mu     sync.Mutex  // ğŸ”¥ æ”¹ä¸º Mutexï¼ˆä¸å†éœ€è¦è¯»å†™é”ï¼‰
    closed atomic.Bool // ğŸ”¥ P0ä¿®å¤ï¼šæ”¹ä¸º atomic.Boolï¼Œçƒ­è·¯å¾„æ— é”è¯»å–

    reconnectCallbacks []func(ctx context.Context) error

    unifiedConsumer nats.ConsumerInfo

    // ğŸ”¥ P0ä¿®å¤ï¼šæ”¹ä¸º sync.Mapï¼ˆæ¶ˆæ¯è·¯ç”±æ—¶æ— é”æŸ¥æ‰¾ï¼‰
    topicHandlers sync.Map // key: string (topic), value: MessageHandler
    // ...
}
```

#### æ­¥éª¤ 2: ä¿®æ”¹åˆå§‹åŒ–é€»è¾‘

**æ–‡ä»¶**: `jxt-core/sdk/pkg/eventbus/nats.go`

**NewNATSEventBus å‡½æ•°**:
```go
func NewNATSEventBus(config *NATSConfig) (EventBus, error) {
    // ... è¿æ¥åˆå§‹åŒ–

    bus := &natsEventBus{
        config: config,
        // ...
    }

    // ğŸ”¥ P0ä¿®å¤ï¼šä½¿ç”¨ atomic.Value å­˜å‚¨
    bus.conn.Store(nc)
    bus.js.Store(js)
    bus.closed.Store(false)

    // ...
    return bus, nil
}
```

#### æ­¥éª¤ 3: æ·»åŠ  Helper æ–¹æ³•

**æ–‡ä»¶**: `jxt-core/sdk/pkg/eventbus/nats.go`

```go
// getConn æ— é”è¯»å– NATS Connection
func (n *natsEventBus) getConn() (*nats.Conn, error) {
    connAny := n.conn.Load()
    if connAny == nil {
        return nil, fmt.Errorf("nats connection not initialized")
    }
    conn, ok := connAny.(*nats.Conn)
    if !ok {
        return nil, fmt.Errorf("invalid nats connection type")
    }
    return conn, nil
}

// getJetStreamContext æ— é”è¯»å– JetStream Context
func (n *natsEventBus) getJetStreamContext() (nats.JetStreamContext, error) {
    jsAny := n.js.Load()
    if jsAny == nil {
        return nil, fmt.Errorf("jetstream context not initialized")
    }
    js, ok := jsAny.(nats.JetStreamContext)
    if !ok {
        return nil, fmt.Errorf("invalid jetstream context type")
    }
    return js, nil
}
```

#### æ­¥éª¤ 4: ä¿®æ”¹é«˜é¢‘è·¯å¾„æ–¹æ³•

**Publish æ–¹æ³•**:
```go
func (n *natsEventBus) Publish(ctx context.Context, topic string, message []byte) error {
    // ğŸ”¥ P0ä¿®å¤ï¼šæ— é”æ£€æŸ¥å…³é—­çŠ¶æ€
    if n.closed.Load() {
        return fmt.Errorf("eventbus is closed")
    }

    // ğŸ”¥ P0ä¿®å¤ï¼šæ— é”è¯»å– JetStream Context
    js, err := n.getJetStreamContext()
    if err != nil {
        return err
    }

    // ... å‘å¸ƒé€»è¾‘
}
```

**processUnifiedPullMessages æ–¹æ³•**:
```go
func (n *natsEventBus) processUnifiedPullMessages(ctx context.Context, topic string, sub *nats.Subscription) {
    for {
        msgs, err := sub.Fetch(batchSize, nats.MaxWait(fetchTimeout))
        // ...

        for _, msg := range msgs {
            // ğŸ”¥ P0ä¿®å¤ï¼šæ— é”è¯»å– handlerï¼ˆä½¿ç”¨ sync.Mapï¼‰
            handlerAny, exists := n.topicHandlers.Load(topic)
            if !exists {
                n.logger.Warn("No handler found for topic", zap.String("topic", topic))
                msg.Ack()
                continue
            }
            handler := handlerAny.(MessageHandler)

            n.handleMessage(ctx, topic, msg.Data, handler, func() error {
                return msg.Ack()
            })
        }
    }
}
```

#### æ­¥éª¤ 5: ä¿®æ”¹ä½é¢‘è·¯å¾„æ–¹æ³•

**Close æ–¹æ³•**:
```go
func (n *natsEventBus) Close() error {
    n.mu.Lock() // ä¿ç•™é” - å…³é—­æ˜¯ä½é¢‘æ“ä½œ
    defer n.mu.Unlock()

    // ğŸ”¥ P0ä¿®å¤ï¼šä½¿ç”¨ atomic.Bool è®¾ç½®å…³é—­çŠ¶æ€
    if n.closed.Load() {
        return nil
    }
    n.closed.Store(true)

    // è·å–è¿æ¥å¯¹è±¡
    conn, err := n.getConn()
    if err != nil {
        return err
    }

    // ... å…¶ä»–å…³é—­é€»è¾‘
    conn.Drain()
    conn.Close()

    return nil
}
```

**Subscribe æ–¹æ³•**:
```go
func (n *natsEventBus) subscribeJetStream(ctx context.Context, topic string, handler MessageHandler) error {
    // ğŸ”¥ P0ä¿®å¤ï¼šä½¿ç”¨ sync.Map å­˜å‚¨ handler
    n.topicHandlers.Store(topic, handler)

    // ... å…¶ä»–è®¢é˜…é€»è¾‘
}
```

### 5.3 P1 ä¼˜åŒ–å®æ–½æ­¥éª¤

#### æ­¥éª¤ 1: æ·»åŠ å•é£æŠ‘åˆ¶

**ä¿®æ”¹ç»“æ„ä½“**:
```go
import "golang.org/x/sync/singleflight"

type natsEventBus struct {
    // ...

    // ğŸ”¥ P1ä¼˜åŒ–ï¼šæ”¹ä¸º sync.Mapï¼ˆå‘å¸ƒæ—¶æ— é”è¯»å–ï¼‰
    createdStreams sync.Map // key: string (streamName), value: bool

    // ğŸ”¥ P1ä¼˜åŒ–ï¼šå•é£æŠ‘åˆ¶ï¼ˆé¿å…å¹¶å‘åˆ›å»ºé£æš´ï¼‰
    streamCreateSF singleflight.Group

    // ...
}
```

#### æ­¥éª¤ 2: å®ç° ensureStream æ–¹æ³•

```go
// ensureStream ç¡®ä¿ Stream å­˜åœ¨ï¼ˆå¸¦å•é£æŠ‘åˆ¶ï¼‰
func (n *natsEventBus) ensureStream(topic string, cfg TopicOptions) error {
    streamName := n.getStreamNameForTopic(topic)

    // ğŸ”¥ P1ä¼˜åŒ–ï¼šå¿«é€Ÿè·¯å¾„ - æ— é”æ£€æŸ¥æœ¬åœ°ç¼“å­˜
    if _, ok := n.createdStreams.Load(streamName); ok {
        return nil
    }

    // ğŸ”¥ P1ä¼˜åŒ–ï¼šå•é£æŠ‘åˆ¶ - åŒä¸€ stream åªåˆ›å»ºä¸€æ¬¡
    _, err, _ := n.streamCreateSF.Do(streamName, func() (any, error) {
        // Double-checkï¼šå¯èƒ½å…¶ä»– goroutine å·²ç»åˆ›å»ºæˆåŠŸ
        if _, ok := n.createdStreams.Load(streamName); ok {
            return nil, nil
        }

        // å®é™…åˆ›å»º Stream
        if err := n.ensureTopicInJetStream(topic, cfg); err != nil {
            return nil, err
        }

        // ğŸ”¥ æˆåŠŸåæ·»åŠ åˆ°æœ¬åœ°ç¼“å­˜
        n.createdStreams.Store(streamName, true)
        return nil, nil
    })

    return err
}
```

### 5.4 æµ‹è¯•éªŒè¯

#### å¹¶å‘æµ‹è¯•
```bash
# è¿è¡Œå¹¶å‘æµ‹è¯•ï¼ˆæ£€æµ‹æ•°æ®ç«æ€ï¼‰
cd jxt-core/tests/eventbus/performance_tests
go test -race -v -run TestKafkaVsNATSPerformanceComparison -timeout=30m
go test -race -v -run TestMemoryPersistenceComparison -timeout=30m
```

#### æ€§èƒ½æµ‹è¯•
```bash
# è¿è¡Œæ€§èƒ½æµ‹è¯•
cd jxt-core/tests/eventbus/performance_tests
go test -v -run TestKafkaVsNATSPerformanceComparison -timeout=30m
go test -v -run TestMemoryPersistenceComparison -timeout=30m
```

#### åç¨‹æ³„æ¼æ£€æµ‹
```bash
# ä½¿ç”¨ pprof æ£€æµ‹åç¨‹æ³„æ¼
go test -v -run TestMemoryPersistenceComparison -timeout=30m -memprofile=mem.prof -cpuprofile=cpu.prof

# æŸ¥çœ‹åç¨‹æ•°
go tool pprof -http=:8080 mem.prof
```

### 5.5 é¢„æœŸç»“æœ

ä¼˜åŒ–å®Œæˆåï¼ŒNATS EventBus åº”è¾¾åˆ°ä»¥ä¸‹æ€§èƒ½æŒ‡æ ‡ï¼š

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡å¹…åº¦ |
|------|--------|--------|---------|
| **ååé‡** | 2861 msg/s | 3500-4000 msg/s | **+22-40%** |
| **P99 å»¶è¿Ÿ** | 32 ms | 22-26 ms | **-20-30%** |
| **Handler æŸ¥æ‰¾** | 100 ä¸‡æ¬¡/ç§’ | 300-500 ä¸‡æ¬¡/ç§’ | **3-5x** |
| **é”ç«äº‰** | 30% | 5-10% | **-70%** |
| **åç¨‹æ³„æ¼** | 1-12 ä¸ª | 0 ä¸ª | **-100%** |

---

**æ–‡æ¡£ç»“æŸ**


