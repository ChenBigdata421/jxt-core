package performance_tests

import (
	"context"
	"fmt"
	"testing"
	"time"

	"github.com/ChenBigdata421/jxt-core/sdk/pkg/eventbus"
	"github.com/stretchr/testify/require"
)

// TestNATSPublishEnvelopeProfiler è¯¦ç»†åˆ†æ PublishEnvelope çš„æ€§èƒ½ç“¶é¢ˆ
func TestNATSPublishEnvelopeProfiler(t *testing.T) {
	// åˆ›å»º NATS EventBus
	config := &eventbus.EventBusConfig{
		Type: "nats",
		NATS: eventbus.NATSConfig{
			URLs:     []string{"nats://localhost:4222"},
			ClientID: "profiler-test",
			JetStream: eventbus.JetStreamConfig{
				Enabled: true,
				Stream: eventbus.StreamConfig{
					Name:     "PROFILER_STREAM",
					Subjects: []string{"profiler.*"},
					Storage:  "file",
					Replicas: 1,
				},
				Consumer: eventbus.NATSConsumerConfig{
					DurableName:  "profiler-consumer",
					AckPolicy:    "explicit",
					ReplayPolicy: "instant",
				},
			},
		},
	}

	bus, err := eventbus.NewEventBus(config)
	require.NoError(t, err)
	defer bus.Close()

	ctx := context.Background()
	topic := "profiler.test"

	// é¢„çƒ­ï¼ˆé¿å…é¦–æ¬¡è°ƒç”¨çš„åˆå§‹åŒ–å¼€é”€ï¼‰
	t.Log("ğŸ”¥ é¢„çƒ­é˜¶æ®µ...")
	for i := 0; i < 100; i++ {
		envelope := eventbus.NewEnvelopeWithAutoID(
			fmt.Sprintf("warmup-%d", i),
			"WarmupEvent",
			1,
			[]byte("warmup"),
		)
		_ = bus.PublishEnvelope(ctx, topic, envelope)
	}
	time.Sleep(1 * time.Second)

	// æµ‹è¯•é˜¶æ®µï¼šè¯¦ç»†è®¡æ—¶
	t.Log("ğŸ“Š å¼€å§‹æ€§èƒ½åˆ†æ...")
	messageCount := 1000

	// åˆ†æ®µè®¡æ—¶
	type Timing struct {
		Total     time.Duration
		Validate  time.Duration
		Serialize time.Duration
		Publish   time.Duration
		Other     time.Duration
	}

	timings := make([]Timing, messageCount)

	for i := 0; i < messageCount; i++ {
		envelope := eventbus.NewEnvelopeWithAutoID(
			fmt.Sprintf("agg-%d", i%100),
			"TestEvent",
			int64(i/100+1),
			[]byte(fmt.Sprintf("message %d", i)),
		)

		// æ€»æ—¶é—´
		totalStart := time.Now()

		// 1. æ ¡éªŒæ—¶é—´
		validateStart := time.Now()
		err := envelope.Validate()
		validateDuration := time.Since(validateStart)
		require.NoError(t, err)

		// 2. åºåˆ—åŒ–æ—¶é—´
		serializeStart := time.Now()
		_, err = envelope.ToBytes()
		serializeDuration := time.Since(serializeStart)
		require.NoError(t, err)

		// 3. å‘å¸ƒæ—¶é—´ï¼ˆåŒ…å«æ‰€æœ‰ PublishEnvelope çš„å¼€é”€ï¼‰
		publishStart := time.Now()
		err = bus.PublishEnvelope(ctx, topic, envelope)
		publishDuration := time.Since(publishStart)
		require.NoError(t, err)

		totalDuration := time.Since(totalStart)

		timings[i] = Timing{
			Total:     totalDuration,
			Validate:  validateDuration,
			Serialize: serializeDuration,
			Publish:   publishDuration,
			Other:     totalDuration - validateDuration - serializeDuration - publishDuration,
		}
	}

	// ç»Ÿè®¡åˆ†æ
	var (
		totalSum     int64
		validateSum  int64
		serializeSum int64
		publishSum   int64
		otherSum     int64
	)

	for _, timing := range timings {
		totalSum += timing.Total.Microseconds()
		validateSum += timing.Validate.Microseconds()
		serializeSum += timing.Serialize.Microseconds()
		publishSum += timing.Publish.Microseconds()
		otherSum += timing.Other.Microseconds()
	}

	avgTotal := float64(totalSum) / float64(messageCount) / 1000.0         // ms
	avgValidate := float64(validateSum) / float64(messageCount) / 1000.0   // ms
	avgSerialize := float64(serializeSum) / float64(messageCount) / 1000.0 // ms
	avgPublish := float64(publishSum) / float64(messageCount) / 1000.0     // ms
	avgOther := float64(otherSum) / float64(messageCount) / 1000.0         // ms

	// è¾“å‡ºç»“æœ
	t.Log("================================================================================")
	t.Log("ğŸ“Š NATS PublishEnvelope æ€§èƒ½åˆ†ææŠ¥å‘Š")
	t.Log("================================================================================")
	t.Logf("æ¶ˆæ¯æ•°é‡: %d", messageCount)
	t.Log("")
	t.Log("â±ï¸  å¹³å‡è€—æ—¶åˆ†è§£:")
	t.Logf("   æ€»è€—æ—¶:        %.3f ms (100.00%%)", avgTotal)
	t.Logf("   â”œâ”€ Validate:   %.3f ms (%.2f%%)", avgValidate, avgValidate/avgTotal*100)
	t.Logf("   â”œâ”€ Serialize:  %.3f ms (%.2f%%)", avgSerialize, avgSerialize/avgTotal*100)
	t.Logf("   â”œâ”€ Publish:    %.3f ms (%.2f%%)", avgPublish, avgPublish/avgTotal*100)
	t.Logf("   â””â”€ Other:      %.3f ms (%.2f%%)", avgOther, avgOther/avgTotal*100)
	t.Log("")

	// ç™¾åˆ†ä½æ•°åˆ†æ
	type Percentile struct {
		P50 time.Duration
		P90 time.Duration
		P95 time.Duration
		P99 time.Duration
		Max time.Duration
	}

	calculatePercentile := func(durations []time.Duration) Percentile {
		// ç®€å•æ’åº
		sorted := make([]time.Duration, len(durations))
		copy(sorted, durations)
		for i := 0; i < len(sorted); i++ {
			for j := i + 1; j < len(sorted); j++ {
				if sorted[i] > sorted[j] {
					sorted[i], sorted[j] = sorted[j], sorted[i]
				}
			}
		}

		return Percentile{
			P50: sorted[len(sorted)*50/100],
			P90: sorted[len(sorted)*90/100],
			P95: sorted[len(sorted)*95/100],
			P99: sorted[len(sorted)*99/100],
			Max: sorted[len(sorted)-1],
		}
	}

	// æå–å„é˜¶æ®µçš„è€—æ—¶
	totalDurations := make([]time.Duration, messageCount)
	publishDurations := make([]time.Duration, messageCount)
	for i := 0; i < messageCount; i++ {
		totalDurations[i] = timings[i].Total
		publishDurations[i] = timings[i].Publish
	}

	totalPercentile := calculatePercentile(totalDurations)
	publishPercentile := calculatePercentile(publishDurations)

	t.Log("ğŸ“ˆ ç™¾åˆ†ä½æ•°åˆ†æ (æ€»è€—æ—¶):")
	t.Logf("   P50:  %.3f ms", float64(totalPercentile.P50.Microseconds())/1000.0)
	t.Logf("   P90:  %.3f ms", float64(totalPercentile.P90.Microseconds())/1000.0)
	t.Logf("   P95:  %.3f ms", float64(totalPercentile.P95.Microseconds())/1000.0)
	t.Logf("   P99:  %.3f ms", float64(totalPercentile.P99.Microseconds())/1000.0)
	t.Logf("   Max:  %.3f ms", float64(totalPercentile.Max.Microseconds())/1000.0)
	t.Log("")

	t.Log("ğŸ“ˆ ç™¾åˆ†ä½æ•°åˆ†æ (Publish è€—æ—¶):")
	t.Logf("   P50:  %.3f ms", float64(publishPercentile.P50.Microseconds())/1000.0)
	t.Logf("   P90:  %.3f ms", float64(publishPercentile.P90.Microseconds())/1000.0)
	t.Logf("   P95:  %.3f ms", float64(publishPercentile.P95.Microseconds())/1000.0)
	t.Logf("   P99:  %.3f ms", float64(publishPercentile.P99.Microseconds())/1000.0)
	t.Logf("   Max:  %.3f ms", float64(publishPercentile.Max.Microseconds())/1000.0)
	t.Log("")

	// ç“¶é¢ˆåˆ†æ
	t.Log("ğŸ” ç“¶é¢ˆåˆ†æ:")
	maxComponent := "Publish"
	maxValue := avgPublish
	if avgValidate > maxValue {
		maxComponent = "Validate"
		maxValue = avgValidate
	}
	if avgSerialize > maxValue {
		maxComponent = "Serialize"
		maxValue = avgSerialize
	}
	if avgOther > maxValue {
		maxComponent = "Other"
		maxValue = avgOther
	}

	t.Logf("   æœ€å¤§ç“¶é¢ˆ: %s (%.3f ms, %.2f%%)", maxComponent, maxValue, maxValue/avgTotal*100)
	t.Log("")

	// ä¼˜åŒ–å»ºè®®
	t.Log("ğŸ’¡ ä¼˜åŒ–å»ºè®®:")
	if avgValidate > 0.1 {
		t.Log("   âš ï¸  Validate è€—æ—¶è¾ƒé«˜ï¼Œè€ƒè™‘ç¼“å­˜æ ¡éªŒç»“æœæˆ–ç®€åŒ–æ ¡éªŒé€»è¾‘")
	}
	if avgSerialize > 0.5 {
		t.Log("   âš ï¸  Serialize è€—æ—¶è¾ƒé«˜ï¼Œè€ƒè™‘ä½¿ç”¨æ›´å¿«çš„åºåˆ—åŒ–åº“ï¼ˆå¦‚ msgpackï¼‰")
	}
	if avgPublish > 1.0 {
		t.Log("   âš ï¸  Publish è€—æ—¶è¾ƒé«˜ï¼Œå¯èƒ½æ˜¯ NATS SDK çš„ PublishMsgAsync å¼€é”€")
		t.Log("       å»ºè®®æ£€æŸ¥:")
		t.Log("       - NATS æœåŠ¡å™¨æ˜¯å¦åœ¨æœ¬åœ°ï¼ˆå‡å°‘ç½‘ç»œå»¶è¿Ÿï¼‰")
		t.Log("       - PublishAsyncMaxPending é…ç½®æ˜¯å¦åˆç†")
		t.Log("       - æ˜¯å¦æœ‰ç½‘ç»œæ‹¥å¡æˆ–æœåŠ¡å™¨è´Ÿè½½è¿‡é«˜")
	}
	t.Log("================================================================================")

	// ç­‰å¾…æ¶ˆæ¯å¤„ç†å®Œæˆ
	time.Sleep(2 * time.Second)
}

// TestKafkaPublishEnvelopeProfiler Kafka å¯¹æ¯”æµ‹è¯•
func TestKafkaPublishEnvelopeProfiler(t *testing.T) {
	// åˆ›å»º Kafka EventBus
	config := &eventbus.EventBusConfig{
		Type: "kafka",
		Kafka: eventbus.KafkaConfig{
			Brokers:  []string{"localhost:29092"},
			ClientID: "kafka-profiler-test",
			Producer: eventbus.ProducerConfig{
				RequiredAcks:   1,
				FlushFrequency: 500 * time.Millisecond,
				FlushMessages:  100,
				RetryMax:       3,
				// æ³¨æ„ï¼šå‹ç¼©é…ç½®å·²ä» Producer çº§åˆ«ç§»åˆ° Topic çº§åˆ«ï¼Œé€šè¿‡ TopicBuilder é…ç½®
				Timeout: 10 * time.Second,
			},
			Consumer: eventbus.ConsumerConfig{
				GroupID:         "kafka-profiler-group",
				AutoOffsetReset: "earliest",
			},
		},
	}

	bus, err := eventbus.NewEventBus(config)
	require.NoError(t, err)
	defer bus.Close()

	ctx := context.Background()
	topic := "kafka-profiler-test"

	// é¢„çƒ­
	t.Log("ğŸ”¥ é¢„çƒ­é˜¶æ®µ...")
	for i := 0; i < 100; i++ {
		envelope := eventbus.NewEnvelopeWithAutoID(
			fmt.Sprintf("warmup-%d", i),
			"WarmupEvent",
			1,
			[]byte("warmup"),
		)
		_ = bus.PublishEnvelope(ctx, topic, envelope)
	}
	time.Sleep(1 * time.Second)

	// æµ‹è¯•é˜¶æ®µ
	t.Log("ğŸ“Š å¼€å§‹æ€§èƒ½åˆ†æ...")
	messageCount := 1000
	publishDurations := make([]time.Duration, messageCount)

	for i := 0; i < messageCount; i++ {
		envelope := eventbus.NewEnvelopeWithAutoID(
			fmt.Sprintf("agg-%d", i%100),
			"TestEvent",
			int64(i/100+1),
			[]byte(fmt.Sprintf("message %d", i)),
		)

		publishStart := time.Now()
		err = bus.PublishEnvelope(ctx, topic, envelope)
		publishDurations[i] = time.Since(publishStart)
		require.NoError(t, err)
	}

	// ç»Ÿè®¡
	var publishSum int64
	for _, d := range publishDurations {
		publishSum += d.Microseconds()
	}
	avgPublish := float64(publishSum) / float64(messageCount) / 1000.0 // ms

	t.Log("================================================================================")
	t.Log("ğŸ“Š Kafka PublishEnvelope æ€§èƒ½åˆ†ææŠ¥å‘Š")
	t.Log("================================================================================")
	t.Logf("æ¶ˆæ¯æ•°é‡: %d", messageCount)
	t.Logf("å¹³å‡ Publish è€—æ—¶: %.3f ms", avgPublish)
	t.Log("================================================================================")

	time.Sleep(2 * time.Second)
}
