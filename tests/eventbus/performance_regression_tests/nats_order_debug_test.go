package performance_tests

import (
	"context"
	"fmt"
	"strings"
	"sync"
	"sync/atomic"
	"testing"
	"time"

	"github.com/ChenBigdata421/jxt-core/sdk/pkg/eventbus"
	"github.com/ChenBigdata421/jxt-core/sdk/pkg/logger"
	"github.com/stretchr/testify/require"
	"go.uber.org/zap"
)

// TestNATSOrderDebug è°ƒè¯• NATS é¡ºåºè¿åé—®é¢˜
func TestNATSOrderDebug(t *testing.T) {
	// åˆå§‹åŒ– logger
	if logger.DefaultLogger == nil {
		zapLogger, err := zap.NewDevelopment()
		if err != nil {
			t.Fatalf("Failed to initialize logger: %v", err)
		}
		logger.Logger = zapLogger
		logger.DefaultLogger = zapLogger.Sugar()
	}

	t.Log("ğŸ” ===== NATS é¡ºåºè¿åè°ƒè¯•æµ‹è¯• =====")

	// åˆ›å»º NATS EventBus
	timestamp := time.Now().Unix()
	streamName := fmt.Sprintf("DEBUG_%d", timestamp)
	subjectPattern := fmt.Sprintf("debug.%d.>", timestamp)

	natsConfig := &eventbus.NATSConfig{
		URLs:                []string{"nats://localhost:4223"},
		ClientID:            fmt.Sprintf("nats-debug-%d", timestamp),
		MaxReconnects:       10,
		ReconnectWait:       1 * time.Second,
		ConnectionTimeout:   30 * time.Second,
		HealthCheckInterval: 60 * time.Second,
		JetStream: eventbus.JetStreamConfig{
			Enabled:        true,
			PublishTimeout: 10 * time.Second,
			AckWait:        15 * time.Second,
			MaxDeliver:     3,
			Stream: eventbus.StreamConfig{
				Name:      streamName,
				Subjects:  []string{subjectPattern},
				Storage:   "file",
				Retention: "limits",
				MaxAge:    1 * time.Hour,
				MaxBytes:  1024 * 1024 * 1024,
				MaxMsgs:   100000,
				Replicas:  1,
				Discard:   "old",
			},
			Consumer: eventbus.NATSConsumerConfig{
				DurableName:   fmt.Sprintf("debug_%d", timestamp),
				DeliverPolicy: "all",
				AckPolicy:     "explicit",
				ReplayPolicy:  "instant",
				MaxAckPending: 1000,
				MaxWaiting:    500,
				MaxDeliver:    3,
			},
		},
	}

	eb, err := eventbus.NewNATSEventBus(natsConfig)
	require.NoError(t, err, "Failed to create NATS EventBus")
	defer eb.Close()

	// ç­‰å¾…è¿æ¥å»ºç«‹
	time.Sleep(2 * time.Second)

	// æµ‹è¯•å‚æ•° - æ¨¡æ‹Ÿæ€§èƒ½æµ‹è¯•çš„ä½å‹åœºæ™¯
	aggregateCount := 100     // 100 ä¸ªèšåˆ
	messagesPerAggregate := 5 // æ¯ä¸ªèšåˆ 5 æ¡æ¶ˆæ¯ï¼ˆæ€»å…± 500 æ¡ï¼‰
	totalMessages := aggregateCount * messagesPerAggregate

	// ğŸ”‘ ä½¿ç”¨ 5 ä¸ª topicsï¼ˆä¸æ€§èƒ½æµ‹è¯•ä¸€è‡´ï¼‰
	topicCount := 5
	topics := make([]string, topicCount)
	for i := 0; i < topicCount; i++ {
		topics[i] = fmt.Sprintf("debug.%d.topic%d", timestamp, i+1)
	}

	t.Logf("ğŸ“Š æµ‹è¯•å‚æ•°:")
	t.Logf("   èšåˆæ•°é‡: %d", aggregateCount)
	t.Logf("   æ¯ä¸ªèšåˆæ¶ˆæ¯æ•°: %d", messagesPerAggregate)
	t.Logf("   æ€»æ¶ˆæ¯æ•°: %d", totalMessages)
	t.Logf("   Topic æ•°é‡: %d", topicCount)
	t.Logf("   Topics: %v", topics)

	// æ¥æ”¶æ¶ˆæ¯ç»Ÿè®¡
	type ReceivedMessage struct {
		AggregateID  string
		EventVersion int64
		ReceivedAt   time.Time
		ReceivedSeq  int64
	}

	var receivedMessages []ReceivedMessage
	var receivedMu sync.Mutex
	var receivedCount int64
	var orderViolations int64

	// æ¯ä¸ªèšåˆçš„æœ€åæ¥æ”¶ç‰ˆæœ¬
	lastVersions := make(map[string]int64)
	var lastVersionsMu sync.Mutex

	// è®¢é˜…æ¶ˆæ¯
	ctx, cancel := context.WithTimeout(context.Background(), 60*time.Second)
	defer cancel()

	handler := func(ctx context.Context, env *eventbus.Envelope) error {
		seq := atomic.AddInt64(&receivedCount, 1)

		receivedMu.Lock()
		receivedMessages = append(receivedMessages, ReceivedMessage{
			AggregateID:  env.AggregateID,
			EventVersion: env.EventVersion,
			ReceivedAt:   time.Now(),
			ReceivedSeq:  seq,
		})
		receivedMu.Unlock()

		// æ£€æŸ¥é¡ºåº
		lastVersionsMu.Lock()
		lastVersion, exists := lastVersions[env.AggregateID]
		if exists && env.EventVersion <= lastVersion {
			atomic.AddInt64(&orderViolations, 1)
			t.Logf("âŒ é¡ºåºè¿å: AggregateID=%s, LastVersion=%d, CurrentVersion=%d, ReceivedSeq=%d",
				env.AggregateID, lastVersion, env.EventVersion, seq)
		}
		lastVersions[env.AggregateID] = env.EventVersion
		lastVersionsMu.Unlock()

		return nil
	}

	// è®¢é˜…æ‰€æœ‰ topics
	for _, topic := range topics {
		err = eb.SubscribeEnvelope(ctx, topic, handler)
		require.NoError(t, err, "Failed to subscribe to topic: "+topic)
	}

	// ç­‰å¾…è®¢é˜…ç”Ÿæ•ˆ
	time.Sleep(2 * time.Second)

	// å‘é€æ¶ˆæ¯
	t.Log("ğŸ“¤ å¼€å§‹å‘é€æ¶ˆæ¯...")
	sendStart := time.Now()

	aggregateIDs := make([]string, aggregateCount)
	for i := 0; i < aggregateCount; i++ {
		aggregateIDs[i] = fmt.Sprintf("agg-%d", i)
	}

	// ä¸ºæ¯ä¸ªèšåˆIDåˆ›å»ºä¸€ä¸ª goroutine ä¸²è¡Œå‘é€æ¶ˆæ¯
	// ğŸ”‘ å…³é”®ï¼šåŒä¸€ä¸ªèšåˆIDçš„æ‰€æœ‰æ¶ˆæ¯éƒ½å‘é€åˆ°åŒä¸€ä¸ª topic
	var sendWg sync.WaitGroup
	for aggIndex := 0; aggIndex < aggregateCount; aggIndex++ {
		sendWg.Add(1)
		go func(aggregateIndex int) {
			defer sendWg.Done()
			aggregateID := aggregateIDs[aggregateIndex]

			// ğŸ”‘ é€‰æ‹© topicï¼ˆåŒä¸€ä¸ªèšåˆIDå§‹ç»ˆä½¿ç”¨åŒä¸€ä¸ª topicï¼‰
			topicIndex := aggregateIndex % topicCount
			topic := topics[topicIndex]

			// ä¸²è¡Œå‘é€è¯¥èšåˆIDçš„æ‰€æœ‰æ¶ˆæ¯åˆ°åŒä¸€ä¸ª topic
			for version := int64(1); version <= int64(messagesPerAggregate); version++ {
				// ä½¿ç”¨ NewEnvelopeWithAutoID è‡ªåŠ¨ç”Ÿæˆ EventID
				// Payload å¿…é¡»æ˜¯æœ‰æ•ˆçš„ JSON
				payload := fmt.Sprintf(`{"aggregate":"%s","message":%d}`, aggregateID, version)
				envelope := eventbus.NewEnvelopeWithAutoID(
					aggregateID,
					"TestEvent",
					version,
					[]byte(payload),
				)

				err := eb.PublishEnvelope(ctx, topic, envelope)
				if err != nil {
					t.Logf("âŒ å‘é€å¤±è´¥: AggregateID=%s, Version=%d, Topic=%s, Error=%v", aggregateID, version, topic, err)
				}
			}

			t.Logf("âœ… èšåˆ %s çš„æ‰€æœ‰æ¶ˆæ¯å·²å‘é€åˆ° topic %s", aggregateID, topic)
		}(aggIndex)
	}

	sendWg.Wait()
	sendDuration := time.Since(sendStart)
	t.Logf("âœ… å‘é€å®Œæˆ: %d æ¡æ¶ˆæ¯, è€—æ—¶: %v", totalMessages, sendDuration)

	// ç­‰å¾…æ¶ˆæ¯å¤„ç†å®Œæˆ
	t.Log("â³ ç­‰å¾…æ¶ˆæ¯å¤„ç†å®Œæˆ...")
	timeout := time.After(30 * time.Second)
	ticker := time.NewTicker(1 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-timeout:
			t.Logf("âš ï¸  è¶…æ—¶: æ¥æ”¶åˆ° %d/%d æ¡æ¶ˆæ¯", atomic.LoadInt64(&receivedCount), totalMessages)
			goto analysis
		case <-ticker.C:
			received := atomic.LoadInt64(&receivedCount)
			violations := atomic.LoadInt64(&orderViolations)
			t.Logf("ğŸ“Š è¿›åº¦: æ¥æ”¶ %d/%d, é¡ºåºè¿å %d", received, totalMessages, violations)
			if received >= int64(totalMessages) {
				t.Log("âœ… æ‰€æœ‰æ¶ˆæ¯å·²æ¥æ”¶")
				goto analysis
			}
		}
	}

analysis:
	// åˆ†æç»“æœ
	t.Log("\n" + strings.Repeat("=", 80))
	t.Log("ğŸ“Š æµ‹è¯•ç»“æœåˆ†æ")
	t.Log(strings.Repeat("=", 80))

	finalReceived := atomic.LoadInt64(&receivedCount)
	finalViolations := atomic.LoadInt64(&orderViolations)

	t.Logf("å‘é€æ¶ˆæ¯æ•°: %d", totalMessages)
	t.Logf("æ¥æ”¶æ¶ˆæ¯æ•°: %d", finalReceived)
	t.Logf("æˆåŠŸç‡: %.2f%%", float64(finalReceived)/float64(totalMessages)*100)
	t.Logf("é¡ºåºè¿å: %d", finalViolations)
	t.Logf("é¡ºåºè¿åç‡: %.2f%%", float64(finalViolations)/float64(finalReceived)*100)

	// åˆ†ææ¯ä¸ªèšåˆçš„æ¥æ”¶æƒ…å†µ
	t.Log("\nğŸ“Š æ¯ä¸ªèšåˆçš„æ¥æ”¶æƒ…å†µ:")
	aggregateStats := make(map[string][]int64)
	receivedMu.Lock()
	for _, msg := range receivedMessages {
		aggregateStats[msg.AggregateID] = append(aggregateStats[msg.AggregateID], msg.EventVersion)
	}
	receivedMu.Unlock()

	for aggID, versions := range aggregateStats {
		// æ£€æŸ¥æ˜¯å¦æœ‰é¡ºåºè¿å
		violations := 0
		for i := 1; i < len(versions); i++ {
			if versions[i] <= versions[i-1] {
				violations++
			}
		}

		// æ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±
		missing := []int64{}
		versionSet := make(map[int64]bool)
		for _, v := range versions {
			versionSet[v] = true
		}
		for v := int64(1); v <= int64(messagesPerAggregate); v++ {
			if !versionSet[v] {
				missing = append(missing, v)
			}
		}

		// æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤
		duplicates := []int64{}
		versionCount := make(map[int64]int)
		for _, v := range versions {
			versionCount[v]++
		}
		for v, count := range versionCount {
			if count > 1 {
				duplicates = append(duplicates, v)
			}
		}

		status := "âœ…"
		if violations > 0 || len(missing) > 0 || len(duplicates) > 0 {
			status = "âŒ"
		}

		t.Logf("%s %s: æ¥æ”¶=%d/%d, é¡ºåºè¿å=%d, ç¼ºå¤±=%d, é‡å¤=%d",
			status, aggID, len(versions), messagesPerAggregate, violations, len(missing), len(duplicates))

		if len(missing) > 0 && len(missing) <= 10 {
			t.Logf("   ç¼ºå¤±ç‰ˆæœ¬: %v", missing)
		}
		if len(duplicates) > 0 && len(duplicates) <= 10 {
			t.Logf("   é‡å¤ç‰ˆæœ¬: %v", duplicates)
		}
	}

	// åˆ†ææ¥æ”¶æ—¶é—´åˆ†å¸ƒ
	t.Log("\nğŸ“Š æ¥æ”¶æ—¶é—´åˆ†æ:")
	if len(receivedMessages) > 0 {
		receivedMu.Lock()
		firstReceived := receivedMessages[0].ReceivedAt
		lastReceived := receivedMessages[len(receivedMessages)-1].ReceivedAt
		receivedMu.Unlock()

		receiveDuration := lastReceived.Sub(firstReceived)
		t.Logf("é¦–æ¡æ¶ˆæ¯æ¥æ”¶æ—¶é—´: %v", firstReceived.Format("15:04:05.000"))
		t.Logf("æœ«æ¡æ¶ˆæ¯æ¥æ”¶æ—¶é—´: %v", lastReceived.Format("15:04:05.000"))
		t.Logf("æ¥æ”¶è€—æ—¶: %v", receiveDuration)
		if receiveDuration.Seconds() > 0 {
			t.Logf("æ¥æ”¶ååé‡: %.2f msg/s", float64(finalReceived)/receiveDuration.Seconds())
		}
	}

	t.Log(strings.Repeat("=", 80))

	// æ–­è¨€
	require.Equal(t, int64(totalMessages), finalReceived, "åº”è¯¥æ¥æ”¶åˆ°æ‰€æœ‰æ¶ˆæ¯")
	require.Equal(t, int64(0), finalViolations, "ä¸åº”è¯¥æœ‰é¡ºåºè¿å")
}
