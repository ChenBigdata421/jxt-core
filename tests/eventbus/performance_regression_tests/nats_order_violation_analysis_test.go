package performance_tests

import (
	"context"
	"fmt"
	"sync"
	"sync/atomic"
	"testing"
	"time"

	"github.com/ChenBigdata421/jxt-core/sdk/pkg/eventbus"
	"github.com/stretchr/testify/require"
)

// TestNATSOrderViolationAnalysis åˆ†æ NATS é¡ºåºè¿åçš„è¯¦ç»†åŸå› 
func TestNATSOrderViolationAnalysis(t *testing.T) {
	t.Log("ğŸ” ===== NATS é¡ºåºè¿åè¯¦ç»†åˆ†ææµ‹è¯• =====")

	// åˆ›å»º NATS EventBus
	timestamp := time.Now().Unix()
	streamName := fmt.Sprintf("PERF_ANALYSIS_%d", timestamp)
	subjectPattern := fmt.Sprintf("analysis.%d.>", timestamp)

	natsConfig := &eventbus.NATSConfig{
		URLs:                []string{"nats://localhost:4223"},
		ClientID:            fmt.Sprintf("nats-analysis-%d", timestamp),
		MaxReconnects:       10,
		ReconnectWait:       1 * time.Second,
		ConnectionTimeout:   30 * time.Second,
		HealthCheckInterval: 60 * time.Second,
		JetStream: eventbus.JetStreamConfig{
			Enabled:        true,
			PublishTimeout: 10 * time.Second,
			AckWait:        15 * time.Second,
			MaxDeliver:     3,
			Stream: eventbus.StreamConfig{
				Name:      streamName,
				Subjects:  []string{subjectPattern},
				Storage:   "file",
				Retention: "limits",
				MaxAge:    1 * time.Hour,
				MaxBytes:  1024 * 1024 * 1024,
				MaxMsgs:   100000,
				Replicas:  1,
				Discard:   "old",
			},
			Consumer: eventbus.NATSConsumerConfig{
				DurableName:   fmt.Sprintf("analysis_%d", timestamp),
				DeliverPolicy: "all",
				AckPolicy:     "explicit",
				ReplayPolicy:  "instant",
				MaxAckPending: 1000,
				MaxWaiting:    500,
				MaxDeliver:    3,
			},
		},
	}

	eb, err := eventbus.NewNATSEventBus(natsConfig)
	require.NoError(t, err, "Failed to create NATS EventBus")
	defer eb.Close()

	ctx := context.Background()

	// æµ‹è¯•å‚æ•° - æ¨¡æ‹Ÿæ€§èƒ½æµ‹è¯•çš„ä½å‹åœºæ™¯
	aggregateCount := 50       // 50 ä¸ªèšåˆ
	messagesPerAggregate := 10 // æ¯ä¸ªèšåˆ 10 æ¡æ¶ˆæ¯ï¼ˆæ€»å…± 500 æ¡ï¼‰
	totalMessages := aggregateCount * messagesPerAggregate

	// ğŸ”‘ ä½¿ç”¨ 5 ä¸ª topicsï¼ˆä¸æ€§èƒ½æµ‹è¯•ä¸€è‡´ï¼‰
	topicCount := 5
	topics := make([]string, topicCount)
	for i := 0; i < topicCount; i++ {
		topics[i] = fmt.Sprintf("analysis.%d.topic%d", timestamp, i+1)
	}

	t.Logf("ğŸ“Š æµ‹è¯•å‚æ•°:")
	t.Logf("   èšåˆæ•°é‡: %d", aggregateCount)
	t.Logf("   æ¯ä¸ªèšåˆæ¶ˆæ¯æ•°: %d", messagesPerAggregate)
	t.Logf("   æ€»æ¶ˆæ¯æ•°: %d", totalMessages)
	t.Logf("   Topic æ•°é‡: %d", topicCount)
	t.Logf("   Topics: %v", topics)

	// ç”ŸæˆèšåˆIDåˆ—è¡¨ï¼ˆåŒ…å«topicä¿¡æ¯ï¼‰
	aggregateIDs := make([]string, aggregateCount)
	for i := 0; i < aggregateCount; i++ {
		topicIndex := i % topicCount
		aggregateIDs[i] = fmt.Sprintf("topic%d-agg-%d", topicIndex+1, i)
	}

	// è¯¦ç»†çš„æ¥æ”¶ç»Ÿè®¡
	type MessageRecord struct {
		AggregateID  string
		Version      int64
		ReceivedTime time.Time
		ReceivedSeq  int
		Topic        string // ä»èšåˆIDä¸­æå–
	}

	var receivedMessages []MessageRecord
	var receivedMu sync.Mutex
	var receivedCount int64
	var orderViolations int64
	var duplicateMessages int64

	// é¡ºåºæ£€æŸ¥å™¨
	type AggregateState struct {
		mu          sync.Mutex
		lastVersion int64
		received    map[int64]int // version -> æ¥æ”¶æ¬¡æ•°
	}
	aggregateStates := make(map[string]*AggregateState)
	var statesMu sync.Mutex

	// åˆ›å»ºæ¶ˆæ¯å¤„ç†å™¨
	handler := func(ctx context.Context, envelope *eventbus.Envelope) error {
		seq := int(atomic.AddInt64(&receivedCount, 1))

		// ä»èšåˆIDä¸­æå–topicä¿¡æ¯ï¼ˆæ ¼å¼ï¼štopic1-agg-0ï¼‰
		topicInfo := ""
		if len(envelope.AggregateID) > 6 && envelope.AggregateID[:5] == "topic" {
			topicInfo = envelope.AggregateID[:6] // "topic1"
		}

		// è®°å½•æ¥æ”¶
		receivedMu.Lock()
		receivedMessages = append(receivedMessages, MessageRecord{
			AggregateID:  envelope.AggregateID,
			Version:      envelope.EventVersion,
			ReceivedTime: time.Now(),
			ReceivedSeq:  seq,
			Topic:        topicInfo,
		})
		receivedMu.Unlock()

		// è·å–æˆ–åˆ›å»ºèšåˆçŠ¶æ€
		statesMu.Lock()
		state, exists := aggregateStates[envelope.AggregateID]
		if !exists {
			state = &AggregateState{
				received: make(map[int64]int),
			}
			aggregateStates[envelope.AggregateID] = state
		}
		statesMu.Unlock()

		// æ£€æŸ¥é¡ºåºå’Œé‡å¤
		state.mu.Lock()
		defer state.mu.Unlock()

		// æ£€æŸ¥æ˜¯å¦é‡å¤
		if count, exists := state.received[envelope.EventVersion]; exists {
			atomic.AddInt64(&duplicateMessages, 1)
			t.Logf("ğŸ” æ¶ˆæ¯é‡å¤: AggregateID=%s, Version=%d, æ¥æ”¶æ¬¡æ•°=%d, ReceivedSeq=%d",
				envelope.AggregateID, envelope.EventVersion, count+1, seq)
			state.received[envelope.EventVersion] = count + 1
			return nil
		}

		// æ£€æŸ¥é¡ºåº
		if envelope.EventVersion <= state.lastVersion {
			atomic.AddInt64(&orderViolations, 1)
			t.Logf("âŒ é¡ºåºè¿å: AggregateID=%s, Topic=%s, LastVersion=%d, CurrentVersion=%d, ReceivedSeq=%d",
				envelope.AggregateID, topicInfo, state.lastVersion, envelope.EventVersion, seq)
		}

		state.lastVersion = envelope.EventVersion
		state.received[envelope.EventVersion] = 1

		return nil
	}

	// è®¢é˜…æ‰€æœ‰ topics
	for _, topic := range topics {
		err = eb.SubscribeEnvelope(ctx, topic, handler)
		require.NoError(t, err, "Failed to subscribe to topic: "+topic)
	}

	// ç­‰å¾…è®¢é˜…å»ºç«‹
	time.Sleep(5 * time.Second)

	t.Logf("ğŸ“¤ å¼€å§‹å‘é€æ¶ˆæ¯...")

	// ä¸ºæ¯ä¸ªèšåˆIDåˆ›å»ºä¸€ä¸ª goroutine ä¸²è¡Œå‘é€æ¶ˆæ¯
	// ğŸ”‘ å…³é”®ï¼šåŒä¸€ä¸ªèšåˆIDçš„æ‰€æœ‰æ¶ˆæ¯éƒ½å‘é€åˆ°åŒä¸€ä¸ª topicï¼ˆä¸æ€§èƒ½æµ‹è¯•ä¸€è‡´ï¼‰
	var sendWg sync.WaitGroup
	for aggIndex := 0; aggIndex < aggregateCount; aggIndex++ {
		sendWg.Add(1)
		go func(aggregateIndex int) {
			defer sendWg.Done()
			aggregateID := aggregateIDs[aggregateIndex]

			// ğŸ”‘ é€‰æ‹© topicï¼ˆåŒä¸€ä¸ªèšåˆIDå§‹ç»ˆä½¿ç”¨åŒä¸€ä¸ª topicï¼‰
			topicIndex := aggregateIndex % topicCount
			topic := topics[topicIndex]

			// ä¸²è¡Œå‘é€è¯¥èšåˆIDçš„æ‰€æœ‰æ¶ˆæ¯åˆ°åŒä¸€ä¸ª topic
			for version := int64(1); version <= int64(messagesPerAggregate); version++ {
				envelope := &eventbus.Envelope{
					AggregateID:  aggregateID,
					EventType:    "TestEvent",
					EventVersion: version,
					Timestamp:    time.Now(),
					Payload:      []byte(fmt.Sprintf("aggregate %s message %d", aggregateID, version)),
				}

				err := eb.PublishEnvelope(ctx, topic, envelope)
				if err != nil {
					t.Logf("âŒ å‘é€å¤±è´¥: AggregateID=%s, Version=%d, Topic=%s, Error=%v", aggregateID, version, topic, err)
				}
			}
		}(aggIndex)
	}

	sendWg.Wait()
	t.Logf("âœ… å‘é€å®Œæˆ: %d æ¡æ¶ˆæ¯", totalMessages)

	t.Logf("â³ ç­‰å¾…æ¶ˆæ¯å¤„ç†å®Œæˆ...")

	// ç­‰å¾…æ‰€æœ‰æ¶ˆæ¯æ¥æ”¶å®Œæˆï¼ˆæœ€å¤šç­‰å¾… 30 ç§’ï¼‰
	timeout := time.After(30 * time.Second)
	ticker := time.NewTicker(1 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-timeout:
			t.Logf("âš ï¸  è¶…æ—¶: æ¥æ”¶ %d/%d", receivedCount, totalMessages)
			goto ANALYZE
		case <-ticker.C:
			current := atomic.LoadInt64(&receivedCount)
			violations := atomic.LoadInt64(&orderViolations)
			duplicates := atomic.LoadInt64(&duplicateMessages)
			t.Logf("ğŸ“Š è¿›åº¦: æ¥æ”¶ %d/%d, é¡ºåºè¿å %d, é‡å¤æ¶ˆæ¯ %d", current, totalMessages, violations, duplicates)
			if current >= int64(totalMessages) {
				t.Logf("âœ… æ‰€æœ‰æ¶ˆæ¯å·²æ¥æ”¶")
				goto ANALYZE
			}
		}
	}

ANALYZE:
	time.Sleep(2 * time.Second) // ç­‰å¾…æœ€åçš„æ¶ˆæ¯å¤„ç†å®Œæˆ

	t.Logf("\n================================================================================")
	t.Logf("ğŸ“Š æµ‹è¯•ç»“æœåˆ†æ")
	t.Logf("================================================================================")

	finalReceived := atomic.LoadInt64(&receivedCount)
	finalViolations := atomic.LoadInt64(&orderViolations)
	finalDuplicates := atomic.LoadInt64(&duplicateMessages)

	t.Logf("å‘é€æ¶ˆæ¯æ•°: %d", totalMessages)
	t.Logf("æ¥æ”¶æ¶ˆæ¯æ•°: %d", finalReceived)
	t.Logf("æˆåŠŸç‡: %.2f%%", float64(finalReceived)/float64(totalMessages)*100)
	t.Logf("é¡ºåºè¿å: %d", finalViolations)
	t.Logf("é‡å¤æ¶ˆæ¯: %d", finalDuplicates)
	t.Logf("é¡ºåºè¿åç‡: %.2f%%", float64(finalViolations)/float64(totalMessages)*100)
	t.Logf("é‡å¤ç‡: %.2f%%", float64(finalDuplicates)/float64(totalMessages)*100)

	t.Logf("\n================================================================================")
	t.Logf("ğŸ” æ ¹æœ¬åŸå› åˆ†æ")
	t.Logf("================================================================================")

	if finalDuplicates > 0 {
		t.Logf("âš ï¸  å‘ç° %d æ¡é‡å¤æ¶ˆæ¯ï¼", finalDuplicates)
		t.Logf("   å¯èƒ½åŸå› :")
		t.Logf("   1. NATS JetStream çš„é‡è¯•æœºåˆ¶ï¼ˆMaxDeliver=3ï¼‰")
		t.Logf("   2. ACK è¶…æ—¶å¯¼è‡´æ¶ˆæ¯é‡æ–°æŠ•é€’ï¼ˆAckWait=15sï¼‰")
		t.Logf("   3. æ¶ˆè´¹è€…å¤„ç†æ…¢å¯¼è‡´ ACK å»¶è¿Ÿ")
	}

	if finalViolations > 0 && finalDuplicates == 0 {
		t.Logf("âŒ å‘ç° %d æ¬¡çœŸæ­£çš„é¡ºåºè¿åï¼ˆéé‡å¤æ¶ˆæ¯å¯¼è‡´ï¼‰ï¼", finalViolations)
		t.Logf("   è¿™æ˜¯ä¸¥é‡é—®é¢˜ï¼Œéœ€è¦æ·±å…¥è°ƒæŸ¥ï¼")
	}

	if finalViolations > 0 && finalDuplicates > 0 {
		t.Logf("âš ï¸  é¡ºåºè¿åå¯èƒ½æ˜¯ç”±é‡å¤æ¶ˆæ¯å¯¼è‡´çš„")
		t.Logf("   éœ€è¦åŒºåˆ†ï¼šçœŸæ­£çš„ä¹±åº vs é‡å¤æ¶ˆæ¯")
	}

	t.Logf("\n================================================================================")

	// æ–­è¨€ï¼šä¸åº”è¯¥æœ‰é¡ºåºè¿åï¼ˆæ’é™¤é‡å¤æ¶ˆæ¯çš„å½±å“ï¼‰
	// å¦‚æœåªæ˜¯é‡å¤æ¶ˆæ¯ï¼Œä¸ç®—çœŸæ­£çš„é¡ºåºè¿å
	if finalViolations > 0 && finalDuplicates == 0 {
		t.Errorf("âŒ å‘ç°çœŸæ­£çš„é¡ºåºè¿å: %d æ¬¡", finalViolations)
	}
}
