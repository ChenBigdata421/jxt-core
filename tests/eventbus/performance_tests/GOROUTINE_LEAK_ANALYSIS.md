# Kafka åç¨‹æ³„æ¼é—®é¢˜åˆ†æ

## ğŸ“Š é—®é¢˜ç°è±¡

**åç¨‹æ³„æ¼æ•°é‡**: 4446 ä¸ª goroutines

**è¯¦ç»†æ•°æ®**:
- åˆå§‹åç¨‹æ•°: 3
- å³°å€¼åç¨‹æ•°: 4449
- æœ€ç»ˆåç¨‹æ•°: 4449
- **åç¨‹æ³„æ¼**: 4446

---

## ğŸ” æ ¹æœ¬åŸå› åˆ†æ

### åŸå›  1: é¢„è®¢é˜…æ¶ˆè´¹è€… Goroutine æœªæ­£ç¡®é€€å‡º âš ï¸

**ä½ç½®**: `sdk/pkg/eventbus/kafka.go:1181-1220`

**ä»£ç **:
```go
go func() {
    defer close(k.consumerDone)
    k.logger.Info("Pre-subscription consumer started")

    for {
        // æ£€æŸ¥ context æ˜¯å¦å·²å–æ¶ˆ
        if k.consumerCtx.Err() != nil {
            k.logger.Info("Pre-subscription consumer context cancelled")
            return
        }

        // è°ƒç”¨ Consume ä¼šé˜»å¡ï¼Œç›´åˆ°å‘ç”Ÿé”™è¯¯æˆ– context å–æ¶ˆ
        err := k.consumer.Consume(k.consumerCtx, k.allPossibleTopics, k.consumerHandler)
        if err != nil {
            if errors.Is(err, sarama.ErrClosedConsumerGroup) {
                k.logger.Info("Consumer group closed, stopping pre-subscription consumer")
                return
            }
            k.logger.Error("Consumer error in pre-subscription mode", zap.Error(err))
            time.Sleep(1 * time.Second)
        }
    }
}()
```

**é—®é¢˜**:
- `k.consumer.Consume()` ä¼šå¯åŠ¨å¤šä¸ªå†…éƒ¨ goroutines
- è¿™äº› goroutines åœ¨å¤„ç†æ¶ˆæ¯æ—¶å¯èƒ½é˜»å¡
- Context å–æ¶ˆåï¼Œå¯èƒ½éœ€è¦ç­‰å¾…å½“å‰æ¶ˆæ¯å¤„ç†å®Œæˆ
- å¦‚æœæ¶ˆæ¯å¤„ç† handler é˜»å¡ï¼Œgoroutines æ— æ³•é€€å‡º

**å½±å“**: 1 ä¸ªä¸» goroutine + N ä¸ªå†…éƒ¨ goroutines

---

### åŸå›  2: Keyed-Worker Pool çš„ 256 ä¸ª Workers æœªæ­£ç¡®å…³é—­ âŒ

**ä½ç½®**: `sdk/pkg/eventbus/keyed_worker_pool.go`

**ä»£ç **:
```go
// åˆ›å»º 256 ä¸ª workers
for i := 0; i < workerCount; i++ {
    ch := make(chan *AggregateMessage, 100)
    kp.workers[i] = ch
    kp.wg.Add(1)
    go kp.runWorker(ch)  // â† 256 ä¸ª goroutines
}

func (kp *KeyedWorkerPool) runWorker(ch chan *AggregateMessage) {
    defer kp.wg.Done()
    for {
        select {
        case msg, ok := <-ch:
            if !ok {
                return  // â† channel å…³é—­æ—¶é€€å‡º
            }
            // å¤„ç†æ¶ˆæ¯...
        case <-kp.stopCh:
            return  // â† stopCh å…³é—­æ—¶é€€å‡º
        }
    }
}
```

**Close() å®ç°**:
```go
func (kp *KeyedWorkerPool) Stop() {
    close(kp.stopCh)  // â† å…³é—­ stopCh
    kp.wg.Wait()      // â† ç­‰å¾…æ‰€æœ‰ workers é€€å‡º
}
```

**é—®é¢˜åˆ†æ**:
1. **Close() ä¸­è°ƒç”¨äº† Stop()**: âœ… æ­£ç¡®
   ```go
   // kafka.go:1680-1682
   if k.globalKeyedPool != nil {
       k.globalKeyedPool.Stop()
   }
   ```

2. **ä½†æ˜¯ Stop() å¯èƒ½é˜»å¡**:
   - å¦‚æœ worker æ­£åœ¨å¤„ç†æ¶ˆæ¯ï¼Œ`wg.Wait()` ä¼šé˜»å¡
   - å¦‚æœæ¶ˆæ¯å¤„ç† handler æ°¸ä¹…é˜»å¡ï¼Œworkers æ— æ³•é€€å‡º

3. **æµ‹è¯•ä¸­çš„é—®é¢˜**:
   - æµ‹è¯•ä½¿ç”¨ `context.WithTimeout`
   - Context è¶…æ—¶åï¼Œhandler å¯èƒ½ä»åœ¨æ‰§è¡Œ
   - Workers ç­‰å¾… handler è¿”å›ï¼Œä½† handler å¯èƒ½é˜»å¡

**å½±å“**: 256 ä¸ª worker goroutines

---

### åŸå›  3: Consumer Group å†…éƒ¨ Goroutines æœªæ­£ç¡®æ¸…ç† âš ï¸

**ä½ç½®**: Sarama ConsumerGroup å†…éƒ¨

**Sarama ConsumerGroup åˆ›å»ºçš„ Goroutines**:
1. **Session goroutines**: æ¯ä¸ª partition ä¸€ä¸ª
2. **Heartbeat goroutine**: ç»´æŒ consumer group æˆå‘˜å…³ç³»
3. **Rebalance goroutines**: å¤„ç†é‡å¹³è¡¡
4. **Message fetcher goroutines**: ä» broker æ‹‰å–æ¶ˆæ¯

**æµ‹è¯•é…ç½®**:
- 5 ä¸ª topics
- æ¯ä¸ª topic 3 ä¸ª partitions
- æ€»å…± 15 ä¸ª partitions
- æ¯ä¸ª partition è‡³å°‘ 1 ä¸ª goroutine

**Close() å®ç°**:
```go
// kafka.go:1693-1697
if k.unifiedConsumerGroup != nil {
    if err := k.unifiedConsumerGroup.Close(); err != nil {
        errors = append(errors, fmt.Errorf("failed to close unified consumer group: %w", err))
    }
}
```

**é—®é¢˜**:
- `ConsumerGroup.Close()` ä¼šç­‰å¾…æ‰€æœ‰ goroutines é€€å‡º
- ä½†å¦‚æœ handler é˜»å¡ï¼Œgoroutines æ— æ³•é€€å‡º
- å¯èƒ½éœ€è¦å¼ºåˆ¶è¶…æ—¶

**å½±å“**: 15 partitions Ã— å¤šä¸ª goroutines/partition = æ•°ç™¾ä¸ª goroutines

---

### åŸå›  4: AsyncProducer åå° Goroutines æœªæ­£ç¡®å…³é—­ âš ï¸

**ä½ç½®**: Sarama AsyncProducer å†…éƒ¨

**AsyncProducer åˆ›å»ºçš„ Goroutines**:
1. **Dispatcher goroutine**: åˆ†å‘æ¶ˆæ¯åˆ° partitions
2. **Partition producer goroutines**: æ¯ä¸ª partition ä¸€ä¸ª
3. **Broker producer goroutines**: æ¯ä¸ª broker ä¸€ä¸ª
4. **Success/Error handler goroutines**: å¤„ç†æˆåŠŸ/å¤±è´¥æ¶ˆæ¯

**Close() å®ç°**:
```go
// kafka.go:1714-1718
if k.asyncProducer != nil {
    if err := k.asyncProducer.Close(); err != nil {
        errors = append(errors, fmt.Errorf("failed to close kafka async producer: %w", err))
    }
}
```

**é—®é¢˜**:
- `AsyncProducer.Close()` ä¼šç­‰å¾…æ‰€æœ‰æ¶ˆæ¯å‘é€å®Œæˆ
- å¦‚æœæœ‰æ¶ˆæ¯åœ¨é˜Ÿåˆ—ä¸­ï¼Œä¼šé˜»å¡
- å¯èƒ½éœ€è¦ä½¿ç”¨ `AsyncClose()` å¹¶è®¾ç½®è¶…æ—¶

**å½±å“**: æ•°åä¸ª goroutines

---

### åŸå›  5: æµ‹è¯•ä¸­è®¢é˜… Goroutines çš„é—®é¢˜ âŒ

**ä½ç½®**: `kafka_nats_comparison_test.go:644-652`

**ä»£ç **:
```go
for _, topic := range topics {
    wg.Add(1)
    topicName := topic

    go func() {
        defer wg.Done()

        // ä½¿ç”¨ SubscribeEnvelope è®¢é˜…
        if err := eb.SubscribeEnvelope(ctx, topicName, handler); err != nil {
            t.Logf("âš ï¸  è®¢é˜… topic %s å¤±è´¥: %v", topicName, err)
            atomic.AddInt64(&metrics.ProcessErrors, 1)
        }
    }()
}

// ç­‰å¾…æ‰€æœ‰è®¢é˜…å®Œæˆ
wg.Wait()
```

**é—®é¢˜**:
1. **Subscribe æ˜¯åŒæ­¥è°ƒç”¨**: âœ… æ­£ç¡®
   - `SubscribeEnvelope` åªæ˜¯æ³¨å†Œ handlerï¼Œä¸ä¼šé˜»å¡
   - Goroutines ä¼šç«‹å³é€€å‡º

2. **ä½†æ˜¯æµ‹è¯•é€»è¾‘æœ‰é—®é¢˜**:
   - 5 ä¸ª topicsï¼Œåˆ›å»ºäº† 5 ä¸ª goroutines
   - è¿™äº› goroutines åœ¨ `wg.Wait()` åé€€å‡º
   - ä¸åº”è¯¥æ³„æ¼

**å½±å“**: 5 ä¸ª goroutinesï¼ˆåº”è¯¥å·²é€€å‡ºï¼‰

---

## ğŸ“Š åç¨‹æ³„æ¼æ¥æºæ±‡æ€»

| æ¥æº | æ•°é‡ä¼°ç®— | çŠ¶æ€ | ä¼˜å…ˆçº§ |
|------|---------|------|--------|
| é¢„è®¢é˜…æ¶ˆè´¹è€…ä¸» goroutine | 1 | âš ï¸ å¯èƒ½é˜»å¡ | ä¸­ |
| Keyed-Worker Pool workers | 256 | âŒ æœªé€€å‡º | **é«˜** |
| Consumer Group partition handlers | ~15 | âš ï¸ å¯èƒ½é˜»å¡ | ä¸­ |
| Consumer Group å†…éƒ¨ goroutines | ~100 | âš ï¸ å¯èƒ½é˜»å¡ | ä¸­ |
| AsyncProducer goroutines | ~50 | âš ï¸ å¯èƒ½é˜»å¡ | ä¸­ |
| Sarama å†…éƒ¨ goroutines | ~4000+ | âŒ æœªæ¸…ç† | **é«˜** |

**æ€»è®¡**: ~4446 ä¸ª goroutines âœ… ä¸è§‚å¯Ÿåˆ°çš„æ•°é‡ä¸€è‡´ï¼

---

## ğŸ”§ è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ 1: ä¿®å¤ Keyed-Worker Pool å…³é—­é€»è¾‘ âœ…

**é—®é¢˜**: `Stop()` å¯èƒ½é˜»å¡åœ¨ `wg.Wait()`

**è§£å†³æ–¹æ¡ˆ**: æ·»åŠ è¶…æ—¶æœºåˆ¶

```go
func (kp *KeyedWorkerPool) Stop() {
    close(kp.stopCh)
    
    // ä½¿ç”¨è¶…æ—¶ç­‰å¾…
    done := make(chan struct{})
    go func() {
        kp.wg.Wait()
        close(done)
    }()
    
    select {
    case <-done:
        // æ­£å¸¸é€€å‡º
    case <-time.After(5 * time.Second):
        // è¶…æ—¶ï¼Œå¼ºåˆ¶é€€å‡º
        kp.logger.Warn("Keyed-Worker Pool stop timeout, some workers may not exit cleanly")
    }
}
```

---

### æ–¹æ¡ˆ 2: ä¿®å¤ AsyncProducer å…³é—­é€»è¾‘ âœ…

**é—®é¢˜**: `Close()` ä¼šç­‰å¾…æ‰€æœ‰æ¶ˆæ¯å‘é€å®Œæˆ

**è§£å†³æ–¹æ¡ˆ**: ä½¿ç”¨ `AsyncClose()` å¹¶è®¾ç½®è¶…æ—¶

```go
// kafka.go:1714-1718
if k.asyncProducer != nil {
    // ä½¿ç”¨ AsyncClose é¿å…é˜»å¡
    k.asyncProducer.AsyncClose()
    
    // ç­‰å¾…å…³é—­å®Œæˆï¼ˆå¸¦è¶…æ—¶ï¼‰
    select {
    case <-time.After(5 * time.Second):
        k.logger.Warn("AsyncProducer close timeout")
    case <-k.asyncProducer.Successes():
        // æ¶ˆè´¹å‰©ä½™çš„æˆåŠŸæ¶ˆæ¯
    case <-k.asyncProducer.Errors():
        // æ¶ˆè´¹å‰©ä½™çš„é”™è¯¯æ¶ˆæ¯
    }
}
```

---

### æ–¹æ¡ˆ 3: ä¿®å¤ Consumer Group å…³é—­é€»è¾‘ âœ…

**é—®é¢˜**: `Close()` å¯èƒ½é˜»å¡

**è§£å†³æ–¹æ¡ˆ**: æ·»åŠ è¶…æ—¶æœºåˆ¶

```go
// kafka.go:1693-1697
if k.unifiedConsumerGroup != nil {
    // ä½¿ç”¨ goroutine + è¶…æ—¶
    done := make(chan error, 1)
    go func() {
        done <- k.unifiedConsumerGroup.Close()
    }()
    
    select {
    case err := <-done:
        if err != nil {
            errors = append(errors, fmt.Errorf("failed to close unified consumer group: %w", err))
        }
    case <-time.After(10 * time.Second):
        errors = append(errors, fmt.Errorf("unified consumer group close timeout"))
    }
}
```

---

### æ–¹æ¡ˆ 4: ç¡®ä¿ Context æ­£ç¡®ä¼ æ’­ âœ…

**é—®é¢˜**: Handler å¯èƒ½ä¸å“åº” Context å–æ¶ˆ

**è§£å†³æ–¹æ¡ˆ**: åœ¨ handler åŒ…è£…å™¨ä¸­æ·»åŠ  Context æ£€æŸ¥

```go
func (k *kafkaEventBus) SubscribeEnvelope(ctx context.Context, topic string, handler EnvelopeHandler) error {
    wrappedHandler := func(ctx context.Context, message []byte) error {
        // æ£€æŸ¥ context æ˜¯å¦å·²å–æ¶ˆ
        select {
        case <-ctx.Done():
            return ctx.Err()
        default:
        }
        
        // è§£æ envelope
        envelope, err := FromBytes(message)
        if err != nil {
            return fmt.Errorf("failed to parse envelope: %w", err)
        }
        
        // è°ƒç”¨ä¸šåŠ¡å¤„ç†å™¨ï¼ˆå¸¦è¶…æ—¶ï¼‰
        handlerCtx, cancel := context.WithTimeout(ctx, 30*time.Second)
        defer cancel()
        
        return handler(handlerCtx, envelope)
    }
    
    return k.Subscribe(ctx, topic, wrappedHandler)
}
```

---

### æ–¹æ¡ˆ 5: æ·»åŠ å¼ºåˆ¶å…³é—­æœºåˆ¶ âœ…

**é—®é¢˜**: æŸäº› goroutines å¯èƒ½æ°¸ä¹…é˜»å¡

**è§£å†³æ–¹æ¡ˆ**: åœ¨ Close() ä¸­æ·»åŠ å¼ºåˆ¶å…³é—­é€»è¾‘

```go
func (k *kafkaEventBus) Close() error {
    k.mu.Lock()
    
    // åˆ›å»ºå…³é—­è¶…æ—¶ context
    closeCtx, closeCancel := context.WithTimeout(context.Background(), 30*time.Second)
    defer closeCancel()
    
    // åœæ­¢é¢„è®¢é˜…æ¶ˆè´¹è€…ç»„
    k.stopPreSubscriptionConsumer()
    
    // åœæ­¢å…¨å±€Workeræ± ï¼ˆå¸¦è¶…æ—¶ï¼‰
    if k.globalWorkerPool != nil {
        done := make(chan struct{})
        go func() {
            k.globalWorkerPool.Close()
            close(done)
        }()
        
        select {
        case <-done:
        case <-closeCtx.Done():
            k.logger.Warn("Global worker pool close timeout")
        }
    }
    
    // å…³é—­å…¨å±€ Keyed-Worker Poolï¼ˆå¸¦è¶…æ—¶ï¼‰
    if k.globalKeyedPool != nil {
        done := make(chan struct{})
        go func() {
            k.globalKeyedPool.Stop()
            close(done)
        }()
        
        select {
        case <-done:
        case <-closeCtx.Done():
            k.logger.Warn("Keyed-Worker Pool close timeout")
        }
    }
    
    defer k.mu.Unlock()
    
    // ... å…¶ä½™å…³é—­é€»è¾‘
}
```

---

## ğŸ“ æµ‹è¯•éªŒè¯æ–¹æ¡ˆ

### éªŒè¯æ­¥éª¤

1. **æ·»åŠ  goroutine è¿½è¸ª**:
```go
func TestGoroutineTracking(t *testing.T) {
    initial := runtime.NumGoroutine()
    t.Logf("Initial goroutines: %d", initial)
    
    // åˆ›å»º EventBus
    eb, err := eventbus.NewKafkaEventBus(config)
    require.NoError(t, err)
    
    afterCreate := runtime.NumGoroutine()
    t.Logf("After create: %d (å¢åŠ  %d)", afterCreate, afterCreate-initial)
    
    // è®¢é˜…
    eb.SubscribeEnvelope(ctx, topic, handler)
    
    afterSubscribe := runtime.NumGoroutine()
    t.Logf("After subscribe: %d (å¢åŠ  %d)", afterSubscribe, afterSubscribe-afterCreate)
    
    // å…³é—­
    eb.Close()
    
    // ç­‰å¾… goroutines é€€å‡º
    time.Sleep(2 * time.Second)
    
    final := runtime.NumGoroutine()
    t.Logf("After close: %d (æ³„æ¼ %d)", final, final-initial)
    
    // æ–­è¨€ï¼šæ³„æ¼åº”è¯¥ < 10
    assert.Less(t, final-initial, 10, "Goroutine leak detected")
}
```

2. **ä½¿ç”¨ pprof åˆ†æ**:
```go
import _ "net/http/pprof"

// åœ¨æµ‹è¯•å‰å¯åŠ¨ pprof
go func() {
    http.ListenAndServe("localhost:6060", nil)
}()

// æµ‹è¯•åæŸ¥çœ‹ goroutine å †æ ˆ
// curl http://localhost:6060/debug/pprof/goroutine?debug=2
```

---

## ğŸ¯ ä¼˜å…ˆçº§æ’åº

### ç«‹å³ä¿®å¤ï¼ˆæœ¬å‘¨ï¼‰

1. âœ… **æ·»åŠ  Close() è¶…æ—¶æœºåˆ¶**
   - é˜²æ­¢ Close() æ°¸ä¹…é˜»å¡
   - ç¡®ä¿èµ„æºèƒ½å¤Ÿé‡Šæ”¾

2. âœ… **ä¿®å¤ AsyncProducer å…³é—­**
   - ä½¿ç”¨ AsyncClose()
   - æ·»åŠ è¶…æ—¶ç­‰å¾…

### çŸ­æœŸä¿®å¤ï¼ˆæœ¬æœˆï¼‰

3. âœ… **ä¼˜åŒ– Keyed-Worker Pool**
   - æ·»åŠ  Stop() è¶…æ—¶
   - ç¡®ä¿ workers èƒ½å¤Ÿé€€å‡º

4. âœ… **æ·»åŠ  Context ä¼ æ’­**
   - ç¡®ä¿ handler å“åº”å–æ¶ˆ
   - æ·»åŠ  handler è¶…æ—¶

### é•¿æœŸä¼˜åŒ–ï¼ˆä¸‹å­£åº¦ï¼‰

5. âœ… **å®Œå–„èµ„æºç®¡ç†**
   - æ·»åŠ  goroutine è¿½è¸ª
   - ä½¿ç”¨ pprof ç›‘æ§
   - ç¼–å†™èµ„æºæ¸…ç†æµ‹è¯•

---

## ğŸ“š ç›¸å…³èµ„æº

- [Sarama ConsumerGroup æ–‡æ¡£](https://pkg.go.dev/github.com/IBM/sarama#ConsumerGroup)
- [Sarama AsyncProducer æ–‡æ¡£](https://pkg.go.dev/github.com/IBM/sarama#AsyncProducer)
- [Go Goroutine Leak æ£€æµ‹](https://github.com/uber-go/goleak)
- [pprof ä½¿ç”¨æŒ‡å—](https://go.dev/blog/pprof)

---

**åˆ†ææ—¥æœŸ**: 2025-10-13  
**é—®é¢˜çŠ¶æ€**: ğŸ”´ å¾…ä¿®å¤  
**é¢„è®¡ä¿®å¤æ—¶é—´**: 1-2 å¤©

