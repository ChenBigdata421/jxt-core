package reliability_regression_tests

import (
	"context"
	"fmt"
	"sync"
	"sync/atomic"
	"testing"
	"time"

	"github.com/ChenBigdata421/jxt-core/sdk/pkg/eventbus"
	jxtjson "github.com/ChenBigdata421/jxt-core/sdk/pkg/json"
)

// TestKafkaFaultIsolation æµ‹è¯• Kafka EventBus æ•…éšœéš”ç¦»ï¼ˆå•ä¸ª Actor æ•…éšœä¸å½±å“å…¶ä»– Actorï¼‰
// âœ… Kafka Envelope æ”¯æŒ at-least-once è¯­ä¹‰ï¼Œpanic åä¼šé‡æŠ•é€’æ¶ˆæ¯
func TestKafkaFaultIsolation(t *testing.T) {
	helper := NewTestHelper(t)
	defer helper.Cleanup()

	topic := fmt.Sprintf("test.kafka.fault.isolation.%d", helper.GetTimestamp())
	bus := helper.CreateKafkaEventBus(fmt.Sprintf("kafka-fault-isolation-%d", helper.GetTimestamp()))

	var totalReceived int64
	var aggregate1Received int64
	var aggregate2Received int64
	var aggregate3Received int64
	var panicCount int64
	var panicTriggered atomic.Bool

	ctx := context.Background()

	// è®¢é˜… Envelopeï¼Œaggregate-1 çš„æ¶ˆæ¯è§¦å‘ panic
	err := bus.SubscribeEnvelope(ctx, topic, func(ctx context.Context, envelope *eventbus.Envelope) error {
		// aggregate-1 çš„ç¬¬ä¸€æ¡æ¶ˆæ¯è§¦å‘ panicï¼ˆåªè§¦å‘ä¸€æ¬¡ï¼‰
		if envelope.AggregateID == "aggregate-1" && envelope.EventVersion == 1 {
			if panicTriggered.CompareAndSwap(false, true) {
				atomic.AddInt64(&panicCount, 1)
				t.Logf("âš ï¸ Panic on aggregate-1")
				panic("simulated panic for aggregate-1")
			}
		}

		// â­ åªè®¡æ•°æˆåŠŸå¤„ç†çš„æ¶ˆæ¯ï¼ˆä¸åŒ…æ‹¬ panic çš„ï¼‰
		atomic.AddInt64(&totalReceived, 1)

		// ç»Ÿè®¡å„èšåˆçš„æ¶ˆæ¯æ•°
		switch envelope.AggregateID {
		case "aggregate-1":
			atomic.AddInt64(&aggregate1Received, 1)
		case "aggregate-2":
			atomic.AddInt64(&aggregate2Received, 1)
		case "aggregate-3":
			atomic.AddInt64(&aggregate3Received, 1)
		}

		t.Logf("ğŸ“¨ Processed: AggregateID=%s, Version=%d", envelope.AggregateID, envelope.EventVersion)
		return nil
	})
	helper.AssertNoError(err, "SubscribeEnvelope should not return error")

	time.Sleep(100 * time.Millisecond)

	// å‘é€å¤šä¸ªèšåˆçš„æ¶ˆæ¯ï¼ˆäº¤é”™å‘é€ï¼Œæµ‹è¯•éš”ç¦»æ€§ï¼‰
	aggregates := []string{"aggregate-1", "aggregate-2", "aggregate-3"}
	versionsPerAggregate := 5
	totalMessages := len(aggregates) * versionsPerAggregate

	for version := 1; version <= versionsPerAggregate; version++ {
		for _, aggID := range aggregates {
			envelope := &eventbus.Envelope{
				EventID:      fmt.Sprintf("evt-%s-v%d", aggID, version),
				AggregateID:  aggID,
				EventType:    "TestEvent",
				EventVersion: int64(version),
				Timestamp:    time.Now(),
				Payload:      jxtjson.RawMessage(fmt.Sprintf(`{"aggregate":"%s","version":%d}`, aggID, version)),
			}
			err = bus.PublishEnvelope(ctx, topic, envelope)
			helper.AssertNoError(err, "PublishEnvelope should not return error")
			time.Sleep(10 * time.Millisecond)
		}
	}

	// âœ… Kafka ä½¿ç”¨ at-least-once è¯­ä¹‰ï¼Œpanic åä¼šé‡æŠ•é€’æ¶ˆæ¯
	expectedMessages := int64(totalMessages)
	success := helper.WaitForMessages(&totalReceived, expectedMessages, 30*time.Second)
	helper.AssertTrue(success, "Should receive all messages after panic recovery (at-least-once)")

	// éªŒè¯ç»“æœ
	actualReceived := atomic.LoadInt64(&totalReceived)
	helper.AssertEqual(expectedMessages, actualReceived, "Should receive all messages (at-least-once semantics)")
	helper.AssertGreaterThan(atomic.LoadInt64(&panicCount), 0, "Should panic at least once")

	// éªŒè¯æ•…éšœéš”ç¦»ï¼šaggregate-2 å’Œ aggregate-3 åº”è¯¥æ”¶åˆ°æ‰€æœ‰æ¶ˆæ¯
	helper.AssertEqual(int64(versionsPerAggregate), atomic.LoadInt64(&aggregate2Received), "aggregate-2 should receive all messages")
	helper.AssertEqual(int64(versionsPerAggregate), atomic.LoadInt64(&aggregate3Received), "aggregate-3 should receive all messages")

	// âœ… aggregate-1 åº”è¯¥æ”¶åˆ°æ‰€æœ‰æ¶ˆæ¯ï¼ˆåŒ…æ‹¬é‡æŠ•é€’çš„ version=1ï¼‰
	aggregate1Count := atomic.LoadInt64(&aggregate1Received)
	helper.AssertEqual(int64(versionsPerAggregate), aggregate1Count, "aggregate-1 should receive all messages including retried ones (at-least-once)")

	t.Logf("âœ… Kafka Envelope Fault isolation test passed (at-least-once semantics)")
	t.Logf("ğŸ“Š aggregate-1: %d, aggregate-2: %d, aggregate-3: %d, Panic count: %d",
		aggregate1Count,
		atomic.LoadInt64(&aggregate2Received),
		atomic.LoadInt64(&aggregate3Received),
		atomic.LoadInt64(&panicCount))
	t.Logf("âœ… Note: Kafka Envelope uses at-least-once semantics, so panic triggers message retry")
}

// TestKafkaFaultIsolationRaw æµ‹è¯• Kafka Subscribe (é Envelope) çš„ at-most-once è¯­ä¹‰
func TestKafkaFaultIsolationRaw(t *testing.T) {
	helper := NewTestHelper(t)
	defer helper.Cleanup()

	topic := fmt.Sprintf("test.kafka.fault.raw.%d", helper.GetTimestamp())
	bus := helper.CreateKafkaEventBus(fmt.Sprintf("kafka-fault-raw-%d", helper.GetTimestamp()))

	var totalReceived int64
	var panicCount int64
	var panicTriggered atomic.Bool

	ctx := context.Background()

	helper.AssertNoError(bus.Subscribe(ctx, topic, func(ctx context.Context, data []byte) error {
		var payload struct {
			Aggregate string `json:"aggregate"`
			Version   int64  `json:"version"`
		}

		if err := jxtjson.Unmarshal(data, &payload); err != nil {
			return fmt.Errorf("failed to decode payload: %w", err)
		}

		// åªåœ¨ç¬¬ä¸€æ¬¡å¤„ç† aggregate-1 version 2 æ—¶è§¦å‘ panicï¼ˆè·³è¿‡ version 1ï¼‰
		if payload.Aggregate == "aggregate-1" && payload.Version == 2 {
			if panicTriggered.CompareAndSwap(false, true) {
				atomic.AddInt64(&panicCount, 1)
				t.Logf("âš ï¸ Panic on aggregate-1 version 2 (non-envelope)")
				panic("simulated panic for aggregate-1 raw message")
			}
		}

		// â­ åªè®¡æ•°æˆåŠŸå¤„ç†çš„æ¶ˆæ¯ï¼ˆä¸åŒ…æ‹¬ panic çš„ï¼‰
		atomic.AddInt64(&totalReceived, 1)
		t.Logf("ğŸ“¨ Processed raw message: AggregateID=%s, Version=%d", payload.Aggregate, payload.Version)
		return nil
	}), "Subscribe should not return error")

	time.Sleep(100 * time.Millisecond)

	aggregates := []string{"aggregate-1", "aggregate-2", "aggregate-3"}
	versionsPerAggregate := 5
	totalMessages := len(aggregates) * versionsPerAggregate

	for version := int64(1); version <= int64(versionsPerAggregate); version++ {
		for _, aggID := range aggregates {
			payload := struct {
				Aggregate string `json:"aggregate"`
				Version   int64  `json:"version"`
			}{
				Aggregate: aggID,
				Version:   version,
			}
			bytes, err := jxtjson.Marshal(payload)
			helper.AssertNoError(err, "Marshal raw payload should not fail")
			helper.AssertNoError(bus.Publish(ctx, topic, bytes), "Publish should not fail")
			time.Sleep(10 * time.Millisecond)
		}
	}

	expectedMessages := int64(totalMessages - 1)
	success := helper.WaitForMessages(&totalReceived, expectedMessages, 10*time.Second)
	helper.AssertTrue(success, "Should receive all raw messages except the one that panicked")

	actualReceived := atomic.LoadInt64(&totalReceived)
	helper.AssertEqual(expectedMessages, actualReceived, "Total raw messages should match at-most-once expectation")
	helper.AssertEqual(int64(1), atomic.LoadInt64(&panicCount), "Raw handler should panic exactly once")

	t.Logf("âœ… Kafka raw (non-envelope) fault isolation test passed (at-most-once semantics)")
	t.Logf("ğŸ“Š Expected: %d, Received: %d, Panic: %d", expectedMessages, actualReceived, atomic.LoadInt64(&panicCount))
}

// TestKafkaConcurrentFaultRecovery æµ‹è¯• Kafka EventBus å¹¶å‘æ•…éšœæ¢å¤
func TestKafkaConcurrentFaultRecovery(t *testing.T) {
	helper := NewTestHelper(t)
	defer helper.Cleanup()

	topic := fmt.Sprintf("test.kafka.concurrent.fault.recovery.%d", helper.GetTimestamp())
	bus := helper.CreateKafkaEventBus(fmt.Sprintf("kafka-concurrent-fault-%d", helper.GetTimestamp()))

	var totalReceived int64
	var panicCount int64
	var mu sync.Mutex
	panicAggregates := make(map[string]bool)

	ctx := context.Background()

	// è®¢é˜… Envelopeï¼Œå¤šä¸ªèšåˆçš„ç¬¬ä¸€æ¡æ¶ˆæ¯éƒ½è§¦å‘ panic
	err := bus.SubscribeEnvelope(ctx, topic, func(ctx context.Context, envelope *eventbus.Envelope) error {
		atomic.AddInt64(&totalReceived, 1)

		// æ¯ä¸ªèšåˆçš„ç¬¬ä¸€æ¡æ¶ˆæ¯è§¦å‘ panic
		if envelope.EventVersion == 1 {
			mu.Lock()
			if !panicAggregates[envelope.AggregateID] {
				panicAggregates[envelope.AggregateID] = true
				mu.Unlock()
				atomic.AddInt64(&panicCount, 1)
				t.Logf("âš ï¸ Panic on %s version 1", envelope.AggregateID)
				panic(fmt.Sprintf("simulated panic for %s", envelope.AggregateID))
			}
			mu.Unlock()
		}

		t.Logf("ğŸ“¨ Processed: AggregateID=%s, Version=%d", envelope.AggregateID, envelope.EventVersion)
		return nil
	})
	helper.AssertNoError(err, "SubscribeEnvelope should not return error")

	time.Sleep(100 * time.Millisecond)

	// å‘é€å¤šä¸ªèšåˆçš„æ¶ˆæ¯ï¼ˆå¹¶å‘å‘é€ï¼‰
	aggregateCount := 5
	versionsPerAggregate := 3
	totalMessages := aggregateCount * versionsPerAggregate

	var wg sync.WaitGroup
	for aggID := 1; aggID <= aggregateCount; aggID++ {
		wg.Add(1)
		go func(id int) {
			defer wg.Done()
			for version := 1; version <= versionsPerAggregate; version++ {
				envelope := &eventbus.Envelope{
					EventID:      fmt.Sprintf("evt-agg%d-v%d", id, version),
					AggregateID:  fmt.Sprintf("aggregate-%d", id),
					EventType:    "TestEvent",
					EventVersion: int64(version),
					Timestamp:    time.Now(),
					Payload:      jxtjson.RawMessage(fmt.Sprintf(`{"aggregate":"aggregate-%d","version":%d}`, id, version)),
				}
				err := bus.PublishEnvelope(ctx, topic, envelope)
				if err != nil {
					t.Logf("âš ï¸ PublishEnvelope error: %v", err)
				}
				time.Sleep(20 * time.Millisecond)
			}
		}(aggID)
	}

	wg.Wait()

	// ç­‰å¾…æ‰€æœ‰æ¶ˆæ¯å¤„ç†å®Œæˆï¼ˆå…è®¸é‡æŠ•é€’ï¼‰
	time.Sleep(5 * time.Second)

	// éªŒè¯ç»“æœï¼ˆå…è®¸ >= é¢„æœŸï¼Œå› ä¸ºé‡æŠ•é€’å¯èƒ½å¯¼è‡´é‡å¤ï¼‰
	actualReceived := atomic.LoadInt64(&totalReceived)
	helper.AssertGreaterThanOrEqual(actualReceived, int64(totalMessages), "Should receive at least all messages (at-least-once semantics)")
	helper.AssertGreaterThan(atomic.LoadInt64(&panicCount), 0, "Should panic at least once per aggregate")

	t.Logf("âœ… Kafka Concurrent fault recovery test passed (at-least-once semantics)")
	t.Logf("ğŸ“Š Total messages: %d (expected >= %d), Panic count: %d", actualReceived, totalMessages, atomic.LoadInt64(&panicCount))
	if actualReceived > int64(totalMessages) {
		t.Logf("â„¹ï¸ Received %d extra messages due to redelivery (expected behavior for at-least-once)", actualReceived-int64(totalMessages))
	}
}

// TestKafkaFaultIsolationWithHighLoad æµ‹è¯• Kafka EventBus é«˜è´Ÿè½½ä¸‹çš„æ•…éšœéš”ç¦»
func TestKafkaFaultIsolationWithHighLoad(t *testing.T) {
	helper := NewTestHelper(t)
	defer helper.Cleanup()

	topic := fmt.Sprintf("test.kafka.fault.isolation.high.load.%d", helper.GetTimestamp())
	bus := helper.CreateKafkaEventBus(fmt.Sprintf("kafka-high-load-fault-%d", helper.GetTimestamp()))

	var totalReceived int64
	var panicCount int64
	var faultyAggregateReceived int64
	var normalAggregatesReceived int64

	ctx := context.Background()

	// è®¢é˜… Envelopeï¼Œaggregate-fault çš„æ¶ˆæ¯è§¦å‘ panic
	err := bus.SubscribeEnvelope(ctx, topic, func(ctx context.Context, envelope *eventbus.Envelope) error {
		atomic.AddInt64(&totalReceived, 1)

		// aggregate-fault çš„ç¬¬ä¸€æ¡æ¶ˆæ¯è§¦å‘ panic
		if envelope.AggregateID == "aggregate-fault" && envelope.EventVersion == 1 {
			atomic.AddInt64(&panicCount, 1)
			panic("simulated panic for aggregate-fault")
		}

		// ç»Ÿè®¡æ¶ˆæ¯æ•°
		if envelope.AggregateID == "aggregate-fault" {
			atomic.AddInt64(&faultyAggregateReceived, 1)
		} else {
			atomic.AddInt64(&normalAggregatesReceived, 1)
		}

		return nil
	})
	helper.AssertNoError(err, "SubscribeEnvelope should not return error")

	time.Sleep(100 * time.Millisecond)

	// å‘é€å¤§é‡æ¶ˆæ¯ï¼ˆ1 ä¸ªæ•…éšœèšåˆ + 99 ä¸ªæ­£å¸¸èšåˆï¼‰
	normalAggregateCount := 99
	faultyAggregateVersions := 10
	normalAggregateVersions := 10
	totalMessages := faultyAggregateVersions + (normalAggregateCount * normalAggregateVersions)

	// å¹¶å‘å‘é€æ¶ˆæ¯
	var wg sync.WaitGroup

	// å‘é€æ•…éšœèšåˆçš„æ¶ˆæ¯
	wg.Add(1)
	go func() {
		defer wg.Done()
		for version := 1; version <= faultyAggregateVersions; version++ {
			envelope := &eventbus.Envelope{
				EventID:      fmt.Sprintf("evt-fault-v%d", version),
				AggregateID:  "aggregate-fault",
				EventType:    "TestEvent",
				EventVersion: int64(version),
				Timestamp:    time.Now(),
				Payload:      jxtjson.RawMessage(fmt.Sprintf(`{"aggregate":"aggregate-fault","version":%d}`, version)),
			}
			_ = bus.PublishEnvelope(ctx, topic, envelope)
		}
	}()

	// å‘é€æ­£å¸¸èšåˆçš„æ¶ˆæ¯
	for aggID := 1; aggID <= normalAggregateCount; aggID++ {
		wg.Add(1)
		go func(id int) {
			defer wg.Done()
			for version := 1; version <= normalAggregateVersions; version++ {
				envelope := &eventbus.Envelope{
					EventID:      fmt.Sprintf("evt-normal%d-v%d", id, version),
					AggregateID:  fmt.Sprintf("aggregate-normal-%d", id),
					EventType:    "TestEvent",
					EventVersion: int64(version),
					Timestamp:    time.Now(),
					Payload:      jxtjson.RawMessage(fmt.Sprintf(`{"aggregate":"aggregate-normal-%d","version":%d}`, id, version)),
				}
				_ = bus.PublishEnvelope(ctx, topic, envelope)
			}
		}(aggID)
	}

	wg.Wait()

	// ç­‰å¾…æ‰€æœ‰æ¶ˆæ¯å¤„ç†å®Œæˆï¼ˆå…è®¸é‡æŠ•é€’ï¼‰
	time.Sleep(5 * time.Second)

	// éªŒè¯ç»“æœï¼ˆå…è®¸ >= é¢„æœŸï¼Œå› ä¸ºé‡æŠ•é€’å¯èƒ½å¯¼è‡´é‡å¤ï¼‰
	actualReceived := atomic.LoadInt64(&totalReceived)
	helper.AssertGreaterThanOrEqual(actualReceived, int64(totalMessages), "Should receive at least all messages (at-least-once semantics)")
	helper.AssertGreaterThan(atomic.LoadInt64(&panicCount), 0, "Should panic at least once")

	// éªŒè¯æ•…éšœéš”ç¦»ï¼šæ­£å¸¸èšåˆåº”è¯¥æ”¶åˆ°æ‰€æœ‰æ¶ˆæ¯ï¼ˆå…è®¸é‡æŠ•é€’ï¼‰
	expectedNormalMessages := int64(normalAggregateCount * normalAggregateVersions)
	actualNormalReceived := atomic.LoadInt64(&normalAggregatesReceived)
	helper.AssertGreaterThanOrEqual(actualNormalReceived, expectedNormalMessages, "Normal aggregates should receive at least all messages")

	t.Logf("âœ… Kafka Fault isolation with high load test passed (at-least-once semantics)")
	t.Logf("ğŸ“Š Total: %d (expected >= %d), Faulty: %d, Normal: %d, Panic: %d",
		actualReceived,
		totalMessages,
		atomic.LoadInt64(&faultyAggregateReceived),
		actualNormalReceived,
		atomic.LoadInt64(&panicCount))
}
