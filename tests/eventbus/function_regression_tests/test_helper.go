package function_tests

import (
	"context"
	"fmt"
	"sync/atomic"
	"testing"
	"time"

	"github.com/ChenBigdata421/jxt-core/sdk/config"
	"github.com/ChenBigdata421/jxt-core/sdk/pkg/eventbus"
	"github.com/ChenBigdata421/jxt-core/sdk/pkg/logger"
	"github.com/IBM/sarama"
	"github.com/nats-io/nats.go"
)

// TestHelper æµ‹è¯•è¾…åŠ©å·¥å…·
type TestHelper struct {
	t              *testing.T
	kafkaAdmin     sarama.ClusterAdmin
	natsConn       *nats.Conn
	createdTopics  []string
	createdStreams []string
}

// NewTestHelper åˆ›å»ºæµ‹è¯•è¾…åŠ©å·¥å…·
func NewTestHelper(t *testing.T) *TestHelper {
	// åˆå§‹åŒ– logger
	logger.Setup()

	return &TestHelper{
		t:              t,
		createdTopics:  make([]string, 0),
		createdStreams: make([]string, 0),
	}
}

// CreateMemoryEventBus åˆ›å»º Memory EventBus ç”¨äºæµ‹è¯•
func (h *TestHelper) CreateMemoryEventBus() eventbus.EventBus {
	cfg := &eventbus.EventBusConfig{
		Type: "memory",
	}

	bus, err := eventbus.NewEventBus(cfg)
	h.AssertNoError(err, "Failed to create Memory EventBus")

	return bus
}

// CreateKafkaEventBus åˆ›å»º Kafka EventBus ç”¨äºæµ‹è¯•
func (h *TestHelper) CreateKafkaEventBus(clientID string) eventbus.EventBus {
	cfg := &eventbus.KafkaConfig{
		Brokers: []string{"localhost:29094"},
		Producer: eventbus.ProducerConfig{
			RequiredAcks:    1,
			FlushFrequency:  10 * time.Millisecond,
			FlushMessages:   100,
			Timeout:         5 * time.Second,
			FlushBytes:      1048576,
			RetryMax:        3,
			BatchSize:       16384,
			BufferSize:      8388608,
			MaxMessageBytes: 1048576,
		},
		Consumer: eventbus.ConsumerConfig{
			GroupID:            fmt.Sprintf("test-group-%s", clientID),
			SessionTimeout:     10 * time.Second,
			HeartbeatInterval:  3 * time.Second,
			MaxProcessingTime:  5 * time.Second,
			AutoOffsetReset:    "earliest",
			EnableAutoCommit:   true,
			AutoCommitInterval: 1 * time.Second,
			FetchMaxWait:       100 * time.Millisecond,
			MaxPollRecords:     500,
		},
		Net: eventbus.NetConfig{
			DialTimeout:  10 * time.Second,
			ReadTimeout:  10 * time.Second,
			WriteTimeout: 10 * time.Second,
		},
		ClientID: clientID,
	}

	bus, err := eventbus.NewKafkaEventBus(cfg)
	if err != nil {
		h.t.Fatalf("Failed to create Kafka EventBus: %v", err)
	}

	return bus
}

// CreateKafkaEventBusWithHealthCheck åˆ›å»ºå¸¦è‡ªå®šä¹‰å¥åº·æ£€æŸ¥é…ç½®çš„ Kafka EventBus ç”¨äºæµ‹è¯•
func (h *TestHelper) CreateKafkaEventBusWithHealthCheck(groupID string, healthCheckConfig config.HealthCheckConfig) eventbus.EventBus {
	cfg := &eventbus.KafkaConfig{
		Brokers: []string{"localhost:29094"},
		Producer: eventbus.ProducerConfig{
			RequiredAcks:    1,
			FlushFrequency:  10 * time.Millisecond,
			FlushMessages:   100,
			Timeout:         5 * time.Second,
			FlushBytes:      1048576,
			RetryMax:        3,
			BatchSize:       16384,
			BufferSize:      8388608,
			MaxMessageBytes: 1048576,
		},
		Consumer: eventbus.ConsumerConfig{
			GroupID:            groupID,
			SessionTimeout:     10 * time.Second,
			HeartbeatInterval:  3 * time.Second,
			MaxProcessingTime:  5 * time.Second,
			AutoOffsetReset:    "earliest",
			EnableAutoCommit:   true,
			AutoCommitInterval: 1 * time.Second,
			FetchMaxWait:       100 * time.Millisecond,
			MaxPollRecords:     500,
		},
		Net: eventbus.NetConfig{
			DialTimeout:  10 * time.Second,
			ReadTimeout:  10 * time.Second,
			WriteTimeout: 10 * time.Second,
		},
		ClientID: groupID,
		Enterprise: eventbus.EnterpriseConfig{
			HealthCheck: eventbus.HealthCheckConfig{
				Enabled:          healthCheckConfig.Enabled,
				Topic:            healthCheckConfig.Publisher.Topic,
				Interval:         healthCheckConfig.Publisher.Interval,
				Timeout:          healthCheckConfig.Publisher.Timeout,
				FailureThreshold: healthCheckConfig.Publisher.FailureThreshold,
				MessageTTL:       healthCheckConfig.Publisher.MessageTTL,
			},
		},
	}

	bus, err := eventbus.NewKafkaEventBus(cfg)
	if err != nil {
		h.t.Fatalf("Failed to create Kafka EventBus: %v", err)
	}

	return bus
}

// CreateNATSEventBus åˆ›å»º NATS EventBus ç”¨äºæµ‹è¯•
// æ³¨æ„ï¼šå¯ç”¨ JetStream ä»¥æ”¯æŒæŒä¹…åŒ–åŠŸèƒ½æµ‹è¯•
func (h *TestHelper) CreateNATSEventBus(clientID string) eventbus.EventBus {
	// ä½¿ç”¨ clientID ç”Ÿæˆå”¯ä¸€çš„ stream åç§°ï¼Œé¿å…å¤šä¸ªæµ‹è¯•ä¹‹é—´çš„å†²çª
	streamName := fmt.Sprintf("TEST_STREAM_%s", clientID)

	// ğŸ”§ ä¿®å¤ï¼šä¸ºæ¯ä¸ªæµ‹è¯•ä½¿ç”¨å”¯ä¸€çš„ subject å‰ç¼€ï¼Œé¿å… Stream subjects å†²çª
	// ä½¿ç”¨ clientID ä½œä¸ºå‰ç¼€ï¼Œç¡®ä¿æ¯ä¸ªæµ‹è¯•çš„ subjects ä¸é‡å 
	// ä¾‹å¦‚ï¼šnats-envelope-1760865444338.> åªåŒ¹é…è¯¥æµ‹è¯•çš„ä¸»é¢˜
	subjectPrefix := fmt.Sprintf("%s.>", clientID)

	cfg := &eventbus.NATSConfig{
		URLs:     []string{"nats://localhost:4223"},
		ClientID: clientID,
		// å¯ç”¨ JetStream ä»¥æ”¯æŒ ConfigureTopic ç­‰æŒä¹…åŒ–åŠŸèƒ½
		JetStream: eventbus.JetStreamConfig{
			Enabled: true,
			Stream: eventbus.StreamConfig{
				Name:     streamName,
				Subjects: []string{subjectPrefix},
			},
		},
	}

	bus, err := eventbus.NewNATSEventBus(cfg)
	if err != nil {
		h.t.Fatalf("Failed to create NATS EventBus: %v", err)
	}

	return bus
}

// CreateNATSEventBusWithHealthCheck åˆ›å»ºå¸¦è‡ªå®šä¹‰å¥åº·æ£€æŸ¥é…ç½®çš„ NATS EventBus ç”¨äºæµ‹è¯•
func (h *TestHelper) CreateNATSEventBusWithHealthCheck(clientID string, healthCheckConfig config.HealthCheckConfig) eventbus.EventBus {
	// ä½¿ç”¨ clientID ç”Ÿæˆå”¯ä¸€çš„ stream åç§°ï¼Œé¿å…å¤šä¸ªæµ‹è¯•ä¹‹é—´çš„å†²çª
	streamName := fmt.Sprintf("TEST_STREAM_%s", clientID)

	// ğŸ”§ ä¿®å¤ï¼šä¸ºæ¯ä¸ªæµ‹è¯•ä½¿ç”¨å”¯ä¸€çš„ subject å‰ç¼€ï¼Œé¿å… Stream subjects å†²çª
	subjectPrefix := fmt.Sprintf("%s.>", clientID)

	cfg := &eventbus.NATSConfig{
		URLs:     []string{"nats://localhost:4223"},
		ClientID: clientID,
		// å¯ç”¨ JetStream ä»¥æ”¯æŒå¥åº·æ£€æŸ¥æŒä¹…åŒ–
		JetStream: eventbus.JetStreamConfig{
			Enabled: true,
			Stream: eventbus.StreamConfig{
				Name:     streamName,
				Subjects: []string{subjectPrefix},
			},
		},
		Enterprise: eventbus.EnterpriseConfig{
			HealthCheck: eventbus.HealthCheckConfig{
				Enabled:          healthCheckConfig.Enabled,
				Topic:            healthCheckConfig.Publisher.Topic,
				Interval:         healthCheckConfig.Publisher.Interval,
				Timeout:          healthCheckConfig.Publisher.Timeout,
				FailureThreshold: healthCheckConfig.Publisher.FailureThreshold,
				MessageTTL:       healthCheckConfig.Publisher.MessageTTL,
			},
		},
	}

	bus, err := eventbus.NewNATSEventBus(cfg)
	if err != nil {
		h.t.Fatalf("Failed to create NATS EventBus: %v", err)
	}

	return bus
}

// CleanupKafkaTopics æ¸…ç† Kafka topics
func (h *TestHelper) CleanupKafkaTopics(topics []string) {
	if h.kafkaAdmin == nil {
		config := sarama.NewConfig()
		config.Version = sarama.V2_6_0_0
		admin, err := sarama.NewClusterAdmin([]string{"localhost:29094"}, config)
		if err != nil {
			h.t.Logf("âš ï¸  Failed to create Kafka admin: %v", err)
			return
		}
		h.kafkaAdmin = admin
	}

	for _, topic := range topics {
		err := h.kafkaAdmin.DeleteTopic(topic)
		if err != nil {
			h.t.Logf("âš ï¸  Failed to delete Kafka topic %s: %v", topic, err)
		} else {
			h.t.Logf("âœ… Deleted Kafka topic: %s", topic)
		}
	}

	// ç­‰å¾…åˆ é™¤å®Œæˆ
	time.Sleep(2 * time.Second)
}

// CleanupNATSStreams æ¸…ç† NATS streams
func (h *TestHelper) CleanupNATSStreams(streamPrefix string) {
	if h.natsConn == nil {
		nc, err := nats.Connect("nats://localhost:4223")
		if err != nil {
			h.t.Logf("âš ï¸  Failed to connect to NATS: %v", err)
			return
		}
		h.natsConn = nc
	}

	js, err := h.natsConn.JetStream()
	if err != nil {
		h.t.Logf("âš ï¸  Failed to get JetStream context: %v", err)
		return
	}

	// åˆ—å‡ºæ‰€æœ‰ streams
	streams := js.StreamNames()
	for stream := range streams {
		// åˆ é™¤åŒ¹é…å‰ç¼€çš„ stream
		if len(streamPrefix) == 0 || len(stream) >= len(streamPrefix) && stream[:len(streamPrefix)] == streamPrefix {
			err := js.DeleteStream(stream)
			if err != nil {
				h.t.Logf("âš ï¸  Failed to delete NATS stream %s: %v", stream, err)
			} else {
				h.t.Logf("âœ… Deleted NATS stream: %s", stream)
			}
		}
	}

	// ç­‰å¾…åˆ é™¤å®Œæˆ
	time.Sleep(1 * time.Second)
}

// Cleanup æ¸…ç†æ‰€æœ‰èµ„æº
func (h *TestHelper) Cleanup() {
	if len(h.createdTopics) > 0 {
		h.CleanupKafkaTopics(h.createdTopics)
	}

	if len(h.createdStreams) > 0 {
		for _, stream := range h.createdStreams {
			h.CleanupNATSStreams(stream)
		}
	}

	if h.kafkaAdmin != nil {
		h.kafkaAdmin.Close()
	}

	if h.natsConn != nil {
		h.natsConn.Close()
	}
}

// WaitForMessages ç­‰å¾…æ¥æ”¶æŒ‡å®šæ•°é‡çš„æ¶ˆæ¯
func (h *TestHelper) WaitForMessages(received *int64, expected int64, timeout time.Duration) bool {
	deadline := time.Now().Add(timeout)
	for time.Now().Before(deadline) {
		if atomic.LoadInt64(received) >= expected {
			return true
		}
		time.Sleep(100 * time.Millisecond)
	}
	return false
}

// AssertEqual æ–­è¨€ç›¸ç­‰
func (h *TestHelper) AssertEqual(expected, actual interface{}, message string) {
	if expected != actual {
		h.t.Errorf("%s: expected %v, got %v", message, expected, actual)
	}
}

// AssertNoError æ–­è¨€æ— é”™è¯¯
func (h *TestHelper) AssertNoError(err error, message string) {
	if err != nil {
		h.t.Errorf("%s: %v", message, err)
	}
}

// AssertTrue æ–­è¨€ä¸ºçœŸ
func (h *TestHelper) AssertTrue(condition bool, message string) {
	if !condition {
		h.t.Errorf("%s: expected true, got false", message)
	}
}

// AssertNotEmpty æ–­è¨€éç©º
func (h *TestHelper) AssertNotEmpty(obj interface{}, message string) {
	if obj == nil {
		h.t.Errorf("%s: expected non-empty, got nil", message)
		return
	}

	// æ£€æŸ¥å­—ç¬¦ä¸²ã€åˆ‡ç‰‡ã€map ç­‰
	switch v := obj.(type) {
	case string:
		if v == "" {
			h.t.Errorf("%s: expected non-empty string", message)
		}
	case []byte:
		if len(v) == 0 {
			h.t.Errorf("%s: expected non-empty byte slice", message)
		}
	}
}

// AssertNotNil æ–­è¨€ä¸ä¸º nil
func (h *TestHelper) AssertNotNil(obj interface{}, message string) {
	if obj == nil {
		h.t.Errorf("%s: expected non-nil, got nil", message)
	}
}

// AssertError æ–­è¨€æœ‰é”™è¯¯
func (h *TestHelper) AssertError(err error, message string) {
	if err == nil {
		h.t.Errorf("%s: expected error, got nil", message)
	}
}

// CreateKafkaTopics åˆ›å»º Kafka topics
func (h *TestHelper) CreateKafkaTopics(topics []string, numPartitions int32) {
	if h.kafkaAdmin == nil {
		config := sarama.NewConfig()
		config.Version = sarama.V2_6_0_0
		admin, err := sarama.NewClusterAdmin([]string{"localhost:29094"}, config)
		if err != nil {
			h.t.Fatalf("Failed to create Kafka admin: %v", err)
		}
		h.kafkaAdmin = admin
	}

	for _, topic := range topics {
		err := h.kafkaAdmin.CreateTopic(topic, &sarama.TopicDetail{
			NumPartitions:     numPartitions,
			ReplicationFactor: 1,
		}, false)
		if err != nil {
			h.t.Logf("âš ï¸  Failed to create Kafka topic %s: %v", topic, err)
		} else {
			h.t.Logf("âœ… Created Kafka topic: %s", topic)
			h.createdTopics = append(h.createdTopics, topic)
		}
	}

	// ç­‰å¾…åˆ›å»ºå®Œæˆ
	time.Sleep(2 * time.Second)
}

// WaitForCondition ç­‰å¾…æ¡ä»¶æ»¡è¶³
func (h *TestHelper) WaitForCondition(condition func() bool, timeout time.Duration, message string) bool {
	deadline := time.Now().Add(timeout)
	for time.Now().Before(deadline) {
		if condition() {
			return true
		}
		time.Sleep(100 * time.Millisecond)
	}
	h.t.Logf("âš ï¸  Timeout waiting for condition: %s", message)
	return false
}

// GetTimestamp è·å–å½“å‰æ—¶é—´æˆ³ï¼ˆç”¨äºç”Ÿæˆå”¯ä¸€IDï¼‰
func (h *TestHelper) GetTimestamp() int64 {
	return time.Now().UnixNano() / int64(time.Millisecond)
}

// CloseEventBus å…³é—­ EventBus å¹¶ç­‰å¾…èµ„æºé‡Šæ”¾
func (h *TestHelper) CloseEventBus(bus eventbus.EventBus) {
	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	// åœæ­¢æ‰€æœ‰ç›‘æ§
	_ = bus.StopAllBacklogMonitoring()
	_ = bus.StopAllHealthCheck()

	// å…³é—­ EventBus
	err := bus.Close()
	if err != nil {
		h.t.Logf("âš ï¸  Failed to close EventBus: %v", err)
	}

	// ç­‰å¾…èµ„æºé‡Šæ”¾
	select {
	case <-ctx.Done():
		h.t.Logf("âš ï¸  Timeout waiting for EventBus to close")
	case <-time.After(1 * time.Second):
		// æ­£å¸¸å…³é—­
	}
}
